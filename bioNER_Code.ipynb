{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZdmucYVNJ_JV",
    "outputId": "6e243559-7e96-44e8-b433-f20318c2cb4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\administrator\\anaconda3\\lib\\site-packages (4.27.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [18 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\pip-install-6fqiepgh\\tensorflow-gpu_feaf57065a864c97996b3415c86aef10\\setup.py\", line 37, in <module>\n",
      "      raise Exception(TF_REMOVAL_WARNING)\n",
      "  Exception:\n",
      "  \n",
      "  =========================================================\n",
      "  The \"tensorflow-gpu\" package has been removed!\n",
      "  \n",
      "  Please install \"tensorflow\" instead.\n",
      "  \n",
      "  Other than the name, the two packages have been identical\n",
      "  since TensorFlow 2.1, or roughly since Sep 2019. For more\n",
      "  information, see: pypi.org/project/tensorflow-gpu\n",
      "  =========================================================\n",
      "  \n",
      "  \n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tensorflow-gpu\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Running setup.py install for tensorflow-gpu did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [18 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\pip-install-6fqiepgh\\tensorflow-gpu_feaf57065a864c97996b3415c86aef10\\setup.py\", line 37, in <module>\n",
      "      raise Exception(TF_REMOVAL_WARNING)\n",
      "  Exception:\n",
      "  \n",
      "  =========================================================\n",
      "  The \"tensorflow-gpu\" package has been removed!\n",
      "  \n",
      "  Please install \"tensorflow\" instead.\n",
      "  \n",
      "  Other than the name, the two packages have been identical\n",
      "  since TensorFlow 2.1, or roughly since Sep 2019. For more\n",
      "  information, see: pypi.org/project/tensorflow-gpu\n",
      "  =========================================================\n",
      "  \n",
      "  \n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Encountered error while trying to install package.\n",
      "\n",
      "tensorflow-gpu\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: seqeval[gpu] in c:\\users\\administrator\\anaconda3\\lib\\site-packages (0.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: Keras>=2.2.4 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from seqeval[gpu]) (2.11.0)\n",
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: python_version>\"3.7\" in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-gpu->seqeval[gpu]) (0.0.2)\n",
      "Building wheels for collected packages: tensorflow-gpu\n",
      "  Building wheel for tensorflow-gpu (setup.py): started\n",
      "  Building wheel for tensorflow-gpu (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for tensorflow-gpu\n",
      "Failed to build tensorflow-gpu\n",
      "Installing collected packages: tensorflow-gpu\n",
      "  Running setup.py install for tensorflow-gpu: started\n",
      "  Running setup.py install for tensorflow-gpu: finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers seqeval[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQofjGvCoPW6",
    "outputId": "0c4d8ab8-6169-4d8d-bc65-a7673c900a4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in c:\\users\\administrator\\anaconda3\\lib\\site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iA00ZO0KGBwy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForTokenClassification, BertTokenizerFast, BertConfig, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "STfRAGpFGtdn",
    "outputId": "e07731aa-cdf1-4b89-88cb-e12211f8f022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "jfWFfyFQG8ey",
    "outputId": "e88f1772-7810-401e-bf68-86b24ab009fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABSTRACT_ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14145090</td>\n",
       "      <td>velvet antlers vas are commonly used in tradit...</td>\n",
       "      <td>63</td>\n",
       "      <td>transverse aortic constriction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900667</td>\n",
       "      <td>the clinical features of our cases demonstrate...</td>\n",
       "      <td>85</td>\n",
       "      <td>hodgkins lymphoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8625554</td>\n",
       "      <td>ceftobiprole bpr is an investigational cephalo...</td>\n",
       "      <td>90</td>\n",
       "      <td>methicillinsusceptible s aureus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8157202</td>\n",
       "      <td>we have taken a basic biologic RPA to elucidat...</td>\n",
       "      <td>26</td>\n",
       "      <td>parathyroid hormonerelated protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6784974</td>\n",
       "      <td>lipoperoxidationderived aldehydes for example ...</td>\n",
       "      <td>157</td>\n",
       "      <td>lipoperoxidation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ABSTRACT_ID                                               TEXT  LOCATION  \\\n",
       "0     14145090  velvet antlers vas are commonly used in tradit...        63   \n",
       "1      1900667  the clinical features of our cases demonstrate...        85   \n",
       "2      8625554  ceftobiprole bpr is an investigational cephalo...        90   \n",
       "3      8157202  we have taken a basic biologic RPA to elucidat...        26   \n",
       "4      6784974  lipoperoxidationderived aldehydes for example ...       157   \n",
       "\n",
       "                                LABEL  \n",
       "0      transverse aortic constriction  \n",
       "1                   hodgkins lymphoma  \n",
       "2     methicillinsusceptible s aureus  \n",
       "3  parathyroid hormonerelated protein  \n",
       "4                    lipoperoxidation  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./train.csv\", encoding='unicode_escape',nrows=1500000)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select labels having frequency >=145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zDSa1sRpDsbo",
    "outputId": "f1560140-4bf2-47ce-b5bb-5f18eb1e4a0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "689"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.DataFrame(data.LABEL.value_counts())\n",
    "d = d.loc[d.LABEL >= 145]\n",
    "d = list(d.index)\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Bl9ZJkShFb-9"
   },
   "outputs": [],
   "source": [
    "data = data.loc[data['LABEL'].isin(d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qI0K--G3GxxT",
    "outputId": "21dd28c0-5668-43bd-bc8c-9bdd7d8843cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102262, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new file for processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDsYHAPkny1k",
    "outputId": "0d5ca243-bb94-453e-e73e-36600ee09abd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"data.csv\", \"w\")\n",
    "f.write('sentence_id,word,label\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "A1_PV6vhoGaf"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_special_characters(word):\n",
    "  # w=re.split(\"[\\\\,;&|+%$!~.:/%^#\\-@?\\'\\\"(){}\\[\\]]\",word)\n",
    "  w=re.sub(\"[\\W+\\_]\", \"\",word,0,re.IGNORECASE)\n",
    "  new_word=\"\".join(w)\n",
    "  return new_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qFI5uz3woHff"
   },
   "outputs": [],
   "source": [
    "def remove_accents(word):\n",
    "  new_word= unidecode.unidecode(word)\n",
    "  return new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fxTzf1VyobO0"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import unidecode\n",
    "index = 0\n",
    "tag = 'O'\n",
    "for A_ID,text,location,label in np.array(data):\n",
    "  Words = text.split()\n",
    "  word_index = 0\n",
    "  for word in Words:\n",
    "    word=remove_special_characters(word)\n",
    "    word=remove_accents(word)\n",
    "    if word_index == location:\n",
    "      f.write(f'Sentence:{index},{word},{label}\\n')\n",
    "    else:\n",
    "      f.write(f'Sentence:{index},{word},{tag}\\n')\n",
    "    word_index += 1\n",
    "    f.write('\\n')\n",
    "  index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "f65meaiApT3_"
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "695o1s9soli_"
   },
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Arexp5jN43Bd",
    "outputId": "bdc3179f-b4a0-4681-aefa-343e3ed55801"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id    18061440\n",
       "word           18061000\n",
       "label          18061440\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8BRYoIL6nH-m",
    "outputId": "746f7ded-a1c7-4a62-b27f-b6db22b2c479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels: 690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "O                             17959178\n",
       "type ii collagen                   164\n",
       "hexosaminidase                     163\n",
       "envelope                           162\n",
       "adenocarcinoma of the lung         161\n",
       "                                ...   \n",
       "food deprivation                   145\n",
       "motivational interviewing          145\n",
       "h after inoculation                145\n",
       "water immersion                    145\n",
       "galactomannan                      145\n",
       "Name: label, Length: 690, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of unique labels: {}\".format(len(data2.label.unique())))\n",
    "frequencies = data2.label.value_counts()\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RaFsr1VHnep4",
    "outputId": "95bf1489-43bb-427f-c2d7-d865c63f6e0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('type ii collagen', 164), ('hexosaminidase', 163), ('envelope', 162), ('adenocarcinoma of the lung', 161), ('betahemolytic streptococci', 161), ('graft', 160), ('ornithine decarboxylase activity', 160), ('human endothelial cells', 159), ('kidney cells', 159), ('cardiac tamponade', 159), ('pulmonary metastases', 159), ('unbound fraction', 158), ('nomeganitrolarginine', 158), ('scanning tunneling microscope', 158), ('chemoembolization', 158), ('rnaprotein', 158), ('melting points', 158), ('left pulmonary artery', 157), ('total gastrectomy', 157), ('covalent binding', 157), ('immunohistochemical analysis', 157), ('extent of absorption', 157), ('extracellular matrix components', 157), ('adrenal medulla', 156), ('major histocompatibility complex class i', 156), ('tributyrin', 156), ('working memory', 156), ('pharyngoesophageal', 156), ('primary progressive', 156), ('parietal cortex', 156), ('cerebral perfusion', 156), ('olfactory bulbs', 155), ('opsonized zymosan', 155), ('serumfree media', 155), ('mechanosensitive', 155), ('internal anal sphincter', 155), ('hiatal hernia', 155), ('patientcentered care', 155), ('postexposure', 155), ('trypsin', 155), ('tibial nerve', 155), ('diazoxide', 155), ('oxidized', 155), ('iliac crest', 155), ('myosin heavy', 155), ('lichen planus', 154), ('normal liver', 154), ('systemic', 154), ('nicorandil', 154), ('mmp inhibitors', 154), ('active oxygen', 154), ('immediate breast reconstruction', 154), ('resiniferatoxin', 154), ('leukemia cells', 154), ('longterm survivors', 154), ('triolein', 154), ('multivessel disease', 154), ('schizosaccharomyces pombe', 154), ('recovery room', 154), ('granulocyte colony stimulating factor', 154), ('surface charge density', 154), ('primary pulmonary hypertension', 154), ('lateral wall', 154), ('leukocytes', 153), ('caloric restriction', 153), ('low malignant potential', 153), ('tumors', 153), ('space flight', 153), ('bacitracin', 153), ('contrastenhanced ct', 153), ('rift valley fever', 153), ('men who have sex with men', 153), ('papillary thyroid carcinomas', 153), ('carpal tunnel syndrome', 153), ('nadh dehydrogenase', 153), ('peak plasma concentration', 153), ('intragastric', 153), ('positive ion', 153), ('tricyclic antidepressants', 153), ('acute exacerbation', 153), ('rheumatoid', 153), ('renal artery stenosis', 153), ('invasive pneumococcal disease', 153), ('posterolateral', 153), ('quantitative polymerase chain reaction', 152), ('inferior olive', 152), ('cold pressor test', 152), ('best supportive care', 152), ('periventricular leukomalacia', 152), ('dorsal horn', 152), ('electronmicroscopy', 152), ('egg weight', 152), ('contrastenhanced computed tomography', 152), ('coronary artery occlusion', 152), ('drug user', 152), ('multidimensional scaling', 152), ('pars plana vitrectomy', 152), ('multislice ct', 152), ('respiratory chain', 152), ('monozygotic', 152), ('physiotherapy', 152), ('overshoot', 152), ('longterm retention', 152), ('arachidonoylglycerol', 152), ('dobutamine stress echocardiography', 152), ('microscope', 152), ('visual analogue', 152), ('vaccine effectiveness', 152), ('uterine contractions', 152), ('antimicrobial peptide', 152), ('bronchopulmonary dysplasia', 152), ('neurohypophysis', 152), ('integral membrane proteins', 152), ('gonadotrophin', 152), ('cabergoline', 152), ('chelating agent', 152), ('ion trap mass spectrometer', 152), ('light microscopy', 151), ('liquid crystalline', 151), ('reciprocal translocations', 151), ('cardiac transplantation', 151), ('homozygous deletion', 151), ('high cholesterol', 151), ('early follicular', 151), ('power density', 151), ('flip angle', 151), ('global cerebral ischemia', 151), ('phenothiazine', 151), ('radial artery', 151), ('singlechain antibody', 151), ('subsarcolemmal', 151), ('recovery', 151), ('posterior cingulate cortex', 151), ('gross domestic product', 151), ('lincomycin', 151), ('antidiuretic', 151), ('erythema nodosum', 151), ('immunological synapse', 151), ('endothelial cell monolayers', 151), ('cell tumors', 151), ('stem cell', 151), ('liver parenchymal cells', 151), ('isocyanate', 151), ('longissimus dorsi', 151), ('respiratory epithelium', 151), ('cricothyroid', 151), ('vascular endothelial', 151), ('cytotoxicsuppressor', 151), ('erythema multiforme', 151), ('maintenance hemodialysis', 151), ('bundle branch block', 151), ('intervention group', 151), ('inferior oblique', 151), ('pattern', 151), ('photofrin', 151), ('population growth rate', 151), ('patients with acute myocardial infarction', 151), ('lung compliance', 150), ('glycogen synthase', 150), ('serum folate', 150), ('hexagonal phase', 150), ('infection control', 150), ('isoelectrofocusing', 150), ('immunodiffusion', 150), ('estradiolbeta', 150), ('aortic diameter', 150), ('elementary bodies', 150), ('glass ionomer cement', 150), ('molybdenum', 150), ('retrograde amnesia', 150), ('gabapentin', 150), ('cytomegalovirus infection', 150), ('regulatory domain', 150), ('vaginal hysterectomy', 150), ('handgrip', 150), ('regression coefficient', 150), ('computed tomography scanning', 150), ('levels', 150), ('lens culinaris', 150), ('chemotaxis', 150), ('assisted living', 150), ('total p', 150), ('preferred direction', 150), ('iodine deficiency', 150), ('binding potential', 150), ('tissue culture', 150), ('hydroalcoholic extract', 150), ('black carbon', 150), ('costeffectiveness analysis', 150), ('meningococcal disease', 150), ('neuroblastoma cells', 150), ('body height', 150), ('luminal epithelial', 150), ('bipolar i', 150), ('alveolar bone loss', 150), ('tracheobronchial', 150), ('methanolic extract', 150), ('noonan syndrome', 150), ('medical outcomes study', 150), ('subretinal fluid', 150), ('ultrafiltration', 149), ('aortic valve disease', 149), ('main pancreatic duct', 149), ('health promotion', 149), ('interstitial cystitis', 149), ('insulindependent diabetes mellitus', 149), ('bundle sheath', 149), ('shortaxis', 149), ('blood plasma', 149), ('melaninconcentrating hormone', 149), ('clinical examination', 149), ('personal protective equipment', 149), ('connective tissue diseases', 149), ('total testosterone', 149), ('highly polymorphic', 149), ('middle temporal', 149), ('cancer', 149), ('plasmodium berghei', 149), ('congenital heart diseases', 149), ('duodenal', 149), ('aldehyde oxidase', 149), ('alternative splicing', 149), ('unresponsiveness', 149), ('antireflux surgery', 149), ('short bowel syndrome', 149), ('bacterial translocation', 149), ('phosphate buffer solution', 149), ('twitch force', 149), ('periaqueductal grey', 149), ('organizing pneumonia', 149), ('negative symptoms', 149), ('alternative pathway', 149), ('mosaic virus', 149), ('serial analysis of gene expression', 149), ('corrected', 149), ('plasmodesmata', 149), ('prosthetic valve endocarditis', 149), ('triglyceride levels', 149), ('bismuth', 149), ('nethylmaleimidesensitive factor', 149), ('chronic constriction injury', 149), ('ecadherin', 149), ('ca channels', 149), ('mean platelet volume', 149), ('nitrocellulose membrane', 149), ('neuroleptic malignant syndrome', 149), ('stomach cancer', 149), ('videoassisted thoracic surgery', 149), ('suppressorcytotoxic', 149), ('autologous bmt', 149), ('insertion loss', 149), ('posterior tibial nerve', 149), ('lung transplant recipients', 149), ('cervical spondylotic myelopathy', 149), ('chemical warfare', 149), ('superior laryngeal', 149), ('great saphenous vein', 149), ('response times', 149), ('highresolution transmission electron microscopy', 149), ('cognitivebehavioral', 149), ('capsid', 149), ('atherosclerotic', 149), ('breeding values', 149), ('basic life support', 149), ('estrogen receptors', 148), ('fructosebisphosphatase', 148), ('dry eye syndrome', 148), ('mammalian', 148), ('mesalazine', 148), ('public health service', 148), ('antigen receptors', 148), ('proliferative index', 148), ('lanreotide', 148), ('chronic disorders', 148), ('hydroxybenzoate', 148), ('japanese encephalitis', 148), ('anterior chamber depth', 148), ('macrophage migration inhibitory factor', 148), ('inflammatory myopathy', 148), ('placebo', 148), ('amlodipine', 148), ('spiral ganglion', 148), ('spindle assembly checkpoint', 148), ('recombinant human growth hormone', 148), ('tindependent', 148), ('heterogeneous nuclear', 148), ('margin', 148), ('acute myeloid', 148), ('chemiluminescent', 148), ('drosophila melanogaster', 148), ('electron transport system', 148), ('cutaneous leishmaniasis', 148), ('cardiac rupture', 148), ('nuclear transfer', 148), ('ventral prostate', 148), ('calorie restriction', 148), ('aminoglutethimide', 148), ('aminoglycoside antibiotics', 148), ('streptococcus agalactiae', 148), ('preeclamptic', 148), ('pseudorabies', 148), ('culture filtrate', 148), ('second molar', 148), ('receptorinteracting protein', 148), ('solubilization', 148), ('mycobacterium bovis', 148), ('days of incubation', 148), ('kynurenine pathway', 148), ('blunt abdominal trauma', 148), ('noncompetitive', 148), ('neurosecretory', 148), ('electrically stimulated', 148), ('thiotepa', 148), ('bleeding time', 148), ('chemiluminescence', 148), ('ketopgf alpha', 148), ('gonadotropic', 148), ('rubrospinal', 148), ('polymerase chain reaction method', 148), ('mantelhaenszel', 148), ('truncal vagotomy', 148), ('milliseconds', 148), ('hypothalamicpituitaryadrenal axis', 148), ('achilles tendon', 148), ('diffuse alveolar damage', 148), ('episodic memory', 148), ('intrauterine pregnancy', 148), ('pegylated', 148), ('procainamide', 148), ('methylglyoxal', 148), ('left ventricular dysfunction', 148), ('picosecond', 148), ('subclavian vein', 148), ('conscious sedation', 148), ('transactivation', 148), ('mitotic activity', 148), ('homologous', 148), ('tuning curves', 147), ('primary myelofibrosis', 147), ('electrophysiologic', 147), ('herpes simplex encephalitis', 147), ('chest roentgenogram', 147), ('trabecular bone volume', 147), ('cervical cancer', 147), ('rapid prototyping', 147), ('corticospinal tract', 147), ('inhibitory', 147), ('nomifensine', 147), ('mediobasal hypothalamus', 147), ('bone marrow involvement', 147), ('intermetatarsal', 147), ('information systems', 147), ('discriminant function', 147), ('normal brain tissue', 147), ('tantalum', 147), ('cortical plate', 147), ('czech republic', 147), ('friedreichs ataxia', 147), ('chest radiographs', 147), ('nucleotide phosphodiesterase', 147), ('migration inhibition', 147), ('distal radius', 147), ('placebocontrolled trials', 147), ('blast crisis', 147), ('dopa decarboxylase', 147), ('pronuclear', 147), ('backpropagation', 147), ('tibiofemoral', 147), ('antisense oligonucleotide', 147), ('bovine tuberculosis', 147), ('maximal exercise', 147), ('gibberellin', 147), ('fibres', 147), ('round window', 147), ('low anterior resection', 147), ('deep cerebellar nuclei', 147), ('pulmonary embolus', 147), ('neck dissection', 147), ('propylene glycol', 147), ('tunicamycin', 147), ('bone scan', 147), ('fractional shortening', 147), ('correspondence analysis', 147), ('primary health care', 147), ('trapezoid body', 147), ('dipeptidyl peptidase', 147), ('dietinduced obesity', 147), ('dim light', 147), ('haemagglutination', 147), ('peak force', 147), ('tetrahydrofuran', 147), ('dentate gyrus', 147), ('dermal papilla', 147), ('genetically obese', 147), ('inferior alveolar nerve', 147), ('renal blood flow', 147), ('pairedpulse facilitation', 147), ('silica gel', 147), ('adductor pollicis', 147), ('major histocompatibility', 147), ('protein gene product', 147), ('supercritical fluid', 147), ('salmon calcitonin', 147), ('lewis', 147), ('vasovagal syncope', 147), ('eosinophilic esophagitis', 147), ('intraabdominal', 147), ('neurocysticercosis', 147), ('transfer function', 147), ('celiac trunk', 147), ('corneal endothelial', 147), ('peptic ulcer', 147), ('hemoglobin s', 147), ('cerebrospinal', 147), ('serumfree', 147), ('brain stem', 147), ('olfactory receptor', 147), ('alcoholic liver disease', 147), ('confocal laser scanning microscopy', 147), ('pnitrophenol', 147), ('lymphoblastoid cells', 147), ('pancreastatin', 147), ('lactic acidosis', 147), ('functional class', 147), ('hemodialyzed', 147), ('pregnancy rates', 147), ('proteases', 147), ('superior temporal sulcus', 147), ('epinephrine', 147), ('pulmonary tb', 146), ('parathormone', 146), ('particle size distribution', 146), ('frontal lobe', 146), ('geometric means', 146), ('good recovery', 146), ('basal lamina', 146), ('wiskottaldrich syndrome', 146), ('protein synthesis inhibitor cycloheximide', 146), ('surgical intensive care unit', 146), ('epicatechin', 146), ('fetal growth retardation', 146), ('methadone maintenance', 146), ('megavoltage', 146), ('posterior cranial fossa', 146), ('acute pyelonephritis', 146), ('choanal atresia', 146), ('human colon adenocarcinoma', 146), ('social isolation', 146), ('gemfibrozil', 146), ('degree of conversion', 146), ('border zone', 146), ('endometrial hyperplasia', 146), ('vascular', 146), ('myoelectric', 146), ('renal dysfunction', 146), ('hepatitis', 146), ('lymphoblastoid', 146), ('indapamide', 146), ('histidine kinase', 146), ('power spectra', 146), ('urinary volume', 146), ('protein data bank', 146), ('peptide mass fingerprinting', 146), ('electron capture', 146), ('ventromedial hypothalamic', 146), ('cluster analysis', 146), ('reference group', 146), ('days after birth', 146), ('general surgery', 146), ('marfan syndrome', 146), ('cochlear implantation', 146), ('attenuation coefficient', 146), ('benzoic acid', 146), ('agematched controls', 146), ('vitro stimulation', 146), ('brassinosteroid', 146), ('complementary medicine', 146), ('acute lymphocytic', 146), ('artemether', 146), ('annulus fibrosus', 146), ('postvaccination', 146), ('disintegrin and metalloproteinase', 146), ('serum uric acid', 146), ('bandwidth', 146), ('physiologically based pharmacokinetic', 146), ('common mental disorders', 146), ('metastatic disease', 146), ('resident peritoneal macrophages', 146), ('cation exchange capacity', 146), ('peak bone mass', 146), ('bed rest', 146), ('caspofungin', 146), ('insulindependent diabetes', 146), ('heavy drinkers', 146), ('doublestranded dna', 146), ('quaternary ammonium', 146), ('universal precautions', 146), ('variant angina', 146), ('innominate artery', 146), ('visceral adipose tissue', 146), ('holliday junction', 146), ('enteral nutrition', 146), ('metastasisfree survival', 146), ('cognitive therapy', 146), ('coronary artery calcification', 146), ('metformin', 146), ('epidural morphine', 146), ('arachidonic', 146), ('normal women', 146), ('farinfrared', 146), ('pulmonary fibrosis', 146), ('molecular beacon', 146), ('chronic granulomatous disease', 146), ('retinal nerve fiber layer', 146), ('olfactory nerve', 146), ('venous outflow', 146), ('sea surface temperature', 146), ('polyelectrolyte', 146), ('pulmonary sequestration', 146), ('displacement', 146), ('recombinant human bone morphogenetic protein', 146), ('permeability transition pore', 146), ('dorsal motor nucleus', 146), ('infant mortality', 146), ('cbl', 146), ('tetracyclines', 146), ('right ventricular pressure', 146), ('flow cytometry', 146), ('ammoniaoxidizing bacteria', 146), ('laparoscopic radical prostatectomy', 146), ('sympathectomized', 146), ('acanthamoeba keratitis', 146), ('methyl methanesulfonate', 146), ('light microscopic', 146), ('proton transfer', 146), ('pulse pressure', 146), ('erythrocyte aggregation', 146), ('stable disease', 146), ('encapsulation efficiency', 146), ('polyhedrin', 146), ('granulation tissue', 146), ('follicular carcinomas', 146), ('dissolved organic carbon', 146), ('nicotine', 146), ('action potential amplitude', 146), ('aberrant crypt foci', 146), ('abscisic acid', 146), ('fluorescence microscopy', 146), ('patellar tendon', 146), ('hexobarbital', 146), ('conditioned responses', 146), ('intraabdominal abscess', 146), ('saturation transfer', 146), ('prostate brachytherapy', 146), ('tetratricopeptide', 146), ('stearoylcoa desaturase', 146), ('proximal tubule', 146), ('wall stress', 146), ('hivinfected', 146), ('fetal thymus', 146), ('rejection', 146), ('pseudopregnancy', 145), ('recurrent abdominal pain', 145), ('interacting protein', 145), ('transplanted', 145), ('high protein diet', 145), ('prefrontal cortical', 145), ('logistic regression', 145), ('tuberculin skin test', 145), ('lowdensity lipoproteins', 145), ('transsphenoidal surgery', 145), ('stress echocardiography', 145), ('uric acid', 145), ('position effect', 145), ('walking test', 145), ('immunocompromised patients', 145), ('microcrystalline cellulose', 145), ('typical development', 145), ('left ventricular systolic function', 145), ('methyl orange', 145), ('proteinprotein interaction', 145), ('sacroiliac', 145), ('differential display', 145), ('visual cortex', 145), ('lateral rectus', 145), ('central corneal thickness', 145), ('ovulation rate', 145), ('retrovirus', 145), ('conformal radiotherapy', 145), ('hearing aids', 145), ('f hybrid', 145), ('endothelial cell dysfunction', 145), ('peak amplitude', 145), ('methadone maintenance treatment', 145), ('digital image analysis', 145), ('electroretinographic', 145), ('methadone', 145), ('balloon pump', 145), ('treatment group', 145), ('haemofiltration', 145), ('avian myeloblastosis virus', 145), ('phytosterols', 145), ('hypersensitive response', 145), ('sites', 145), ('fulllength', 145), ('tyrosine', 145), ('soil organic carbon', 145), ('perchloric acid', 145), ('acute ischaemic stroke', 145), ('microcomputed tomography', 145), ('rat peritoneal mast cells', 145), ('mixed cellularity', 145), ('biochemical response', 145), ('bone loss', 145), ('pulsed doppler', 145), ('former smokers', 145), ('tensile strength', 145), ('external rotation', 145), ('osmotic pressure', 145), ('serotonin receptor', 145), ('agonist quinpirole', 145), ('anterior horn', 145), ('cumulative dose', 145), ('tropomyosin', 145), ('articular cartilage', 145), ('opioid receptors', 145), ('thyroid gland', 145), ('biochemical', 145), ('cardiac magnetic resonance', 145), ('soybean agglutinin', 145), ('right', 145), ('folinic acid', 145), ('ionizing irradiation', 145), ('capsular polysaccharides', 145), ('egg count', 145), ('postmortem interval', 145), ('family physicians', 145), ('freunds complete adjuvant', 145), ('stride length', 145), ('congestive cardiac failure', 145), ('acute heart failure', 145), ('breast cancer survivors', 145), ('adrenocortical carcinoma', 145), ('polypropylene mesh', 145), ('pulmonary emboli', 145), ('lyme arthritis', 145), ('hyperparathyroidism', 145), ('exerciseinduced asthma', 145), ('resistant starch', 145), ('histocompatibility', 145), ('glatiramer acetate', 145), ('transgenic mouse', 145), ('sesquiterpene lactones', 145), ('ang ii receptor', 145), ('o delivery', 145), ('common peroneal nerve', 145), ('insulin gene', 145), ('anaplastic lymphoma kinase', 145), ('hip dysplasia', 145), ('dinitrophenyl', 145), ('emergency physician', 145), ('general', 145), ('autonomic blockade', 145), ('moderately differentiated', 145), ('glycemic index', 145), ('electrophoretic mobility shift assays', 145), ('tridimensional', 145), ('dynamic exercise', 145), ('socioeconomic level', 145), ('postimmunization', 145), ('western australia', 145), ('helical computed tomography', 145), ('hemagglutinating', 145), ('placental lactogen', 145), ('verbal fluency', 145), ('feed consumption', 145), ('continuity of care', 145), ('gonadal dysgenesis', 145), ('occupational health', 145), ('internal transcribed spacer region', 145), ('spondyloarthropathies', 145), ('reninangiotensinaldosterone', 145), ('head kidney', 145), ('external anal sphincter', 145), ('food deprivation', 145), ('motivational interviewing', 145), ('h after inoculation', 145), ('water immersion', 145), ('galactomannan', 145)]\n"
     ]
    }
   ],
   "source": [
    "labels = {}\n",
    "for label, count in zip(frequencies.index, frequencies):\n",
    "    if label != \"O\":\n",
    "        if label not in labels.keys():\n",
    "            labels[label] = count\n",
    "        else:\n",
    "            labels[label] += count\n",
    "    continue\n",
    "\n",
    "print(sorted(labels.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels to IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bym3kJF8SR7w",
    "outputId": "4ce3f9b5-8a21-4a06-ecaa-f87205013b91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'hydroxybenzoate': 1,\n",
       " 'aortic valve disease': 2,\n",
       " 'nomifensine': 3,\n",
       " 'rnaprotein': 4,\n",
       " 'socioeconomic level': 5,\n",
       " 'benzoic acid': 6,\n",
       " 'glatiramer acetate': 7,\n",
       " 'transsphenoidal surgery': 8,\n",
       " 'wall stress': 9,\n",
       " 'systemic': 10,\n",
       " 'parietal cortex': 11,\n",
       " 'dipeptidyl peptidase': 12,\n",
       " 'high protein diet': 13,\n",
       " 'dietinduced obesity': 14,\n",
       " 'inferior olive': 15,\n",
       " 'typical development': 16,\n",
       " 'graft': 17,\n",
       " 'neurosecretory': 18,\n",
       " 'endothelial cell monolayers': 19,\n",
       " 'quantitative polymerase chain reaction': 20,\n",
       " 'intragastric': 21,\n",
       " 'sympathectomized': 22,\n",
       " 'extracellular matrix components': 23,\n",
       " 'leukemia cells': 24,\n",
       " 'pseudopregnancy': 25,\n",
       " 'subretinal fluid': 26,\n",
       " 'adrenal medulla': 27,\n",
       " 'interstitial cystitis': 28,\n",
       " 'methyl methanesulfonate': 29,\n",
       " 'highly polymorphic': 30,\n",
       " 'oxidized': 31,\n",
       " 'multislice ct': 32,\n",
       " 'pars plana vitrectomy': 33,\n",
       " 'dim light': 34,\n",
       " 'diazoxide': 35,\n",
       " 'interacting protein': 36,\n",
       " 'peak force': 37,\n",
       " 'tetrahydrofuran': 38,\n",
       " 'alveolar bone loss': 39,\n",
       " 'methyl orange': 40,\n",
       " 'postexposure': 41,\n",
       " 'best supportive care': 42,\n",
       " 'nicotine': 43,\n",
       " 'recovery': 44,\n",
       " 'liver parenchymal cells': 45,\n",
       " 'phytosterols': 46,\n",
       " 'covalent binding': 47,\n",
       " 'pulse pressure': 48,\n",
       " 'days of incubation': 49,\n",
       " 'overshoot': 50,\n",
       " 'mycobacterium bovis': 51,\n",
       " 'proton transfer': 52,\n",
       " 'receptorinteracting protein': 53,\n",
       " 'tributyrin': 54,\n",
       " 'light microscopic': 55,\n",
       " 'trapezoid body': 56,\n",
       " 'second molar': 57,\n",
       " 'fluorescence microscopy': 58,\n",
       " 'ammoniaoxidizing bacteria': 59,\n",
       " 'fetal thymus': 60,\n",
       " 'pseudorabies': 61,\n",
       " 'stearoylcoa desaturase': 62,\n",
       " 'aldehyde oxidase': 63,\n",
       " 'opsonized zymosan': 64,\n",
       " 'lateral rectus': 65,\n",
       " 'rheumatoid': 66,\n",
       " 'visual cortex': 67,\n",
       " 'conditioned responses': 68,\n",
       " 'proteinprotein interaction': 69,\n",
       " 'cbl': 70,\n",
       " 'dermal papilla': 71,\n",
       " 'inferior alveolar nerve': 72,\n",
       " 'hiatal hernia': 73,\n",
       " 'variant angina': 74,\n",
       " 'doublestranded dna': 75,\n",
       " 'heavy drinkers': 76,\n",
       " 'immunological synapse': 77,\n",
       " 'tissue culture': 78,\n",
       " 'renal blood flow': 79,\n",
       " 'ovulation rate': 80,\n",
       " 'nicorandil': 81,\n",
       " 'retrovirus': 82,\n",
       " 'pairedpulse facilitation': 83,\n",
       " 'caspofungin': 84,\n",
       " 'iodine deficiency': 85,\n",
       " 'cell tumors': 86,\n",
       " 'hearing aids': 87,\n",
       " 'bronchopulmonary dysplasia': 88,\n",
       " 'stem cell': 89,\n",
       " 'endothelial cell dysfunction': 90,\n",
       " 'silica gel': 91,\n",
       " 'heterogeneous nuclear': 92,\n",
       " 'margin': 93,\n",
       " 'preferred direction': 94,\n",
       " 'respiratory epithelium': 95,\n",
       " 'peak bone mass': 96,\n",
       " 'patients with acute myocardial infarction': 97,\n",
       " 'differential display': 98,\n",
       " 'superior laryngeal': 99,\n",
       " 'adductor pollicis': 100,\n",
       " 'nomeganitrolarginine': 101,\n",
       " 'common mental disorders': 102,\n",
       " 'major histocompatibility': 103,\n",
       " 'acute myeloid': 104,\n",
       " 'methadone': 105,\n",
       " 'inferior oblique': 106,\n",
       " 'postvaccination': 107,\n",
       " 'chemiluminescent': 108,\n",
       " 'cricothyroid': 109,\n",
       " 'cognitivebehavioral': 110,\n",
       " 'electronmicroscopy': 111,\n",
       " 'annulus fibrosus': 112,\n",
       " 'rift valley fever': 113,\n",
       " 'tibial nerve': 114,\n",
       " 'spindle assembly checkpoint': 115,\n",
       " 'artemether': 116,\n",
       " 'iliac crest': 117,\n",
       " 'respiratory chain': 118,\n",
       " 'brassinosteroid': 119,\n",
       " 'vascular endothelial': 120,\n",
       " 'correspondence analysis': 121,\n",
       " 'meningococcal disease': 122,\n",
       " 'drosophila melanogaster': 123,\n",
       " 'pharyngoesophageal': 124,\n",
       " 'round window': 125,\n",
       " 'cutaneous leishmaniasis': 126,\n",
       " 'singlechain antibody': 127,\n",
       " 'holliday junction': 128,\n",
       " 'cardiac transplantation': 129,\n",
       " 'global cerebral ischemia': 130,\n",
       " 'resiniferatoxin': 131,\n",
       " 'fractional shortening': 132,\n",
       " 'cardiac rupture': 133,\n",
       " 'hypersensitive response': 134,\n",
       " 'sites': 135,\n",
       " 'primary pulmonary hypertension': 136,\n",
       " 'periventricular leukomalacia': 137,\n",
       " 'sacroiliac': 138,\n",
       " 'ketopgf alpha': 139,\n",
       " 'tuberculin skin test': 140,\n",
       " 'displacement': 141,\n",
       " 'chelating agent': 142,\n",
       " 'pulmonary sequestration': 143,\n",
       " 'human endothelial cells': 144,\n",
       " 'kidney cells': 145,\n",
       " 'pronuclear': 146,\n",
       " 'logistic regression': 147,\n",
       " 'arachidonoylglycerol': 148,\n",
       " 'backpropagation': 149,\n",
       " 'mosaic virus': 150,\n",
       " 'working memory': 151,\n",
       " 'phenothiazine': 152,\n",
       " 'luminal epithelial': 153,\n",
       " 'aminoglutethimide': 154,\n",
       " 'chemiluminescence': 155,\n",
       " 'gonadotrophin': 156,\n",
       " 'ecadherin': 157,\n",
       " 'recurrent abdominal pain': 158,\n",
       " 'electron transport system': 159,\n",
       " 'tracheobronchial': 160,\n",
       " 'mean platelet volume': 161,\n",
       " 'stress echocardiography': 162,\n",
       " 'stomach cancer': 163,\n",
       " 'position effect': 164,\n",
       " 'venous outflow': 165,\n",
       " 'neuroleptic malignant syndrome': 166,\n",
       " 'gonadotropic': 167,\n",
       " 'reciprocal translocations': 168,\n",
       " 'unbound fraction': 169,\n",
       " 'monozygotic': 170,\n",
       " 'homozygous deletion': 171,\n",
       " 'nitrocellulose membrane': 172,\n",
       " 'tibiofemoral': 173,\n",
       " 'olfactory nerve': 174,\n",
       " 'response times': 175,\n",
       " 'chronic granulomatous disease': 176,\n",
       " 'enteral nutrition': 177,\n",
       " 'bovine tuberculosis': 178,\n",
       " 'homologous': 179,\n",
       " 'computed tomography scanning': 180,\n",
       " 'picosecond': 181,\n",
       " 'pulmonary metastases': 182,\n",
       " 'capsid': 183,\n",
       " 'amlodipine': 184,\n",
       " 'left ventricular systolic function': 185,\n",
       " 'arachidonic': 186,\n",
       " 'normal liver': 187,\n",
       " 'conscious sedation': 188,\n",
       " 'left ventricular dysfunction': 189,\n",
       " 'renal artery stenosis': 190,\n",
       " 'liquid crystalline': 191,\n",
       " 'dopa decarboxylase': 192,\n",
       " 'walking test': 193,\n",
       " 'uric acid': 194,\n",
       " 'retrograde amnesia': 195,\n",
       " 'triolein': 196,\n",
       " 'metformin': 197,\n",
       " 'microcomputed tomography': 198,\n",
       " 'right ventricular pressure': 199,\n",
       " 'cabergoline': 200,\n",
       " 'mitotic activity': 201,\n",
       " 'ion trap mass spectrometer': 202,\n",
       " 'space flight': 203,\n",
       " 'videoassisted thoracic surgery': 204,\n",
       " 'metastasisfree survival': 205,\n",
       " 'recovery room': 206,\n",
       " 'cognitive therapy': 207,\n",
       " 'rubrospinal': 208,\n",
       " 'procainamide': 209,\n",
       " 'myosin heavy': 210,\n",
       " 'coronary artery calcification': 211,\n",
       " 'caloric restriction': 212,\n",
       " 'rat peritoneal mast cells': 213,\n",
       " 'dynamic exercise': 214,\n",
       " 'regression coefficient': 215,\n",
       " 'highresolution transmission electron microscopy': 216,\n",
       " 'tumors': 217,\n",
       " 'major histocompatibility complex class i': 218,\n",
       " 'great saphenous vein': 219,\n",
       " 'scanning tunneling microscope': 220,\n",
       " 'epidural morphine': 221,\n",
       " 'electrophoretic mobility shift assays': 222,\n",
       " 'handgrip': 223,\n",
       " 'lung transplant recipients': 224,\n",
       " 'low anterior resection': 225,\n",
       " 'normal women': 226,\n",
       " 'subsarcolemmal': 227,\n",
       " 'radial artery': 228,\n",
       " 'glycemic index': 229,\n",
       " 'longissimus dorsi': 230,\n",
       " 'intrauterine pregnancy': 231,\n",
       " 'episodic memory': 232,\n",
       " 'farinfrared': 233,\n",
       " 'pulmonary fibrosis': 234,\n",
       " 'molecular beacon': 235,\n",
       " 'blood plasma': 236,\n",
       " 'diffuse alveolar damage': 237,\n",
       " 'autonomic blockade': 238,\n",
       " 'levels': 239,\n",
       " 'pulmonary embolus': 240,\n",
       " 'neck dissection': 241,\n",
       " 'hip dysplasia': 242,\n",
       " 'microscope': 243,\n",
       " 'estradiolbeta': 244,\n",
       " 'insulin gene': 245,\n",
       " 'sea surface temperature': 246,\n",
       " 'propylene glycol': 247,\n",
       " 'duodenal': 248,\n",
       " 'common peroneal nerve': 249,\n",
       " 'longterm survivors': 250,\n",
       " 'cytomegalovirus infection': 251,\n",
       " 'tunicamycin': 252,\n",
       " 'hypothalamicpituitaryadrenal axis': 253,\n",
       " 'polyelectrolyte': 254,\n",
       " 'milliseconds': 255,\n",
       " 'o delivery': 256,\n",
       " 'supercritical fluid': 257,\n",
       " 'primary health care': 258,\n",
       " 'sesquiterpene lactones': 259,\n",
       " 'hexosaminidase': 260,\n",
       " 'aortic diameter': 261,\n",
       " 'insulindependent diabetes mellitus': 262,\n",
       " 'emergency physician': 263,\n",
       " 'mantelhaenszel': 264,\n",
       " 'lichen planus': 265,\n",
       " 'hemodialyzed': 266,\n",
       " 'isoelectrofocusing': 267,\n",
       " 'drug user': 268,\n",
       " 'peak plasma concentration': 269,\n",
       " 'epinephrine': 270,\n",
       " 'postimmunization': 271,\n",
       " 'recombinant human bone morphogenetic protein': 272,\n",
       " 'serum folate': 273,\n",
       " 'permeability transition pore': 274,\n",
       " 'proteases': 275,\n",
       " 'dorsal motor nucleus': 276,\n",
       " 'spondyloarthropathies': 277,\n",
       " 'lung compliance': 278,\n",
       " 'infant mortality': 279,\n",
       " 'nadh dehydrogenase': 280,\n",
       " 'h after inoculation': 281,\n",
       " 'retinal nerve fiber layer': 282,\n",
       " 'fructosebisphosphatase': 283,\n",
       " 'food deprivation': 284,\n",
       " 'maintenance hemodialysis': 285,\n",
       " 'glycogen synthase': 286,\n",
       " 'visceral adipose tissue': 287,\n",
       " 'multidimensional scaling': 288,\n",
       " 'innominate artery': 289,\n",
       " 'lanreotide': 290,\n",
       " 'placebo': 291,\n",
       " 'head kidney': 292,\n",
       " 'complementary medicine': 293,\n",
       " 'congenital heart diseases': 294,\n",
       " 'vasovagal syncope': 295,\n",
       " 'vaginal hysterectomy': 296,\n",
       " 'acute lymphocytic': 297,\n",
       " 'mammalian': 298,\n",
       " 'helical computed tomography': 299,\n",
       " 'occupational health': 300,\n",
       " 'gonadal dysgenesis': 301,\n",
       " 'eosinophilic esophagitis': 302,\n",
       " 'feed consumption': 303,\n",
       " 'disintegrin and metalloproteinase': 304,\n",
       " 'serum uric acid': 305,\n",
       " 'chronic disorders': 306,\n",
       " 'bandwidth': 307,\n",
       " 'power density': 308,\n",
       " 'public health service': 309,\n",
       " 'basic life support': 310,\n",
       " 'physiologically based pharmacokinetic': 311,\n",
       " 'verbal fluency': 312,\n",
       " 'mechanosensitive': 313,\n",
       " 'celiac trunk': 314,\n",
       " 'corneal endothelial': 315,\n",
       " 'ca channels': 316,\n",
       " 'peptic ulcer': 317,\n",
       " 'posterolateral': 318,\n",
       " 'immediate breast reconstruction': 319,\n",
       " 'alternative pathway': 320,\n",
       " 'internal anal sphincter': 321,\n",
       " 'hemoglobin s': 322,\n",
       " 'cerebrospinal': 323,\n",
       " 'neuroblastoma cells': 324,\n",
       " 'metastatic disease': 325,\n",
       " 'left pulmonary artery': 326,\n",
       " 'coronary artery occlusion': 327,\n",
       " 'atherosclerotic': 328,\n",
       " 'macrophage migration inhibitory factor': 329,\n",
       " 'pattern': 330,\n",
       " 'binding potential': 331,\n",
       " 'resident peritoneal macrophages': 332,\n",
       " 'olfactory receptor': 333,\n",
       " 'prosthetic valve endocarditis': 334,\n",
       " 'chemoembolization': 335,\n",
       " 'alcoholic liver disease': 336,\n",
       " 'cation exchange capacity': 337,\n",
       " 'confocal laser scanning microscopy': 338,\n",
       " 'pnitrophenol': 339,\n",
       " 'lymphoblastoid cells': 340,\n",
       " 'anterior chamber depth': 341,\n",
       " 'pancreastatin': 342,\n",
       " 'acute exacerbation': 343,\n",
       " 'integral membrane proteins': 344,\n",
       " 'galactomannan': 345,\n",
       " 'antireflux surgery': 346,\n",
       " 'short bowel syndrome': 347,\n",
       " 'placebocontrolled trials': 348,\n",
       " 'bacterial translocation': 349,\n",
       " 'histocompatibility': 350,\n",
       " 'intervention group': 351,\n",
       " 'methanolic extract': 352,\n",
       " 'tetracyclines': 353,\n",
       " 'mesalazine': 354,\n",
       " 'medical outcomes study': 355,\n",
       " 'bed rest': 356,\n",
       " 'dry eye syndrome': 357,\n",
       " 'deep cerebellar nuclei': 358,\n",
       " 'adenocarcinoma of the lung': 359,\n",
       " 'blast crisis': 360,\n",
       " 'biochemical': 361,\n",
       " 'methylglyoxal': 362,\n",
       " 'insulindependent diabetes': 363,\n",
       " 'thyroid gland': 364,\n",
       " 'mmp inhibitors': 365,\n",
       " 'middle temporal': 366,\n",
       " 'antidiuretic': 367,\n",
       " 'ultrafiltration': 368,\n",
       " 'opioid receptors': 369,\n",
       " 'tropomyosin': 370,\n",
       " 'cumulative dose': 371,\n",
       " 'bundle sheath': 372,\n",
       " 'assisted living': 373,\n",
       " 'quaternary ammonium': 374,\n",
       " 'total p': 375,\n",
       " 'universal precautions': 376,\n",
       " 'agonist quinpirole': 377,\n",
       " 'serotonin receptor': 378,\n",
       " 'nethylmaleimidesensitive factor': 379,\n",
       " 'vitro stimulation': 380,\n",
       " 'noonan syndrome': 381,\n",
       " 'contrastenhanced computed tomography': 382,\n",
       " 'positive ion': 383,\n",
       " 'osmotic pressure': 384,\n",
       " 'polyhedrin': 385,\n",
       " 'multivessel disease': 386,\n",
       " 'external rotation': 387,\n",
       " 'saturation transfer': 388,\n",
       " 'former smokers': 389,\n",
       " 'hivinfected': 390,\n",
       " 'physiotherapy': 391,\n",
       " 'tetratricopeptide': 392,\n",
       " 'elementary bodies': 393,\n",
       " 'phosphate buffer solution': 394,\n",
       " 'rejection': 395,\n",
       " 'patellar tendon': 396,\n",
       " 'tuning curves': 397,\n",
       " 'infection control': 398,\n",
       " 'plasmodium berghei': 399,\n",
       " 'stable disease': 400,\n",
       " 'abscisic acid': 401,\n",
       " 'biochemical response': 402,\n",
       " 'mixed cellularity': 403,\n",
       " 'chest roentgenogram': 404,\n",
       " 'rapid prototyping': 405,\n",
       " 'laparoscopic radical prostatectomy': 406,\n",
       " 'glass ionomer cement': 407,\n",
       " 'gabapentin': 408,\n",
       " 'regulatory domain': 409,\n",
       " 'achilles tendon': 410,\n",
       " 'acanthamoeba keratitis': 411,\n",
       " 'bone marrow involvement': 412,\n",
       " 'dobutamine stress echocardiography': 413,\n",
       " 'intermetatarsal': 414,\n",
       " 'soybean agglutinin': 415,\n",
       " 'visual analogue': 416,\n",
       " 'connective tissue diseases': 417,\n",
       " 'right': 418,\n",
       " 'exerciseinduced asthma': 419,\n",
       " 'pegylated': 420,\n",
       " 'posterior tibial nerve': 421,\n",
       " 'flow cytometry': 422,\n",
       " 'surface charge density': 423,\n",
       " 'migration inhibition': 424,\n",
       " 'erythrocyte aggregation': 425,\n",
       " 'lincomycin': 426,\n",
       " 'autologous bmt': 427,\n",
       " 'transactivation': 428,\n",
       " 'discriminant function': 429,\n",
       " 'subclavian vein': 430,\n",
       " 'bismuth': 431,\n",
       " 'encapsulation efficiency': 432,\n",
       " 'hyperparathyroidism': 433,\n",
       " 'cerebral perfusion': 434,\n",
       " 'granulation tissue': 435,\n",
       " 'triglyceride levels': 436,\n",
       " 'active oxygen': 437,\n",
       " 'calorie restriction': 438,\n",
       " 'dissolved organic carbon': 439,\n",
       " 'corrected': 440,\n",
       " 'corticospinal tract': 441,\n",
       " 'lyme arthritis': 442,\n",
       " 'papillary thyroid carcinomas': 443,\n",
       " 'action potential amplitude': 444,\n",
       " 'costeffectiveness analysis': 445,\n",
       " 'cytotoxicsuppressor': 446,\n",
       " 'hydroalcoholic extract': 447,\n",
       " 'aberrant crypt foci': 448,\n",
       " 'population growth rate': 449,\n",
       " 'pulmonary emboli': 450,\n",
       " 'nucleotide phosphodiesterase': 451,\n",
       " 'recombinant human growth hormone': 452,\n",
       " 'cortical plate': 453,\n",
       " 'immunohistochemical analysis': 454,\n",
       " 'polypropylene mesh': 455,\n",
       " 'shortaxis': 456,\n",
       " 'distal radius': 457,\n",
       " 'adrenocortical carcinoma': 458,\n",
       " 'lateral wall': 459,\n",
       " 'follicular carcinomas': 460,\n",
       " 'folinic acid': 461,\n",
       " 'stride length': 462,\n",
       " 'freunds complete adjuvant': 463,\n",
       " 'hexobarbital': 464,\n",
       " 'proximal tubule': 465,\n",
       " 'capsular polysaccharides': 466,\n",
       " 'ionizing irradiation': 467,\n",
       " 'prostate brachytherapy': 468,\n",
       " 'intraabdominal abscess': 469,\n",
       " 'ang ii receptor': 470,\n",
       " 'agematched controls': 471,\n",
       " 'salmon calcitonin': 472,\n",
       " 'parathormone': 473,\n",
       " 'social isolation': 474,\n",
       " 'thiotepa': 475,\n",
       " 'ornithine decarboxylase activity': 476,\n",
       " 'invasive pneumococcal disease': 477,\n",
       " 'posterior cranial fossa': 478,\n",
       " 'noncompetitive': 479,\n",
       " 'cancer': 480,\n",
       " 'egg count': 481,\n",
       " 'electrophysiologic': 482,\n",
       " 'postmortem interval': 483,\n",
       " 'family physicians': 484,\n",
       " 'herpes simplex encephalitis': 485,\n",
       " 'trabecular bone volume': 486,\n",
       " 'kynurenine pathway': 487,\n",
       " 'congestive cardiac failure': 488,\n",
       " 'breast cancer survivors': 489,\n",
       " 'chemotaxis': 490,\n",
       " 'normal brain tissue': 491,\n",
       " 'frontal lobe': 492,\n",
       " 'carpal tunnel syndrome': 493,\n",
       " 'type ii collagen': 494,\n",
       " 'information systems': 495,\n",
       " 'mediobasal hypothalamus': 496,\n",
       " 'ventromedial hypothalamic': 497,\n",
       " 'tantalum': 498,\n",
       " 'organizing pneumonia': 499,\n",
       " 'immunodiffusion': 500,\n",
       " 'breeding values': 501,\n",
       " 'chemical warfare': 502,\n",
       " 'cochlear implantation': 503,\n",
       " 'acute heart failure': 504,\n",
       " 'attenuation coefficient': 505,\n",
       " 'gemfibrozil': 506,\n",
       " 'vaccine effectiveness': 507,\n",
       " 'cardiac magnetic resonance': 508,\n",
       " 'human colon adenocarcinoma': 509,\n",
       " 'inhibitory': 510,\n",
       " 'periaqueductal grey': 511,\n",
       " 'cold pressor test': 512,\n",
       " 'megavoltage': 513,\n",
       " 'nuclear transfer': 514,\n",
       " 'bone loss': 515,\n",
       " 'cervical cancer': 516,\n",
       " 'pulsed doppler': 517,\n",
       " 'posterior cingulate cortex': 518,\n",
       " 'histidine kinase': 519,\n",
       " 'primary progressive': 520,\n",
       " 'friedreichs ataxia': 521,\n",
       " 'tensile strength': 522,\n",
       " 'chest radiographs': 523,\n",
       " 'insertion loss': 524,\n",
       " 'general surgery': 525,\n",
       " 'egg weight': 526,\n",
       " 'serial analysis of gene expression': 527,\n",
       " 'lens culinaris': 528,\n",
       " 'bacitracin': 529,\n",
       " 'geometric means': 530,\n",
       " 'anterior horn': 531,\n",
       " 'czech republic': 532,\n",
       " 'inflammatory myopathy': 533,\n",
       " 'articular cartilage': 534,\n",
       " 'methadone maintenance': 535,\n",
       " 'primary myelofibrosis': 536,\n",
       " 'plasmodesmata': 537,\n",
       " 'estrogen receptors': 538,\n",
       " 'total gastrectomy': 539,\n",
       " 'resistant starch': 540,\n",
       " 'dorsal horn': 541,\n",
       " 'twitch force': 542,\n",
       " 'serumfree media': 543,\n",
       " 'western australia': 544,\n",
       " 'hemagglutinating': 545,\n",
       " 'epicatechin': 546,\n",
       " 'placental lactogen': 547,\n",
       " 'brain stem': 548,\n",
       " 'serumfree': 549,\n",
       " 'transfer function': 550,\n",
       " 'neurocysticercosis': 551,\n",
       " 'early follicular': 552,\n",
       " 'intraabdominal': 553,\n",
       " 'japanese encephalitis': 554,\n",
       " 'functional class': 555,\n",
       " 'continuity of care': 556,\n",
       " 'lactic acidosis': 557,\n",
       " 'isocyanate': 558,\n",
       " 'longterm retention': 559,\n",
       " 'internal transcribed spacer region': 560,\n",
       " 'urinary volume': 561,\n",
       " 'lymphoblastoid': 562,\n",
       " 'reninangiotensinaldosterone': 563,\n",
       " 'hepatitis': 564,\n",
       " 'renal dysfunction': 565,\n",
       " 'antigen receptors': 566,\n",
       " 'external anal sphincter': 567,\n",
       " 'superior temporal sulcus': 568,\n",
       " 'motivational interviewing': 569,\n",
       " 'extent of absorption': 570,\n",
       " 'proliferative index': 571,\n",
       " 'water immersion': 572,\n",
       " 'spiral ganglion': 573,\n",
       " 'clinical examination': 574,\n",
       " 'pregnancy rates': 575,\n",
       " 'polymerase chain reaction method': 576,\n",
       " 'health promotion': 577,\n",
       " 'hexagonal phase': 578,\n",
       " 'acute pyelonephritis': 579,\n",
       " 'electron capture': 580,\n",
       " 'lewis': 581,\n",
       " 'acute ischaemic stroke': 582,\n",
       " 'truncal vagotomy': 583,\n",
       " 'bone scan': 584,\n",
       " 'fetal growth retardation': 585,\n",
       " 'uterine contractions': 586,\n",
       " 'basal lamina': 587,\n",
       " 'anaplastic lymphoma kinase': 588,\n",
       " 'total testosterone': 589,\n",
       " 'transgenic mouse': 590,\n",
       " 'dinitrophenyl': 591,\n",
       " 'general': 592,\n",
       " 'degree of conversion': 593,\n",
       " 'melaninconcentrating hormone': 594,\n",
       " 'antimicrobial peptide': 595,\n",
       " 'endometrial hyperplasia': 596,\n",
       " 'moderately differentiated': 597,\n",
       " 'marfan syndrome': 598,\n",
       " 'leukocytes': 599,\n",
       " 'peptide mass fingerprinting': 600,\n",
       " 'protein data bank': 601,\n",
       " 'tridimensional': 602,\n",
       " 'indapamide': 603,\n",
       " 'wiskottaldrich syndrome': 604,\n",
       " 'border zone': 605,\n",
       " 'vascular': 606,\n",
       " 'patientcentered care': 607,\n",
       " 'men who have sex with men': 608,\n",
       " 'myoelectric': 609,\n",
       " 'f hybrid': 610,\n",
       " 'tricyclic antidepressants': 611,\n",
       " 'molybdenum': 612,\n",
       " 'fibres': 613,\n",
       " 'gibberellin': 614,\n",
       " 'maximal exercise': 615,\n",
       " 'prefrontal cortical': 616,\n",
       " 'bipolar i': 617,\n",
       " 'power spectra': 618,\n",
       " 'antisense oligonucleotide': 619,\n",
       " 'chronic constriction injury': 620,\n",
       " 'granulocyte colony stimulating factor': 621,\n",
       " 'flip angle': 622,\n",
       " 'high cholesterol': 623,\n",
       " 'light microscopy': 624,\n",
       " 'ventral prostate': 625,\n",
       " 'cluster analysis': 626,\n",
       " 'reference group': 627,\n",
       " 'days after birth': 628,\n",
       " 'electroretinographic': 629,\n",
       " 'soil organic carbon': 630,\n",
       " 'tyrosine': 631,\n",
       " 'fulllength': 632,\n",
       " 'suppressorcytotoxic': 633,\n",
       " 'low malignant potential': 634,\n",
       " 'perchloric acid': 635,\n",
       " 'neurohypophysis': 636,\n",
       " 'avian myeloblastosis virus': 637,\n",
       " 'genetically obese': 638,\n",
       " 'erythema multiforme': 639,\n",
       " 'haemofiltration': 640,\n",
       " 'bundle branch block': 641,\n",
       " 'melting points': 642,\n",
       " 'balloon pump': 643,\n",
       " 'protein gene product': 644,\n",
       " 'photofrin': 645,\n",
       " 'protein synthesis inhibitor cycloheximide': 646,\n",
       " 'methadone maintenance treatment': 647,\n",
       " 'peak amplitude': 648,\n",
       " 'cervical spondylotic myelopathy': 649,\n",
       " 'negative symptoms': 650,\n",
       " 'body height': 651,\n",
       " 'tindependent': 652,\n",
       " 'conformal radiotherapy': 653,\n",
       " 'contrastenhanced ct': 654,\n",
       " 'aminoglycoside antibiotics': 655,\n",
       " 'central corneal thickness': 656,\n",
       " 'particle size distribution': 657,\n",
       " 'envelope': 658,\n",
       " 'erythema nodosum': 659,\n",
       " 'good recovery': 660,\n",
       " 'streptococcus agalactiae': 661,\n",
       " 'black carbon': 662,\n",
       " 'trypsin': 663,\n",
       " 'preeclamptic': 664,\n",
       " 'alternative splicing': 665,\n",
       " 'olfactory bulbs': 666,\n",
       " 'unresponsiveness': 667,\n",
       " 'digital image analysis': 668,\n",
       " 'culture filtrate': 669,\n",
       " 'treatment group': 670,\n",
       " 'schizosaccharomyces pombe': 671,\n",
       " 'solubilization': 672,\n",
       " 'pulmonary tb': 673,\n",
       " 'dentate gyrus': 674,\n",
       " 'surgical intensive care unit': 675,\n",
       " 'blunt abdominal trauma': 676,\n",
       " 'haemagglutination': 677,\n",
       " 'transplanted': 678,\n",
       " 'microcrystalline cellulose': 679,\n",
       " 'main pancreatic duct': 680,\n",
       " 'gross domestic product': 681,\n",
       " 'cardiac tamponade': 682,\n",
       " 'electrically stimulated': 683,\n",
       " 'choanal atresia': 684,\n",
       " 'immunocompromised patients': 685,\n",
       " 'personal protective equipment': 686,\n",
       " 'bleeding time': 687,\n",
       " 'lowdensity lipoproteins': 688,\n",
       " 'betahemolytic streptococci': 689}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_ids = {k: v for v, k in enumerate(data2.label.unique())}\n",
    "ids_to_labels = {v: k for v, k in enumerate(data2.label.unique())}\n",
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "a2Ke3SDe87X_",
    "outputId": "a0ef416e-9e6a-44d4-b214-fa759a9e710c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence:0</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence:0</td>\n",
       "      <td>xlnd</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence:0</td>\n",
       "      <td>gene</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence:0</td>\n",
       "      <td>from</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence:0</td>\n",
       "      <td>pseudomonas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18061435</th>\n",
       "      <td>Sentence:102261</td>\n",
       "      <td>brain</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18061436</th>\n",
       "      <td>Sentence:102261</td>\n",
       "      <td>vitality</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18061437</th>\n",
       "      <td>Sentence:102261</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18061438</th>\n",
       "      <td>Sentence:102261</td>\n",
       "      <td>productive</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18061439</th>\n",
       "      <td>Sentence:102261</td>\n",
       "      <td>lifespan</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18061440 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              sentence_id         word label\n",
       "0              Sentence:0          the     O\n",
       "1              Sentence:0         xlnd     O\n",
       "2              Sentence:0         gene     O\n",
       "3              Sentence:0         from     O\n",
       "4              Sentence:0  pseudomonas     O\n",
       "...                   ...          ...   ...\n",
       "18061435  Sentence:102261        brain     O\n",
       "18061436  Sentence:102261     vitality     O\n",
       "18061437  Sentence:102261          and     O\n",
       "18061438  Sentence:102261   productive     O\n",
       "18061439  Sentence:102261     lifespan     O\n",
       "\n",
       "[18061440 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "biu1fs69eLVH"
   },
   "outputs": [],
   "source": [
    "labels = list(data2.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GIsx_Mfw8_LU",
    "outputId": "dfde5f05-af62-4d1f-9309-f9aa6edaa50b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence:0</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>the xlnd gene from pseudomonas alcaligenes nci...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence:0</td>\n",
       "      <td>xlnd</td>\n",
       "      <td>O</td>\n",
       "      <td>the xlnd gene from pseudomonas alcaligenes nci...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence:0</td>\n",
       "      <td>gene</td>\n",
       "      <td>O</td>\n",
       "      <td>the xlnd gene from pseudomonas alcaligenes nci...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence:0</td>\n",
       "      <td>from</td>\n",
       "      <td>O</td>\n",
       "      <td>the xlnd gene from pseudomonas alcaligenes nci...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence:0</td>\n",
       "      <td>pseudomonas</td>\n",
       "      <td>O</td>\n",
       "      <td>the xlnd gene from pseudomonas alcaligenes nci...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id         word label  \\\n",
       "0  Sentence:0          the     O   \n",
       "1  Sentence:0         xlnd     O   \n",
       "2  Sentence:0         gene     O   \n",
       "3  Sentence:0         from     O   \n",
       "4  Sentence:0  pseudomonas     O   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  the xlnd gene from pseudomonas alcaligenes nci...   \n",
       "1  the xlnd gene from pseudomonas alcaligenes nci...   \n",
       "2  the xlnd gene from pseudomonas alcaligenes nci...   \n",
       "3  the xlnd gene from pseudomonas alcaligenes nci...   \n",
       "4  the xlnd gene from pseudomonas alcaligenes nci...   \n",
       "\n",
       "                                         word_labels  \n",
       "0  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "1  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "2  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "3  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "4  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new column called \"sentence\" which groups the words by sentence \n",
    "data2['sentence'] = data2[['sentence_id','word','label']].groupby(['sentence_id'])['word'].transform(lambda x: ' '.join(map(str, x)))\n",
    "# create a new column called \"word_labels\" which groups the tags by sentence \n",
    "data2['word_labels'] = data2[['sentence_id','word','label']].groupby(['sentence_id'])['label'].transform(lambda x: ','.join(map(str,x)))\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Rg2_-0uU9pH1",
    "outputId": "2a6354d8-1975-4cfd-ce00-6ca0c784c027"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the xlnd gene from pseudomonas alcaligenes nci...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dilatation of the ascending aorta tends to dev...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,aortic valve disease,O,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the histamineh receptor blocking properties of...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rnainduced silencing complex risc is a small R...</td>\n",
       "      <td>O,O,O,O,O,O,O,rnaprotein,O,O,O,O,O,O,O,O,O,O,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in the first half of this century cardiovascul...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  the xlnd gene from pseudomonas alcaligenes nci...   \n",
       "1  dilatation of the ascending aorta tends to dev...   \n",
       "2  the histamineh receptor blocking properties of...   \n",
       "3  rnainduced silencing complex risc is a small R...   \n",
       "4  in the first half of this century cardiovascul...   \n",
       "\n",
       "                                         word_labels  \n",
       "0  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "1  O,O,O,O,O,O,O,O,O,O,O,aortic valve disease,O,O...  \n",
       "2  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "3  O,O,O,O,O,O,O,rnaprotein,O,O,O,O,O,O,O,O,O,O,O...  \n",
       "4  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = data2[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "glmKBSBGLI9D",
    "outputId": "761488d8-b3f9-4f5a-e6ea-8c436c0c709d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102262"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data2)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "p1TV_AexLO_0",
    "outputId": "a194bbc4-2830-407f-92fd-50ad4299c704"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'three kinds of nanosilver colloids have been prepared by electrolysis of silver rod using sodium citrate solution and agno mixed with polyvinyl alcohol solution as electrolyte and applying v direct current for one hour nanosilver colloids have been investigated by means of tem absorption spectrum electrophoresis experiment and sers the particle size ranges roughly from nm to nm spheroid for sample from nm to nm spheroid for sample and from to manysided for sample featuring absorption maximum at and nm respectively the surface charge of these three kinds of colloidal silver particles is positive in order to test if these nanosilver colloids can be used for sers research the cationic molecular fuchsine basic methylene blue anionic molecular BA MO neutral molecular alcidine orange and sudan red were used it was found that these nanosilver colloids have strong sers activity furthermore the nanosilver colloids that used agno mixed with PVA solution as electrolyte has the strongest sers activity among all the tested molecules the sers of MO has been obtained on the nanosilver colloids which has not been obtaind on the colloids prepared by electrolysis of silver rod using sodium citrate solution and on the gray and yellow silver colloids prepared by traditional means the possible reason has been explained one L1 advantage of this method using agno mixed with polyvinyl alcohol solution as electrolyte is the absence of the spectral interference'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.iloc[41].sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "Xur9NEF3LSes",
    "outputId": "7634464a-11fe-4cfd-c22a-7a38d49df235"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,methyl orange,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.iloc[41].word_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "b51fbdaa86f9462bac966aa8167d7bf3",
      "2abdc206698b4c6eae3e9aadb82891e8",
      "d6f543a965c6445cacb6c3b71293301b",
      "9677a938913941198cebb0bf76b7a57b",
      "f502b4e1d5b04f498781c17593925c5a",
      "9eec38e5e7cf4c1bb94ffc2c813ed4ae",
      "97566bd57258417490704690e66db5ce",
      "75949b69e7a447b4bd37de56b54b5225",
      "0ccab1927a624d6194a3bdb2f6fdbe46",
      "6a44c7ad03e442b68284a30da2d3b310",
      "c8cd176682b74bffbfb964d8681752fc",
      "b365473f00954e5db97592f213c32aae",
      "c08f9b2730274e8abfc6e942208964bb",
      "91095500ddd247ad8fcc95038e5e2f75",
      "83f9b1c8b58d4b6bbc94983c8d78a3fd",
      "df05cbdbb56c4ae590f9489f01c4cb29",
      "524e576b7c934eb4ba1c8e8c12cfe75f",
      "c53cb709e9a54595b5a8fc51ea3924b5",
      "771bda931edf422aa5a2ac077f961266",
      "0449ee29b8be40359e5dec1055689664",
      "3de0161dfd3a4356be21de12a3dd8761",
      "65c848f9d382415885bc02b86d9eb805",
      "cfd1c557cd7c423bbb61e1bc011a3d22",
      "5c5a1716f3bb41c987b3f68714a5f862",
      "8ea6cdfda386407ebcb48692261b9c8c",
      "db13f9dab0564e99810569af3c8b5492",
      "17e55f8b4a4b4515b8df0154a1caf1ed",
      "162cc643970248e1a90f95b32051e09e",
      "580b262793ee4c59b142bf471d5b6416",
      "58c7ff4f1b64478f80e3a3e7e7f025d1",
      "6c19b280e0f24471a25e21e40520471c",
      "a66b80c0d2474bd88fa3f853d658c4b0",
      "2b91c34758c241ac8f649d34c7cc1c7c",
      "846d46fdd2864b2ba151997f3b5234a3",
      "494159e2c4c44a5fb9bb9b3cb458683b",
      "0beb39391dad46a58061b5005bfe05a3",
      "97b6c10a1e084cfc8930cdf9392659fa",
      "057afc3f1bf0472a93fb85c04e983f86",
      "2de4114a6daf430e81f40e11b0b8d7fd",
      "ed75b579b0254b4f866ac91c3af65e5f",
      "f1ed178a8643407f9c041b0cb4d31485",
      "e471753f4232433e97df92fbe99b3c25",
      "7f54a3d1429145c18eb30fb422b8da1d",
      "65435ff608704501a710839c7cca7e17"
     ]
    },
    "id": "LdENbXWSRvBC",
    "outputId": "7cce1a39-4e29-486f-f4b5-b7a439201afe"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 320\n",
    "TRAIN_BATCH_SIZE = 2\n",
    "VALID_BATCH_SIZE = 1\n",
    "EPOCHS = 4\n",
    "MAX_GRAD_NORM = 10\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "4fqOEXK0R3gC"
   },
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "  def __init__(self, dataframe,labels, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        # step 1: get the sentence and word labels \n",
    "        sentence = self.data.sentence[index].strip()\n",
    "        word_labels = self.data.word_labels[index].split(\",\") \n",
    "\n",
    "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
    "        encoding = self.tokenizer(sentence,\n",
    "#                              is_split_into_words=True, \n",
    "                             add_special_tokens=True,\n",
    "                             return_offsets_mapping=True, \n",
    "                             max_length=self.max_len,\n",
    "                             padding='max_length', \n",
    "                             truncation=True\n",
    "                             )\n",
    "        \n",
    "        # step 3: create token labels only for first word pieces of each tokenized word\n",
    "        labels = [labels_to_ids[label] for label in word_labels] \n",
    "        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n",
    "        # create an empty array of -100 of length max_length\n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "        # set only labels whose first offset position is 0 and the second is not 0\n",
    "        i = 0\n",
    "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "          if mapping[0] == 0 and mapping[1] != 0:\n",
    "            # overwrite label\n",
    "            encoded_labels[idx] = labels[i]\n",
    "            i += 1\n",
    "\n",
    "        # step 4: turn everything into PyTorch tensors\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "        \n",
    "        return item\n",
    "\n",
    "  def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define train-test split of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mWcwYA5bS0le",
    "outputId": "9be004e5-aa18-463d-999b-e3303792de1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (102262, 2)\n",
      "TRAIN Dataset: (76696, 2)\n",
      "TEST Dataset: (25566, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.75\n",
    "train_dataset = data2.sample(frac=train_size,random_state=105)\n",
    "test_dataset = data2.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data2.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset,labels, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset,labels, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentence, word_labels]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.drop(data2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "a7tOlybbTJoH"
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d7f9a1f407cf46af914bb869105e6f9a",
      "4556de712c6b43bb99b0611bfb053d21",
      "37ce0e7f681540f0b94db0b75b6fd65b",
      "cb6cc1e0796a4a578117fa91c7c1180f",
      "516c5340a9e94b8aaa22fbe44f80c9e3",
      "b6e9752a11a14bb4bd01de903ac0178d",
      "544f8855a35a4fc8a524f9c9c08cabbb",
      "dc754a57abc9410b8da5061c342a9cec",
      "d5097890e83844a6a30e5700fc61d40c",
      "fde608d7b6774909bc7df1895aabaaf9",
      "aeb2589b18b2404cbd1ba5d6fd40575c"
     ]
    },
    "id": "RK-1qdZb0TvY",
    "outputId": "847fed8a-14fc-44ba-e929-e9536a083e7c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=690, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(labels_to_ids))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "3J0pBYag4ej6"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "lJSv0eYQ0cTO"
   },
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "        loss = outputs[\"loss\"]\n",
    "        tr_logits = outputs[\"logits\"]\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        # print(idx)\n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "#         active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_labels.extend(labels)\n",
    "        tr_preds.extend(predictions)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "mCjyUnSS0i6A",
    "outputId": "f418a8bd-7c49-4ca9-b876-cdaf911b3896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------0-----------------------------------\n",
      "Training loss per 100 training steps: 6.7485809326171875\n",
      "Training loss per 100 training steps: 1.469690045175871\n",
      "Training loss per 100 training steps: 0.8731442134067491\n",
      "Training loss per 100 training steps: 0.6452785111976125\n",
      "Training loss per 100 training steps: 0.555087510315223\n",
      "Training loss per 100 training steps: 0.4853710846793271\n",
      "Training loss per 100 training steps: 0.4539186551596678\n",
      "Training loss per 100 training steps: 0.4157874948675937\n",
      "Training loss per 100 training steps: 0.3917693701426216\n",
      "Training loss per 100 training steps: 0.3854614048245281\n",
      "Training loss per 100 training steps: 0.3570687947310991\n",
      "Training loss per 100 training steps: 0.3442606859287242\n",
      "Training loss per 100 training steps: 0.33080853751707795\n",
      "Training loss per 100 training steps: 0.31296894673671827\n",
      "Training loss per 100 training steps: 0.3055047248790957\n",
      "Training loss per 100 training steps: 0.2962452423475561\n",
      "Training loss per 100 training steps: 0.285149447214461\n",
      "Training loss per 100 training steps: 0.2835595960428239\n",
      "Training loss per 100 training steps: 0.28144377738967546\n",
      "Training loss per 100 training steps: 0.2717379310336366\n",
      "Training loss per 100 training steps: 0.27063183148048525\n",
      "Training loss per 100 training steps: 0.26844597736212633\n",
      "Training loss per 100 training steps: 0.25807025040345843\n",
      "Training loss per 100 training steps: 0.2571723518840708\n",
      "Training loss per 100 training steps: 0.2511860023495388\n",
      "Training loss per 100 training steps: 0.25273718270475976\n",
      "Training loss per 100 training steps: 0.24820545625337426\n",
      "Training loss per 100 training steps: 0.2514076216395214\n",
      "Training loss per 100 training steps: 0.244132536333184\n",
      "Training loss per 100 training steps: 0.24155456832139272\n",
      "Training loss per 100 training steps: 0.2409914234752113\n",
      "Training loss per 100 training steps: 0.23700894060779226\n",
      "Training loss per 100 training steps: 0.23830587579381396\n",
      "Training loss per 100 training steps: 0.23560354720116378\n",
      "Training loss per 100 training steps: 0.23345503156021088\n",
      "Training loss per 100 training steps: 0.22797260447713857\n",
      "Training loss per 100 training steps: 0.2261512571568447\n",
      "Training loss per 100 training steps: 0.22064190021967323\n",
      "Training loss per 100 training steps: 0.22230297356188336\n",
      "Training loss per 100 training steps: 0.2203302959662878\n",
      "Training loss per 100 training steps: 0.22010030222094043\n",
      "Training loss per 100 training steps: 0.2195643567125252\n",
      "Training loss per 100 training steps: 0.21980767755020877\n",
      "Training loss per 100 training steps: 0.22034506980228846\n",
      "Training loss per 100 training steps: 0.22014319594102807\n",
      "Training loss per 100 training steps: 0.22079029868071756\n",
      "Training loss per 100 training steps: 0.21893333582309477\n",
      "Training loss per 100 training steps: 0.2186121928460752\n",
      "Training loss per 100 training steps: 0.22082219320149155\n",
      "Training loss per 100 training steps: 0.2214624328136797\n",
      "Training loss per 100 training steps: 0.22070193405270483\n",
      "Training loss per 100 training steps: 0.21787743436879542\n",
      "Training loss per 100 training steps: 0.216944565747984\n",
      "Training loss per 100 training steps: 0.21673745012939868\n",
      "Training loss per 100 training steps: 0.2167237268965912\n",
      "Training loss per 100 training steps: 0.21399913366142329\n",
      "Training loss per 100 training steps: 0.2134120486542278\n",
      "Training loss per 100 training steps: 0.21442357933621592\n",
      "Training loss per 100 training steps: 0.2149273943542075\n",
      "Training loss per 100 training steps: 0.21295204168971202\n",
      "Training loss per 100 training steps: 0.2111434359710058\n",
      "Training loss per 100 training steps: 0.20858780391827578\n",
      "Training loss per 100 training steps: 0.20620419245138627\n",
      "Training loss per 100 training steps: 0.20761591978873312\n",
      "Training loss per 100 training steps: 0.20724894249331957\n",
      "Training loss per 100 training steps: 0.20700541906601522\n",
      "Training loss per 100 training steps: 0.2078142814791488\n",
      "Training loss per 100 training steps: 0.2060526983845703\n",
      "Training loss per 100 training steps: 0.2054265794884762\n",
      "Training loss per 100 training steps: 0.20512877713072306\n",
      "Training loss per 100 training steps: 0.20379740354246711\n",
      "Training loss per 100 training steps: 0.20322376437567155\n",
      "Training loss per 100 training steps: 0.20163627489862437\n",
      "Training loss per 100 training steps: 0.20085976539446157\n",
      "Training loss per 100 training steps: 0.201269364612756\n",
      "Training loss per 100 training steps: 0.20145151837652372\n",
      "Training loss per 100 training steps: 0.20082761730858675\n",
      "Training loss per 100 training steps: 0.20211080988037974\n",
      "Training loss per 100 training steps: 0.20038446777871888\n",
      "Training loss per 100 training steps: 0.2002120407916766\n",
      "Training loss per 100 training steps: 0.20004582169056484\n",
      "Training loss per 100 training steps: 0.19844503461385524\n",
      "Training loss per 100 training steps: 0.1993289290757547\n",
      "Training loss per 100 training steps: 0.1991612025609635\n",
      "Training loss per 100 training steps: 0.20017776340470828\n",
      "Training loss per 100 training steps: 0.200089773493917\n",
      "Training loss per 100 training steps: 0.1984802309474225\n",
      "Training loss per 100 training steps: 0.19800320367397647\n",
      "Training loss per 100 training steps: 0.19781576241085944\n",
      "Training loss per 100 training steps: 0.19752107990891962\n",
      "Training loss per 100 training steps: 0.19652639317514484\n",
      "Training loss per 100 training steps: 0.19558164239169884\n",
      "Training loss per 100 training steps: 0.19587002131476922\n",
      "Training loss per 100 training steps: 0.19488316280718068\n",
      "Training loss per 100 training steps: 0.19589965818016253\n",
      "Training loss per 100 training steps: 0.19549749512889805\n",
      "Training loss per 100 training steps: 0.19510213404530732\n",
      "Training loss per 100 training steps: 0.19513925718640074\n",
      "Training loss per 100 training steps: 0.19443013680320761\n",
      "Training loss per 100 training steps: 0.19613815032532586\n",
      "Training loss per 100 training steps: 0.19718128635148574\n",
      "Training loss per 100 training steps: 0.19592246024681217\n",
      "Training loss per 100 training steps: 0.1945057291777712\n",
      "Training loss per 100 training steps: 0.1954196477514088\n",
      "Training loss per 100 training steps: 0.19378966869264136\n",
      "Training loss per 100 training steps: 0.1939906863674851\n",
      "Training loss per 100 training steps: 0.193181836974879\n",
      "Training loss per 100 training steps: 0.1933501601165362\n",
      "Training loss per 100 training steps: 0.19199458910499348\n",
      "Training loss per 100 training steps: 0.19173131305099883\n",
      "Training loss per 100 training steps: 0.19275838100187628\n",
      "Training loss per 100 training steps: 0.1931645358148892\n",
      "Training loss per 100 training steps: 0.19317946970034175\n",
      "Training loss per 100 training steps: 0.19321222675356597\n",
      "Training loss per 100 training steps: 0.19246561544013488\n",
      "Training loss per 100 training steps: 0.19295667032987468\n",
      "Training loss per 100 training steps: 0.19269192901957627\n",
      "Training loss per 100 training steps: 0.1924168755223391\n",
      "Training loss per 100 training steps: 0.19252538385772516\n",
      "Training loss per 100 training steps: 0.19269405551810492\n",
      "Training loss per 100 training steps: 0.19142306616048427\n",
      "Training loss per 100 training steps: 0.19087620773678235\n",
      "Training loss per 100 training steps: 0.19185955726725482\n",
      "Training loss per 100 training steps: 0.19172134520739678\n",
      "Training loss per 100 training steps: 0.19100015258512043\n",
      "Training loss per 100 training steps: 0.1915482517913091\n",
      "Training loss per 100 training steps: 0.19161971755305635\n",
      "Training loss per 100 training steps: 0.19218104393118599\n",
      "Training loss per 100 training steps: 0.1930236203948252\n",
      "Training loss per 100 training steps: 0.19278958553723308\n",
      "Training loss per 100 training steps: 0.1917785959530525\n",
      "Training loss per 100 training steps: 0.19169635064538396\n",
      "Training loss per 100 training steps: 0.19161610719625394\n",
      "Training loss per 100 training steps: 0.1923026773273735\n",
      "Training loss per 100 training steps: 0.1909961550680048\n",
      "Training loss per 100 training steps: 0.1912239382916835\n",
      "Training loss per 100 training steps: 0.19045982667509437\n",
      "Training loss per 100 training steps: 0.19136958589016342\n",
      "Training loss per 100 training steps: 0.19093450905140621\n",
      "Training loss per 100 training steps: 0.19159505340144867\n",
      "Training loss per 100 training steps: 0.19098233903715878\n",
      "Training loss per 100 training steps: 0.19148428885658375\n",
      "Training loss per 100 training steps: 0.19055021027309826\n",
      "Training loss per 100 training steps: 0.19077349843303587\n",
      "Training loss per 100 training steps: 0.1901874419396312\n",
      "Training loss per 100 training steps: 0.1900817809719593\n",
      "Training loss per 100 training steps: 0.19097275784657236\n",
      "Training loss per 100 training steps: 0.1903105542107446\n",
      "Training loss per 100 training steps: 0.19016602317788425\n",
      "Training loss per 100 training steps: 0.19139354678107123\n",
      "Training loss per 100 training steps: 0.19091017716858566\n",
      "Training loss per 100 training steps: 0.19128534004528516\n",
      "Training loss per 100 training steps: 0.1904683910022773\n",
      "Training loss per 100 training steps: 0.19130291711452319\n",
      "Training loss per 100 training steps: 0.19194133427519947\n",
      "Training loss per 100 training steps: 0.1911492390626866\n",
      "Training loss per 100 training steps: 0.19166123906568067\n",
      "Training loss per 100 training steps: 0.19137575128099588\n",
      "Training loss per 100 training steps: 0.19089694521043615\n",
      "Training loss per 100 training steps: 0.19158430734351675\n",
      "Training loss per 100 training steps: 0.19127361058555847\n",
      "Training loss per 100 training steps: 0.19150966928709282\n",
      "Training loss per 100 training steps: 0.19154538859310002\n",
      "Training loss per 100 training steps: 0.19223868537274869\n",
      "Training loss per 100 training steps: 0.19146452917281037\n",
      "Training loss per 100 training steps: 0.19062060060542832\n",
      "Training loss per 100 training steps: 0.18965533709131346\n",
      "Training loss per 100 training steps: 0.18921402195440937\n",
      "Training loss per 100 training steps: 0.18919915532308706\n",
      "Training loss per 100 training steps: 0.18902495760913607\n",
      "Training loss per 100 training steps: 0.18978361786143497\n",
      "Training loss per 100 training steps: 0.1897762773163323\n",
      "Training loss per 100 training steps: 0.1893524939261106\n",
      "Training loss per 100 training steps: 0.18885031183424542\n",
      "Training loss per 100 training steps: 0.18915060004785153\n",
      "Training loss per 100 training steps: 0.18893197833292819\n",
      "Training loss per 100 training steps: 0.18894610877640872\n",
      "Training loss per 100 training steps: 0.1887629303364679\n",
      "Training loss per 100 training steps: 0.18860503362760986\n",
      "Training loss per 100 training steps: 0.18857120802511249\n",
      "Training loss per 100 training steps: 0.18809368565927506\n",
      "Training loss per 100 training steps: 0.18799569221477777\n",
      "Training loss per 100 training steps: 0.18792835292110516\n",
      "Training loss per 100 training steps: 0.18825627303398193\n",
      "Training loss per 100 training steps: 0.18851588312379536\n",
      "Training loss per 100 training steps: 0.18835736750569806\n",
      "Training loss per 100 training steps: 0.1879525993917719\n",
      "Training loss per 100 training steps: 0.1877537469869759\n",
      "Training loss per 100 training steps: 0.1881612099052794\n",
      "Training loss per 100 training steps: 0.188113910267454\n",
      "Training loss per 100 training steps: 0.18829364527126247\n",
      "Training loss per 100 training steps: 0.18794158664381128\n",
      "Training loss per 100 training steps: 0.1880186890066605\n",
      "Training loss per 100 training steps: 0.18796330223935862\n",
      "Training loss per 100 training steps: 0.1879668892618108\n",
      "Training loss per 100 training steps: 0.1885164315043\n",
      "Training loss per 100 training steps: 0.18875975622240218\n",
      "Training loss per 100 training steps: 0.18836884330824463\n",
      "Training loss per 100 training steps: 0.18848311894744357\n",
      "Training loss per 100 training steps: 0.18823357322945308\n",
      "Training loss per 100 training steps: 0.18848788874943154\n",
      "Training loss per 100 training steps: 0.18775761082271977\n",
      "Training loss per 100 training steps: 0.18735109020293592\n",
      "Training loss per 100 training steps: 0.1873717093987782\n",
      "Training loss per 100 training steps: 0.1873341931697981\n",
      "Training loss per 100 training steps: 0.18754130104154748\n",
      "Training loss per 100 training steps: 0.18699490518738085\n",
      "Training loss per 100 training steps: 0.1867331768753204\n",
      "Training loss per 100 training steps: 0.18651728320389305\n",
      "Training loss per 100 training steps: 0.18632623818321206\n",
      "Training loss per 100 training steps: 0.18697716363505618\n",
      "Training loss per 100 training steps: 0.18702280302083904\n",
      "Training loss per 100 training steps: 0.18745563930096826\n",
      "Training loss per 100 training steps: 0.187305002725588\n",
      "Training loss per 100 training steps: 0.18743466406602796\n",
      "Training loss per 100 training steps: 0.18696584495234037\n",
      "Training loss per 100 training steps: 0.1866269684368897\n",
      "Training loss per 100 training steps: 0.18653561657935488\n",
      "Training loss per 100 training steps: 0.1859430961736629\n",
      "Training loss per 100 training steps: 0.18551174457832245\n",
      "Training loss per 100 training steps: 0.1850221875855701\n",
      "Training loss per 100 training steps: 0.18552435108642373\n",
      "Training loss per 100 training steps: 0.1856567685680717\n",
      "Training loss per 100 training steps: 0.18527168678627223\n",
      "Training loss per 100 training steps: 0.18498945236544045\n",
      "Training loss per 100 training steps: 0.18461792333063082\n",
      "Training loss per 100 training steps: 0.1843976217280902\n",
      "Training loss per 100 training steps: 0.18466494669541045\n",
      "Training loss per 100 training steps: 0.1847431571608189\n",
      "Training loss per 100 training steps: 0.18449751406010625\n",
      "Training loss per 100 training steps: 0.1842155788500878\n",
      "Training loss per 100 training steps: 0.18461905611967475\n",
      "Training loss per 100 training steps: 0.18425844734342897\n",
      "Training loss per 100 training steps: 0.18425207788026224\n",
      "Training loss per 100 training steps: 0.18357184561738715\n",
      "Training loss per 100 training steps: 0.1837105348982759\n",
      "Training loss per 100 training steps: 0.18317261771567675\n",
      "Training loss per 100 training steps: 0.18282726264977248\n",
      "Training loss per 100 training steps: 0.18221393476878753\n",
      "Training loss per 100 training steps: 0.1818245239555204\n",
      "Training loss per 100 training steps: 0.18168689759576936\n",
      "Training loss per 100 training steps: 0.18171825099004513\n",
      "Training loss per 100 training steps: 0.18197578471442266\n",
      "Training loss per 100 training steps: 0.18161804071466678\n",
      "Training loss per 100 training steps: 0.18097228529494674\n",
      "Training loss per 100 training steps: 0.18080949105728636\n",
      "Training loss per 100 training steps: 0.18053990504014822\n",
      "Training loss per 100 training steps: 0.18050471957007655\n",
      "Training loss per 100 training steps: 0.18033605410300244\n",
      "Training loss per 100 training steps: 0.17988047721015651\n",
      "Training loss per 100 training steps: 0.17953709392276587\n",
      "Training loss per 100 training steps: 0.17890749337316864\n",
      "Training loss per 100 training steps: 0.17908316815616837\n",
      "Training loss per 100 training steps: 0.17894713861636358\n",
      "Training loss per 100 training steps: 0.17881416445638115\n",
      "Training loss per 100 training steps: 0.17841620290750554\n",
      "Training loss per 100 training steps: 0.17845285826743595\n",
      "Training loss per 100 training steps: 0.1786422779485854\n",
      "Training loss per 100 training steps: 0.17857103593398047\n",
      "Training loss per 100 training steps: 0.17859393502544846\n",
      "Training loss per 100 training steps: 0.1787132986316669\n",
      "Training loss per 100 training steps: 0.1785596874489415\n",
      "Training loss per 100 training steps: 0.17806769197243236\n",
      "Training loss per 100 training steps: 0.1779761649926599\n",
      "Training loss per 100 training steps: 0.1777463759826673\n",
      "Training loss per 100 training steps: 0.17742563392856356\n",
      "Training loss per 100 training steps: 0.17760633824296293\n",
      "Training loss per 100 training steps: 0.17725974313623388\n",
      "Training loss per 100 training steps: 0.17756264466742802\n",
      "Training loss per 100 training steps: 0.17719510139964362\n",
      "Training loss per 100 training steps: 0.17716698557403435\n",
      "Training loss per 100 training steps: 0.17698749357003432\n",
      "Training loss per 100 training steps: 0.17662205831967304\n",
      "Training loss per 100 training steps: 0.17616828687135147\n",
      "Training loss per 100 training steps: 0.17594251560304988\n",
      "Training loss per 100 training steps: 0.17622637415558562\n",
      "Training loss per 100 training steps: 0.17609353544879652\n",
      "Training loss per 100 training steps: 0.17591710116064938\n",
      "Training loss per 100 training steps: 0.17542938537289043\n",
      "Training loss per 100 training steps: 0.1759098007727324\n",
      "Training loss per 100 training steps: 0.17610585138817594\n",
      "Training loss per 100 training steps: 0.17593873547239405\n",
      "Training loss per 100 training steps: 0.17565180400689392\n",
      "Training loss per 100 training steps: 0.17566718044329202\n",
      "Training loss per 100 training steps: 0.17549949046446034\n",
      "Training loss per 100 training steps: 0.17547786449672584\n",
      "Training loss per 100 training steps: 0.17526649163874083\n",
      "Training loss per 100 training steps: 0.17548074173816083\n",
      "Training loss per 100 training steps: 0.1752622769280871\n",
      "Training loss per 100 training steps: 0.1748124088501279\n",
      "Training loss per 100 training steps: 0.1747159449934064\n",
      "Training loss per 100 training steps: 0.17441816445085248\n",
      "Training loss per 100 training steps: 0.17436892507423835\n",
      "Training loss per 100 training steps: 0.17418480142438666\n",
      "Training loss per 100 training steps: 0.17368266681229144\n",
      "Training loss per 100 training steps: 0.17350401288318765\n",
      "Training loss per 100 training steps: 0.17382555261828556\n",
      "Training loss per 100 training steps: 0.1739228641980336\n",
      "Training loss per 100 training steps: 0.17381634814429345\n",
      "Training loss per 100 training steps: 0.17402324506664368\n",
      "Training loss per 100 training steps: 0.17380725482418835\n",
      "Training loss per 100 training steps: 0.17362421605249653\n",
      "Training loss per 100 training steps: 0.1732398503814217\n",
      "Training loss per 100 training steps: 0.17349802115465443\n",
      "Training loss per 100 training steps: 0.17305837359709478\n",
      "Training loss per 100 training steps: 0.17340297387447237\n",
      "Training loss per 100 training steps: 0.17319666035947498\n",
      "Training loss per 100 training steps: 0.1732688942876147\n",
      "Training loss per 100 training steps: 0.17310813956234664\n",
      "Training loss per 100 training steps: 0.17303490909706168\n",
      "Training loss per 100 training steps: 0.1732503170130912\n",
      "Training loss per 100 training steps: 0.17296353243010568\n",
      "Training loss per 100 training steps: 0.17273142698516908\n",
      "Training loss per 100 training steps: 0.17246297995414542\n",
      "Training loss per 100 training steps: 0.1725338548710534\n",
      "Training loss per 100 training steps: 0.1726229302604479\n",
      "Training loss per 100 training steps: 0.1725940441563514\n",
      "Training loss per 100 training steps: 0.17244249165854558\n",
      "Training loss per 100 training steps: 0.1722812994581441\n",
      "Training loss per 100 training steps: 0.17195080938502333\n",
      "Training loss per 100 training steps: 0.1714559970826221\n",
      "Training loss per 100 training steps: 0.17150725227862193\n",
      "Training loss per 100 training steps: 0.17148787501815194\n",
      "Training loss per 100 training steps: 0.17153331409553063\n",
      "Training loss per 100 training steps: 0.171324976524681\n",
      "Training loss per 100 training steps: 0.17090992198263294\n",
      "Training loss per 100 training steps: 0.1709389178491205\n",
      "Training loss per 100 training steps: 0.1709556472178273\n",
      "Training loss per 100 training steps: 0.17085391337831463\n",
      "Training loss per 100 training steps: 0.17066648113459038\n",
      "Training loss per 100 training steps: 0.17076075381424471\n",
      "Training loss per 100 training steps: 0.1705897788311174\n",
      "Training loss per 100 training steps: 0.17045048340858787\n",
      "Training loss per 100 training steps: 0.17081804468372802\n",
      "Training loss per 100 training steps: 0.17065036805433353\n",
      "Training loss per 100 training steps: 0.17072646738577027\n",
      "Training loss per 100 training steps: 0.17075581251812205\n",
      "Training loss per 100 training steps: 0.1704001057948171\n",
      "Training loss per 100 training steps: 0.1705237615310059\n",
      "Training loss per 100 training steps: 0.17028695351082523\n",
      "Training loss per 100 training steps: 0.1704821780474308\n",
      "Training loss per 100 training steps: 0.17028453979855873\n",
      "Training loss per 100 training steps: 0.16996466655752457\n",
      "Training loss per 100 training steps: 0.16988922096384484\n",
      "Training loss per 100 training steps: 0.16974118917753572\n",
      "Training loss per 100 training steps: 0.16967154564475295\n",
      "Training loss per 100 training steps: 0.16963521823651534\n",
      "Training loss per 100 training steps: 0.1695701140645655\n",
      "Training loss per 100 training steps: 0.1694139898554936\n",
      "Training loss per 100 training steps: 0.16940026154105842\n",
      "Training loss per 100 training steps: 0.16931773222011104\n",
      "Training loss per 100 training steps: 0.16974967832454732\n",
      "Training loss per 100 training steps: 0.1694835191263949\n",
      "Training loss per 100 training steps: 0.16929669398360458\n",
      "Training loss per 100 training steps: 0.16931789253342272\n",
      "Training loss per 100 training steps: 0.16915693971460266\n",
      "Training loss per 100 training steps: 0.16889153436207757\n",
      "Training loss per 100 training steps: 0.16881449520209224\n",
      "Training loss per 100 training steps: 0.16850027824099276\n",
      "Training loss per 100 training steps: 0.16816129068587995\n",
      "Training loss per 100 training steps: 0.16812061828708275\n",
      "Training loss per 100 training steps: 0.16825640558202565\n",
      "Training loss per 100 training steps: 0.16798747684315113\n",
      "Training loss per 100 training steps: 0.1675494955770794\n",
      "Training loss per 100 training steps: 0.16730653210922072\n",
      "Training loss per 100 training steps: 0.16730599271120308\n",
      "Training loss per 100 training steps: 0.1671149858130135\n",
      "Training loss per 100 training steps: 0.16679809625337833\n",
      "Training loss per 100 training steps: 0.1666225354742068\n",
      "Training loss per 100 training steps: 0.1666494863489315\n",
      "Training loss per 100 training steps: 0.16640362637628825\n",
      "Training loss per 100 training steps: 0.16612292008471838\n",
      "Training loss per 100 training steps: 0.16610262720905675\n",
      "Training loss per 100 training steps: 0.16604130506433215\n",
      "Training loss per 100 training steps: 0.16622167445214306\n",
      "Training loss per 100 training steps: 0.16613942651192717\n",
      "Training loss per 100 training steps: 0.16621155630061557\n",
      "Training loss per 100 training steps: 0.1661297948473718\n",
      "Training loss per 100 training steps: 0.16609947908970882\n",
      "Training loss per 100 training steps: 0.1658902988430258\n",
      "Training loss per 100 training steps: 0.16560125416069893\n",
      "Training loss per 100 training steps: 0.16590180759638246\n",
      "Training loss per 100 training steps: 0.16558739603160874\n",
      "Training loss per 100 training steps: 0.165567194785479\n",
      "Training loss epoch: 0.1659566267948096\n",
      "Training accuracy epoch: 0.9785516845728591\n",
      "------------------------------------1-----------------------------------\n",
      "Training loss per 100 training steps: 0.0008961104322224855\n",
      "Training loss per 100 training steps: 0.17352862589667542\n",
      "Training loss per 100 training steps: 0.09388335525383709\n",
      "Training loss per 100 training steps: 0.10218000808321527\n",
      "Training loss per 100 training steps: 0.14548739685736214\n",
      "Training loss per 100 training steps: 0.14085105421840555\n",
      "Training loss per 100 training steps: 0.13006989886288256\n",
      "Training loss per 100 training steps: 0.12009894389939162\n",
      "Training loss per 100 training steps: 0.12649560074708013\n",
      "Training loss per 100 training steps: 0.1298106121603723\n",
      "Training loss per 100 training steps: 0.12213800050451025\n",
      "Training loss per 100 training steps: 0.12207131328863337\n",
      "Training loss per 100 training steps: 0.11612541470688899\n",
      "Training loss per 100 training steps: 0.10973010602012981\n",
      "Training loss per 100 training steps: 0.10420752720222311\n",
      "Training loss per 100 training steps: 0.09938342252760941\n",
      "Training loss per 100 training steps: 0.09494204245894457\n",
      "Training loss per 100 training steps: 0.09427300051120716\n",
      "Training loss per 100 training steps: 0.09645739217285608\n",
      "Training loss per 100 training steps: 0.09500122340225076\n",
      "Training loss per 100 training steps: 0.09621366266760471\n",
      "Training loss per 100 training steps: 0.09941727412497381\n",
      "Training loss per 100 training steps: 0.10315559651393859\n",
      "Training loss per 100 training steps: 0.10269534499141172\n",
      "Training loss per 100 training steps: 0.10697228434741732\n",
      "Training loss per 100 training steps: 0.10621077050627548\n",
      "Training loss per 100 training steps: 0.10564229154244674\n",
      "Training loss per 100 training steps: 0.10312338602215615\n",
      "Training loss per 100 training steps: 0.10300441784498005\n",
      "Training loss per 100 training steps: 0.10176356815072607\n",
      "Training loss per 100 training steps: 0.10203078124902992\n",
      "Training loss per 100 training steps: 0.10411519792061062\n",
      "Training loss per 100 training steps: 0.10317762458804257\n",
      "Training loss per 100 training steps: 0.1028530281849835\n",
      "Training loss per 100 training steps: 0.1035230351251767\n",
      "Training loss per 100 training steps: 0.1054794194064181\n",
      "Training loss per 100 training steps: 0.10793830233587498\n",
      "Training loss per 100 training steps: 0.10908496493183101\n",
      "Training loss per 100 training steps: 0.11080913606891485\n",
      "Training loss per 100 training steps: 0.10858753425514361\n",
      "Training loss per 100 training steps: 0.10857188848203132\n",
      "Training loss per 100 training steps: 0.10717635834435202\n",
      "Training loss per 100 training steps: 0.10765250647542784\n",
      "Training loss per 100 training steps: 0.10703299873144315\n",
      "Training loss per 100 training steps: 0.10675118785978101\n",
      "Training loss per 100 training steps: 0.10694146238797132\n",
      "Training loss per 100 training steps: 0.1080123876532524\n",
      "Training loss per 100 training steps: 0.10718089509564435\n",
      "Training loss per 100 training steps: 0.10708105804546343\n",
      "Training loss per 100 training steps: 0.10682983635625716\n",
      "Training loss per 100 training steps: 0.1070608153442179\n",
      "Training loss per 100 training steps: 0.10702695932578978\n",
      "Training loss per 100 training steps: 0.1062434703544624\n",
      "Training loss per 100 training steps: 0.10621741293254644\n",
      "Training loss per 100 training steps: 0.10685863122780487\n",
      "Training loss per 100 training steps: 0.10851490855345705\n",
      "Training loss per 100 training steps: 0.10986457961479294\n",
      "Training loss per 100 training steps: 0.11005746446213577\n",
      "Training loss per 100 training steps: 0.10875238773767831\n",
      "Training loss per 100 training steps: 0.1074273908841076\n",
      "Training loss per 100 training steps: 0.10724974825520915\n",
      "Training loss per 100 training steps: 0.10782403367463989\n",
      "Training loss per 100 training steps: 0.10762915224099616\n",
      "Training loss per 100 training steps: 0.10621376088036677\n",
      "Training loss per 100 training steps: 0.10548824078062723\n",
      "Training loss per 100 training steps: 0.1043952902200192\n",
      "Training loss per 100 training steps: 0.10395797737787316\n",
      "Training loss per 100 training steps: 0.10295395242278772\n",
      "Training loss per 100 training steps: 0.10149349817331804\n",
      "Training loss per 100 training steps: 0.10150164065279897\n",
      "Training loss per 100 training steps: 0.10191726162466858\n",
      "Training loss per 100 training steps: 0.10166004828079436\n",
      "Training loss per 100 training steps: 0.10199926624774965\n",
      "Training loss per 100 training steps: 0.10215409961887817\n",
      "Training loss per 100 training steps: 0.10263034552881416\n",
      "Training loss per 100 training steps: 0.10331406077313407\n",
      "Training loss per 100 training steps: 0.10424915613754136\n",
      "Training loss per 100 training steps: 0.10372655344958541\n",
      "Training loss per 100 training steps: 0.10295910366819178\n",
      "Training loss per 100 training steps: 0.1045754957814037\n",
      "Training loss per 100 training steps: 0.10407828110894977\n",
      "Training loss per 100 training steps: 0.10639331668398974\n",
      "Training loss per 100 training steps: 0.1058644958469411\n",
      "Training loss per 100 training steps: 0.10557758794980514\n",
      "Training loss per 100 training steps: 0.10553772075965166\n",
      "Training loss per 100 training steps: 0.10603616399589243\n",
      "Training loss per 100 training steps: 0.10661678808305566\n",
      "Training loss per 100 training steps: 0.10714256541481859\n",
      "Training loss per 100 training steps: 0.10685791496089209\n",
      "Training loss per 100 training steps: 0.10659565003241073\n",
      "Training loss per 100 training steps: 0.10649876991890135\n",
      "Training loss per 100 training steps: 0.10563852043451366\n",
      "Training loss per 100 training steps: 0.1071266492820711\n",
      "Training loss per 100 training steps: 0.10795958372741091\n",
      "Training loss per 100 training steps: 0.1076206660741175\n",
      "Training loss per 100 training steps: 0.10736209564183019\n",
      "Training loss per 100 training steps: 0.1067901858582008\n",
      "Training loss per 100 training steps: 0.10742331903453974\n",
      "Training loss per 100 training steps: 0.10642804634806627\n",
      "Training loss per 100 training steps: 0.10562172695167131\n",
      "Training loss per 100 training steps: 0.1050207237880411\n",
      "Training loss per 100 training steps: 0.10459342907173748\n",
      "Training loss per 100 training steps: 0.10472878200354847\n",
      "Training loss per 100 training steps: 0.10479420762044592\n",
      "Training loss per 100 training steps: 0.10493673935252962\n",
      "Training loss per 100 training steps: 0.10462391652260668\n",
      "Training loss per 100 training steps: 0.10434905185615213\n",
      "Training loss per 100 training steps: 0.10387136545570042\n",
      "Training loss per 100 training steps: 0.10336282335778584\n",
      "Training loss per 100 training steps: 0.10279807710908198\n",
      "Training loss per 100 training steps: 0.10245012134315287\n",
      "Training loss per 100 training steps: 0.10214428413158493\n",
      "Training loss per 100 training steps: 0.10246482814574796\n",
      "Training loss per 100 training steps: 0.10198726361443297\n",
      "Training loss per 100 training steps: 0.1018851485692227\n",
      "Training loss per 100 training steps: 0.10265177072944838\n",
      "Training loss per 100 training steps: 0.10220694417264563\n",
      "Training loss per 100 training steps: 0.1019918865966868\n",
      "Training loss per 100 training steps: 0.10180906725010838\n",
      "Training loss per 100 training steps: 0.10156552330087876\n",
      "Training loss per 100 training steps: 0.1011666451208851\n",
      "Training loss per 100 training steps: 0.10069988463701993\n",
      "Training loss per 100 training steps: 0.10159708741937655\n",
      "Training loss per 100 training steps: 0.10159245472260219\n",
      "Training loss per 100 training steps: 0.10101251228959073\n",
      "Training loss per 100 training steps: 0.1010060033464157\n",
      "Training loss per 100 training steps: 0.10115965438703887\n",
      "Training loss per 100 training steps: 0.10113356179027427\n",
      "Training loss per 100 training steps: 0.10197512662496315\n",
      "Training loss per 100 training steps: 0.10254484725373215\n",
      "Training loss per 100 training steps: 0.10355327507542442\n",
      "Training loss per 100 training steps: 0.10424652004399494\n",
      "Training loss per 100 training steps: 0.10358856562506222\n",
      "Training loss per 100 training steps: 0.10357084693844221\n",
      "Training loss per 100 training steps: 0.1037788054327045\n",
      "Training loss per 100 training steps: 0.1039738288918049\n",
      "Training loss per 100 training steps: 0.10354147871531845\n",
      "Training loss per 100 training steps: 0.10373967666531465\n",
      "Training loss per 100 training steps: 0.10404598932546057\n",
      "Training loss per 100 training steps: 0.10415877213856689\n",
      "Training loss per 100 training steps: 0.10412327733764727\n",
      "Training loss per 100 training steps: 0.10444433798731505\n",
      "Training loss per 100 training steps: 0.10427803731617531\n",
      "Training loss per 100 training steps: 0.10419561249049203\n",
      "Training loss per 100 training steps: 0.10396827938248256\n",
      "Training loss per 100 training steps: 0.10406589309600124\n",
      "Training loss per 100 training steps: 0.10407865796916284\n",
      "Training loss per 100 training steps: 0.10386079947275528\n",
      "Training loss per 100 training steps: 0.10347652239184368\n",
      "Training loss per 100 training steps: 0.10288779009676415\n",
      "Training loss per 100 training steps: 0.10298595408646587\n",
      "Training loss per 100 training steps: 0.10249572791847726\n",
      "Training loss per 100 training steps: 0.10254523727144009\n",
      "Training loss per 100 training steps: 0.10279182830100382\n",
      "Training loss per 100 training steps: 0.10271549367448803\n",
      "Training loss per 100 training steps: 0.10299896209653672\n",
      "Training loss per 100 training steps: 0.10304147243477285\n",
      "Training loss per 100 training steps: 0.10327313484621808\n",
      "Training loss per 100 training steps: 0.10329654651992609\n",
      "Training loss per 100 training steps: 0.10281369926183705\n",
      "Training loss per 100 training steps: 0.10269064503348607\n",
      "Training loss per 100 training steps: 0.10242944848902369\n",
      "Training loss per 100 training steps: 0.10221392112991032\n",
      "Training loss per 100 training steps: 0.10232493680165705\n",
      "Training loss per 100 training steps: 0.10251143195637574\n",
      "Training loss per 100 training steps: 0.10257235696162727\n",
      "Training loss per 100 training steps: 0.10226616588863971\n",
      "Training loss per 100 training steps: 0.10260656631468988\n",
      "Training loss per 100 training steps: 0.10265635095107083\n",
      "Training loss per 100 training steps: 0.10260288122613151\n",
      "Training loss per 100 training steps: 0.10320176907512599\n",
      "Training loss per 100 training steps: 0.10295275259060654\n",
      "Training loss per 100 training steps: 0.10297835406030685\n",
      "Training loss per 100 training steps: 0.1026094353885918\n",
      "Training loss per 100 training steps: 0.10227941206248164\n",
      "Training loss per 100 training steps: 0.10171318983089024\n",
      "Training loss per 100 training steps: 0.10126870247427053\n",
      "Training loss per 100 training steps: 0.10117725882648707\n",
      "Training loss per 100 training steps: 0.10136993541828421\n",
      "Training loss per 100 training steps: 0.10146677995371961\n",
      "Training loss per 100 training steps: 0.10126994339550667\n",
      "Training loss per 100 training steps: 0.10132152842830014\n",
      "Training loss per 100 training steps: 0.10138374385026525\n",
      "Training loss per 100 training steps: 0.10142968092812414\n",
      "Training loss per 100 training steps: 0.1012549605220918\n",
      "Training loss per 100 training steps: 0.10121355620119446\n",
      "Training loss per 100 training steps: 0.10158834591441179\n",
      "Training loss per 100 training steps: 0.1013847384432231\n",
      "Training loss per 100 training steps: 0.1015558342323178\n",
      "Training loss per 100 training steps: 0.10152649799389968\n",
      "Training loss per 100 training steps: 0.10122373307064395\n",
      "Training loss per 100 training steps: 0.10080678980958865\n",
      "Training loss per 100 training steps: 0.10066387909316424\n",
      "Training loss per 100 training steps: 0.1010684690740819\n",
      "Training loss per 100 training steps: 0.1012692263761749\n",
      "Training loss per 100 training steps: 0.10130205344115287\n",
      "Training loss per 100 training steps: 0.10137840807013485\n",
      "Training loss per 100 training steps: 0.10111861238147724\n",
      "Training loss per 100 training steps: 0.10121599679914205\n",
      "Training loss per 100 training steps: 0.10079596388743399\n",
      "Training loss per 100 training steps: 0.1004893405438652\n",
      "Training loss per 100 training steps: 0.10069352536907217\n",
      "Training loss per 100 training steps: 0.10092968537668678\n",
      "Training loss per 100 training steps: 0.10067901883355013\n",
      "Training loss per 100 training steps: 0.10099681190004653\n",
      "Training loss per 100 training steps: 0.10101769812026998\n",
      "Training loss per 100 training steps: 0.10120694307696447\n",
      "Training loss per 100 training steps: 0.10118886984706363\n",
      "Training loss per 100 training steps: 0.10142613922023756\n",
      "Training loss per 100 training steps: 0.10136625825385277\n",
      "Training loss per 100 training steps: 0.10124728346648953\n",
      "Training loss per 100 training steps: 0.10101228395752271\n",
      "Training loss per 100 training steps: 0.1006122416711485\n",
      "Training loss per 100 training steps: 0.10047166160391474\n",
      "Training loss per 100 training steps: 0.10053637698835492\n",
      "Training loss per 100 training steps: 0.10036271680704646\n",
      "Training loss per 100 training steps: 0.10084637591634447\n",
      "Training loss per 100 training steps: 0.10083194518710001\n",
      "Training loss per 100 training steps: 0.10069839976634429\n",
      "Training loss per 100 training steps: 0.10070371674336205\n",
      "Training loss per 100 training steps: 0.10078201946747342\n",
      "Training loss per 100 training steps: 0.100542470654569\n",
      "Training loss per 100 training steps: 0.10015032287345434\n",
      "Training loss per 100 training steps: 0.0999712103936495\n",
      "Training loss per 100 training steps: 0.10011141723552971\n",
      "Training loss per 100 training steps: 0.10019741508427395\n",
      "Training loss per 100 training steps: 0.10003921266030054\n",
      "Training loss per 100 training steps: 0.10007646627226068\n",
      "Training loss per 100 training steps: 0.09998234332968123\n",
      "Training loss per 100 training steps: 0.10045331460065625\n",
      "Training loss per 100 training steps: 0.10038103755145478\n",
      "Training loss per 100 training steps: 0.10049973592583245\n",
      "Training loss per 100 training steps: 0.10057848068962898\n",
      "Training loss per 100 training steps: 0.1003395989516035\n",
      "Training loss per 100 training steps: 0.10056850257041651\n",
      "Training loss per 100 training steps: 0.10026922216678784\n",
      "Training loss per 100 training steps: 0.09996880904447163\n",
      "Training loss per 100 training steps: 0.09986906337300439\n",
      "Training loss per 100 training steps: 0.1006392752214878\n",
      "Training loss per 100 training steps: 0.10065635537703055\n",
      "Training loss per 100 training steps: 0.10043515393430258\n",
      "Training loss per 100 training steps: 0.1000545411430844\n",
      "Training loss per 100 training steps: 0.09982570371859699\n",
      "Training loss per 100 training steps: 0.09951164890218712\n",
      "Training loss per 100 training steps: 0.09944657999642098\n",
      "Training loss per 100 training steps: 0.09955642887412351\n",
      "Training loss per 100 training steps: 0.0996279081712612\n",
      "Training loss per 100 training steps: 0.09953270336896916\n",
      "Training loss per 100 training steps: 0.10033230128288521\n",
      "Training loss per 100 training steps: 0.10015932177775011\n",
      "Training loss per 100 training steps: 0.09988847715278322\n",
      "Training loss per 100 training steps: 0.10030564300549213\n",
      "Training loss per 100 training steps: 0.10010321346039351\n",
      "Training loss per 100 training steps: 0.1000279737429999\n",
      "Training loss per 100 training steps: 0.1001904707759927\n",
      "Training loss per 100 training steps: 0.10012537650364263\n",
      "Training loss per 100 training steps: 0.09987608680701153\n",
      "Training loss per 100 training steps: 0.09958592374844842\n",
      "Training loss per 100 training steps: 0.09937899336401113\n",
      "Training loss per 100 training steps: 0.09953565146122371\n",
      "Training loss per 100 training steps: 0.09926266418441877\n",
      "Training loss per 100 training steps: 0.09914849126141823\n",
      "Training loss per 100 training steps: 0.0987964126353515\n",
      "Training loss per 100 training steps: 0.09867547149219003\n",
      "Training loss per 100 training steps: 0.0983102252139001\n",
      "Training loss per 100 training steps: 0.09795063678674784\n",
      "Training loss per 100 training steps: 0.09762782844005946\n",
      "Training loss per 100 training steps: 0.0978410503054289\n",
      "Training loss per 100 training steps: 0.09789381698727448\n",
      "Training loss per 100 training steps: 0.09767405241443601\n",
      "Training loss per 100 training steps: 0.09769491167771006\n",
      "Training loss per 100 training steps: 0.09757728889940279\n",
      "Training loss per 100 training steps: 0.09777644783528265\n",
      "Training loss per 100 training steps: 0.09753250762766924\n",
      "Training loss per 100 training steps: 0.09749286157488338\n",
      "Training loss per 100 training steps: 0.09757618699525525\n",
      "Training loss per 100 training steps: 0.09758053360170038\n",
      "Training loss per 100 training steps: 0.09744570826940456\n",
      "Training loss per 100 training steps: 0.09727882207346136\n",
      "Training loss per 100 training steps: 0.09734378896759747\n",
      "Training loss per 100 training steps: 0.09729170808041374\n",
      "Training loss per 100 training steps: 0.09736717485418495\n",
      "Training loss per 100 training steps: 0.09731594869889103\n",
      "Training loss per 100 training steps: 0.0973575876789822\n",
      "Training loss per 100 training steps: 0.09768867326012204\n",
      "Training loss per 100 training steps: 0.09790424621930037\n",
      "Training loss per 100 training steps: 0.09791481726734569\n",
      "Training loss per 100 training steps: 0.09786360891097307\n",
      "Training loss per 100 training steps: 0.09810766741349662\n",
      "Training loss per 100 training steps: 0.09792514150601156\n",
      "Training loss per 100 training steps: 0.09826274476035406\n",
      "Training loss per 100 training steps: 0.09851804440359811\n",
      "Training loss per 100 training steps: 0.09844595969888514\n",
      "Training loss per 100 training steps: 0.09880959899920785\n",
      "Training loss per 100 training steps: 0.09872858613260274\n",
      "Training loss per 100 training steps: 0.09865166710327188\n",
      "Training loss per 100 training steps: 0.09872108166095374\n",
      "Training loss per 100 training steps: 0.09865949018825247\n",
      "Training loss per 100 training steps: 0.09842469004416168\n",
      "Training loss per 100 training steps: 0.09874955529106842\n",
      "Training loss per 100 training steps: 0.09884915013913521\n",
      "Training loss per 100 training steps: 0.09866426484130783\n",
      "Training loss per 100 training steps: 0.09857549946134259\n",
      "Training loss per 100 training steps: 0.0983851380348208\n",
      "Training loss per 100 training steps: 0.09845006033332694\n",
      "Training loss per 100 training steps: 0.09848352145517528\n",
      "Training loss per 100 training steps: 0.09839158506925579\n",
      "Training loss per 100 training steps: 0.09829173832286006\n",
      "Training loss per 100 training steps: 0.09816614963893441\n",
      "Training loss per 100 training steps: 0.09841962620940885\n",
      "Training loss per 100 training steps: 0.09851120610043203\n",
      "Training loss per 100 training steps: 0.09859544620880073\n",
      "Training loss per 100 training steps: 0.09882311975747944\n",
      "Training loss per 100 training steps: 0.09864417374357184\n",
      "Training loss per 100 training steps: 0.09848761007097356\n",
      "Training loss per 100 training steps: 0.0985833930504506\n",
      "Training loss per 100 training steps: 0.09867314257365004\n",
      "Training loss per 100 training steps: 0.09885688317061558\n",
      "Training loss per 100 training steps: 0.09863791191295954\n",
      "Training loss per 100 training steps: 0.09891047154317274\n",
      "Training loss per 100 training steps: 0.09890998336556997\n",
      "Training loss per 100 training steps: 0.09875695736020057\n",
      "Training loss per 100 training steps: 0.09854769014040861\n",
      "Training loss per 100 training steps: 0.09847876214810156\n",
      "Training loss per 100 training steps: 0.09864355426566654\n",
      "Training loss per 100 training steps: 0.09843113871108146\n",
      "Training loss per 100 training steps: 0.09846009329928206\n",
      "Training loss per 100 training steps: 0.098258520287658\n",
      "Training loss per 100 training steps: 0.09825825383781837\n",
      "Training loss per 100 training steps: 0.09821359638116918\n",
      "Training loss per 100 training steps: 0.09823205763257696\n",
      "Training loss per 100 training steps: 0.09808739954361323\n",
      "Training loss per 100 training steps: 0.09826850930497698\n",
      "Training loss per 100 training steps: 0.09817069484446966\n",
      "Training loss per 100 training steps: 0.0980207291493092\n",
      "Training loss per 100 training steps: 0.09800133888539483\n",
      "Training loss per 100 training steps: 0.09807021731204935\n",
      "Training loss per 100 training steps: 0.0982070362592064\n",
      "Training loss per 100 training steps: 0.09812226466162621\n",
      "Training loss per 100 training steps: 0.09836281658798762\n",
      "Training loss per 100 training steps: 0.09843896947059955\n",
      "Training loss per 100 training steps: 0.098344603491242\n",
      "Training loss per 100 training steps: 0.09852353385131575\n",
      "Training loss per 100 training steps: 0.09832099806898167\n",
      "Training loss per 100 training steps: 0.09809593076917753\n",
      "Training loss per 100 training steps: 0.09808761923942734\n",
      "Training loss per 100 training steps: 0.09815746322217464\n",
      "Training loss per 100 training steps: 0.09816599563433417\n",
      "Training loss per 100 training steps: 0.09803270725605435\n",
      "Training loss per 100 training steps: 0.09799734378766682\n",
      "Training loss per 100 training steps: 0.09807899107256936\n",
      "Training loss per 100 training steps: 0.09794639662303997\n",
      "Training loss per 100 training steps: 0.09778881195224087\n",
      "Training loss per 100 training steps: 0.09774517674806753\n",
      "Training loss per 100 training steps: 0.09755199193119649\n",
      "Training loss per 100 training steps: 0.09771374279322446\n",
      "Training loss per 100 training steps: 0.09753520137924394\n",
      "Training loss per 100 training steps: 0.09768661894841771\n",
      "Training loss per 100 training steps: 0.09757893814297759\n",
      "Training loss per 100 training steps: 0.09761804004237352\n",
      "Training loss per 100 training steps: 0.09753479879430417\n",
      "Training loss per 100 training steps: 0.09761466488647036\n",
      "Training loss per 100 training steps: 0.09764801901714174\n",
      "Training loss per 100 training steps: 0.09755478550626671\n",
      "Training loss per 100 training steps: 0.09744727025961725\n",
      "Training loss per 100 training steps: 0.09733304154329488\n",
      "Training loss per 100 training steps: 0.09756940744774105\n",
      "Training loss per 100 training steps: 0.09735777289555181\n",
      "Training loss per 100 training steps: 0.09737623523966749\n",
      "Training loss per 100 training steps: 0.09719975657639375\n",
      "Training loss per 100 training steps: 0.09736674464277151\n",
      "Training loss per 100 training steps: 0.09721345711036385\n",
      "Training loss per 100 training steps: 0.09773082706081773\n",
      "Training loss per 100 training steps: 0.09784650771145048\n",
      "Training loss per 100 training steps: 0.09781991526990634\n",
      "Training loss per 100 training steps: 0.09787534712452303\n",
      "Training loss per 100 training steps: 0.09795361093890068\n",
      "Training loss per 100 training steps: 0.0977287833041361\n",
      "Training loss per 100 training steps: 0.09769665652957873\n",
      "Training loss per 100 training steps: 0.09748832664060093\n",
      "Training loss per 100 training steps: 0.09761065865557172\n",
      "Training loss per 100 training steps: 0.0976862050731111\n",
      "Training loss per 100 training steps: 0.0977030638438079\n",
      "Training loss per 100 training steps: 0.09756148011297278\n",
      "Training loss epoch: 0.09752123273709534\n",
      "Training accuracy epoch: 0.9845493897986857\n",
      "------------------------------------2-----------------------------------\n",
      "Training loss per 100 training steps: 8.08794648037292e-05\n",
      "Training loss per 100 training steps: 0.00022786156640193278\n",
      "Training loss per 100 training steps: 0.03860336862988388\n",
      "Training loss per 100 training steps: 0.05725848270560883\n",
      "Training loss per 100 training steps: 0.07849082588718216\n",
      "Training loss per 100 training steps: 0.08752149691117266\n",
      "Training loss per 100 training steps: 0.09566124142555224\n",
      "Training loss per 100 training steps: 0.09854034422733741\n",
      "Training loss per 100 training steps: 0.08917031542515087\n",
      "Training loss per 100 training steps: 0.08532550894261748\n",
      "Training loss per 100 training steps: 0.0799669602761028\n",
      "Training loss per 100 training steps: 0.07337852980705399\n",
      "Training loss per 100 training steps: 0.06737623044485809\n",
      "Training loss per 100 training steps: 0.07034509113641403\n",
      "Training loss per 100 training steps: 0.06765727511088435\n",
      "Training loss per 100 training steps: 0.06894476156724375\n",
      "Training loss per 100 training steps: 0.06992404845738061\n",
      "Training loss per 100 training steps: 0.07738040754832345\n",
      "Training loss per 100 training steps: 0.07565772940046628\n",
      "Training loss per 100 training steps: 0.07292742180025441\n",
      "Training loss per 100 training steps: 0.07198142716585026\n",
      "Training loss per 100 training steps: 0.07149041781188674\n",
      "Training loss per 100 training steps: 0.0684205577819606\n",
      "Training loss per 100 training steps: 0.07051955160757403\n",
      "Training loss per 100 training steps: 0.06874719216241695\n",
      "Training loss per 100 training steps: 0.06962675213615221\n",
      "Training loss per 100 training steps: 0.07080308947111079\n",
      "Training loss per 100 training steps: 0.07342575915095721\n",
      "Training loss per 100 training steps: 0.07450441940898636\n",
      "Training loss per 100 training steps: 0.07390351736311858\n",
      "Training loss per 100 training steps: 0.07240394083856615\n",
      "Training loss per 100 training steps: 0.072855704133682\n",
      "Training loss per 100 training steps: 0.07423785818668664\n",
      "Training loss per 100 training steps: 0.07247101426163119\n",
      "Training loss per 100 training steps: 0.07237243275395822\n",
      "Training loss per 100 training steps: 0.07293867862074119\n",
      "Training loss per 100 training steps: 0.07322589553069916\n",
      "Training loss per 100 training steps: 0.07337151043212627\n",
      "Training loss per 100 training steps: 0.07388801290252138\n",
      "Training loss per 100 training steps: 0.0737741791457119\n",
      "Training loss per 100 training steps: 0.07603798308098335\n",
      "Training loss per 100 training steps: 0.0751198105044768\n",
      "Training loss per 100 training steps: 0.07551176156244618\n",
      "Training loss per 100 training steps: 0.07764875855221985\n",
      "Training loss per 100 training steps: 0.0794437263179908\n",
      "Training loss per 100 training steps: 0.08039403225743609\n",
      "Training loss per 100 training steps: 0.07984908517959663\n",
      "Training loss per 100 training steps: 0.07915469646933004\n",
      "Training loss per 100 training steps: 0.08016944047203968\n",
      "Training loss per 100 training steps: 0.08055208571877888\n",
      "Training loss per 100 training steps: 0.0798993124135728\n",
      "Training loss per 100 training steps: 0.07956718548631259\n",
      "Training loss per 100 training steps: 0.07932631670839843\n",
      "Training loss per 100 training steps: 0.0799312336831279\n",
      "Training loss per 100 training steps: 0.07901601610845911\n",
      "Training loss per 100 training steps: 0.07942600358959473\n",
      "Training loss per 100 training steps: 0.07916000691518822\n",
      "Training loss per 100 training steps: 0.079081428024213\n",
      "Training loss per 100 training steps: 0.07824881718993655\n",
      "Training loss per 100 training steps: 0.0779778172091008\n",
      "Training loss per 100 training steps: 0.07740147307959841\n",
      "Training loss per 100 training steps: 0.07810989706413873\n",
      "Training loss per 100 training steps: 0.07925263764775278\n",
      "Training loss per 100 training steps: 0.07877786357867209\n",
      "Training loss per 100 training steps: 0.07987670317195679\n",
      "Training loss per 100 training steps: 0.07924891145002795\n",
      "Training loss per 100 training steps: 0.07974270459928885\n",
      "Training loss per 100 training steps: 0.07999860502098877\n",
      "Training loss per 100 training steps: 0.07961459997548595\n",
      "Training loss per 100 training steps: 0.08076590592879025\n",
      "Training loss per 100 training steps: 0.08065518519531742\n",
      "Training loss per 100 training steps: 0.08053628072823447\n",
      "Training loss per 100 training steps: 0.08058724628416815\n",
      "Training loss per 100 training steps: 0.08061358804065599\n",
      "Training loss per 100 training steps: 0.08046846593376783\n",
      "Training loss per 100 training steps: 0.07955759566210735\n",
      "Training loss per 100 training steps: 0.07904059722050566\n",
      "Training loss per 100 training steps: 0.0788391212009451\n",
      "Training loss per 100 training steps: 0.07828023828451998\n",
      "Training loss per 100 training steps: 0.07781240100028029\n",
      "Training loss per 100 training steps: 0.0784739524695079\n",
      "Training loss per 100 training steps: 0.07877024793012087\n",
      "Training loss per 100 training steps: 0.07907026209118673\n",
      "Training loss per 100 training steps: 0.08019668087508136\n",
      "Training loss per 100 training steps: 0.08159361551111155\n",
      "Training loss per 100 training steps: 0.08224824312551844\n",
      "Training loss per 100 training steps: 0.08177301523933492\n",
      "Training loss per 100 training steps: 0.08218085774555849\n",
      "Training loss per 100 training steps: 0.08199191976539244\n",
      "Training loss per 100 training steps: 0.08235224558057991\n",
      "Training loss per 100 training steps: 0.08269851046677357\n",
      "Training loss per 100 training steps: 0.0821593085223342\n",
      "Training loss per 100 training steps: 0.08258060679932208\n",
      "Training loss per 100 training steps: 0.08222249114213961\n",
      "Training loss per 100 training steps: 0.08214315067762283\n",
      "Training loss per 100 training steps: 0.08198763036227787\n",
      "Training loss per 100 training steps: 0.08184578443637631\n",
      "Training loss per 100 training steps: 0.08129622342167633\n",
      "Training loss per 100 training steps: 0.08085458178066024\n",
      "Training loss per 100 training steps: 0.08073604960847751\n",
      "Training loss per 100 training steps: 0.08161099907192847\n",
      "Training loss per 100 training steps: 0.08085187605438889\n",
      "Training loss per 100 training steps: 0.08109744841292753\n",
      "Training loss per 100 training steps: 0.08082448897939333\n",
      "Training loss per 100 training steps: 0.08122668132096901\n",
      "Training loss per 100 training steps: 0.0812807294496235\n",
      "Training loss per 100 training steps: 0.08204529551106102\n",
      "Training loss per 100 training steps: 0.0819745874610093\n",
      "Training loss per 100 training steps: 0.0815630805949661\n",
      "Training loss per 100 training steps: 0.08107765410098684\n",
      "Training loss per 100 training steps: 0.08181962708303564\n",
      "Training loss per 100 training steps: 0.08196459179290007\n",
      "Training loss per 100 training steps: 0.08246525829662438\n",
      "Training loss per 100 training steps: 0.08259334733351117\n",
      "Training loss per 100 training steps: 0.08228914157865519\n",
      "Training loss per 100 training steps: 0.0817835100387565\n",
      "Training loss per 100 training steps: 0.08187253992338177\n",
      "Training loss per 100 training steps: 0.0815157396226054\n",
      "Training loss per 100 training steps: 0.08174250347491817\n",
      "Training loss per 100 training steps: 0.08132382859691988\n",
      "Training loss per 100 training steps: 0.0807429139891886\n",
      "Training loss per 100 training steps: 0.08066408014725433\n",
      "Training loss per 100 training steps: 0.08093627589776242\n",
      "Training loss per 100 training steps: 0.08123195150557866\n",
      "Training loss per 100 training steps: 0.08108776291730678\n",
      "Training loss per 100 training steps: 0.0813474675098372\n",
      "Training loss per 100 training steps: 0.08114886591128145\n",
      "Training loss per 100 training steps: 0.08073434882554446\n",
      "Training loss per 100 training steps: 0.08013018249347494\n",
      "Training loss per 100 training steps: 0.08031674166065986\n",
      "Training loss per 100 training steps: 0.0800083190947954\n",
      "Training loss per 100 training steps: 0.07951139452084952\n",
      "Training loss per 100 training steps: 0.07900967852224766\n",
      "Training loss per 100 training steps: 0.07849515861568943\n",
      "Training loss per 100 training steps: 0.07829411483331307\n",
      "Training loss per 100 training steps: 0.07813053780297662\n",
      "Training loss per 100 training steps: 0.07759846379502848\n",
      "Training loss per 100 training steps: 0.07724568425987574\n",
      "Training loss per 100 training steps: 0.07699443980045777\n",
      "Training loss per 100 training steps: 0.07700513004483142\n",
      "Training loss per 100 training steps: 0.07685640916810332\n",
      "Training loss per 100 training steps: 0.07650476626783524\n",
      "Training loss per 100 training steps: 0.07650385029260451\n",
      "Training loss per 100 training steps: 0.07666906723433205\n",
      "Training loss per 100 training steps: 0.0765776407497715\n",
      "Training loss per 100 training steps: 0.07609217551371909\n",
      "Training loss per 100 training steps: 0.0759770044559884\n",
      "Training loss per 100 training steps: 0.07587979090087217\n",
      "Training loss per 100 training steps: 0.07541233021689388\n",
      "Training loss per 100 training steps: 0.07493694602162287\n",
      "Training loss per 100 training steps: 0.0748122463472227\n",
      "Training loss per 100 training steps: 0.07483294497995409\n",
      "Training loss per 100 training steps: 0.07520331886250382\n",
      "Training loss per 100 training steps: 0.07525491503611667\n",
      "Training loss per 100 training steps: 0.07549155613831467\n",
      "Training loss per 100 training steps: 0.07539030719028367\n",
      "Training loss per 100 training steps: 0.0756355113908971\n",
      "Training loss per 100 training steps: 0.07521811865640302\n",
      "Training loss per 100 training steps: 0.07507600287372193\n",
      "Training loss per 100 training steps: 0.07499836657786912\n",
      "Training loss per 100 training steps: 0.07570492452700726\n",
      "Training loss per 100 training steps: 0.07543999479452933\n",
      "Training loss per 100 training steps: 0.0760166288288185\n",
      "Training loss per 100 training steps: 0.07663893875227723\n",
      "Training loss per 100 training steps: 0.07642307762418006\n",
      "Training loss per 100 training steps: 0.07611752071738885\n",
      "Training loss per 100 training steps: 0.07621351578471663\n",
      "Training loss per 100 training steps: 0.07603362482860254\n",
      "Training loss per 100 training steps: 0.07596961314277563\n",
      "Training loss per 100 training steps: 0.07601334932169576\n",
      "Training loss per 100 training steps: 0.07611081333104139\n",
      "Training loss per 100 training steps: 0.07636750022637062\n",
      "Training loss per 100 training steps: 0.0762228875568833\n",
      "Training loss per 100 training steps: 0.07648211091958708\n",
      "Training loss per 100 training steps: 0.07666450137441477\n",
      "Training loss per 100 training steps: 0.0764836954839524\n",
      "Training loss per 100 training steps: 0.07662436073021009\n",
      "Training loss per 100 training steps: 0.07643480858382744\n",
      "Training loss per 100 training steps: 0.07607126096490158\n",
      "Training loss per 100 training steps: 0.07576013533135037\n",
      "Training loss per 100 training steps: 0.07556048915357422\n",
      "Training loss per 100 training steps: 0.07543702630765411\n",
      "Training loss per 100 training steps: 0.07537329231615174\n",
      "Training loss per 100 training steps: 0.07529644877713544\n",
      "Training loss per 100 training steps: 0.07559921577263769\n",
      "Training loss per 100 training steps: 0.07540703153560352\n",
      "Training loss per 100 training steps: 0.07542856626145197\n",
      "Training loss per 100 training steps: 0.07528082819578018\n",
      "Training loss per 100 training steps: 0.07494857880347379\n",
      "Training loss per 100 training steps: 0.07507397700606573\n",
      "Training loss per 100 training steps: 0.07502189764979589\n",
      "Training loss per 100 training steps: 0.07487990507631513\n",
      "Training loss per 100 training steps: 0.07496376231402943\n",
      "Training loss per 100 training steps: 0.07487012571518865\n",
      "Training loss per 100 training steps: 0.07455036979545639\n",
      "Training loss per 100 training steps: 0.07467504803545369\n",
      "Training loss per 100 training steps: 0.07467678833836544\n",
      "Training loss per 100 training steps: 0.07471282112604967\n",
      "Training loss per 100 training steps: 0.07437569727321064\n",
      "Training loss per 100 training steps: 0.07411343252859792\n",
      "Training loss per 100 training steps: 0.07398043675611697\n",
      "Training loss per 100 training steps: 0.0742691281205728\n",
      "Training loss per 100 training steps: 0.0740790470853517\n",
      "Training loss per 100 training steps: 0.07445376915108004\n",
      "Training loss per 100 training steps: 0.07454961391133393\n",
      "Training loss per 100 training steps: 0.07469015555061163\n",
      "Training loss per 100 training steps: 0.0745090527530865\n",
      "Training loss per 100 training steps: 0.07495972143918903\n",
      "Training loss per 100 training steps: 0.07471153510167297\n",
      "Training loss per 100 training steps: 0.0748845269884848\n",
      "Training loss per 100 training steps: 0.07470078378816444\n",
      "Training loss per 100 training steps: 0.0746677056271872\n",
      "Training loss per 100 training steps: 0.07491924215495246\n",
      "Training loss per 100 training steps: 0.07472775031092924\n",
      "Training loss per 100 training steps: 0.07455146287899259\n",
      "Training loss per 100 training steps: 0.07471633705320042\n",
      "Training loss per 100 training steps: 0.07470103979505398\n",
      "Training loss per 100 training steps: 0.07474255546754584\n",
      "Training loss per 100 training steps: 0.0746522583926602\n",
      "Training loss per 100 training steps: 0.0747742488281911\n",
      "Training loss per 100 training steps: 0.07473345914343925\n",
      "Training loss per 100 training steps: 0.07475021435534544\n",
      "Training loss per 100 training steps: 0.07470099385554778\n",
      "Training loss per 100 training steps: 0.07473910343284211\n",
      "Training loss per 100 training steps: 0.07485089214314096\n",
      "Training loss per 100 training steps: 0.07453737203499779\n",
      "Training loss per 100 training steps: 0.07450411260939974\n",
      "Training loss per 100 training steps: 0.07426869555861393\n",
      "Training loss per 100 training steps: 0.07468823234181692\n",
      "Training loss per 100 training steps: 0.07442870211877281\n",
      "Training loss per 100 training steps: 0.07430802288916938\n",
      "Training loss per 100 training steps: 0.07419621924751908\n",
      "Training loss per 100 training steps: 0.07389184440222493\n",
      "Training loss per 100 training steps: 0.07374657320640707\n",
      "Training loss per 100 training steps: 0.0740737636932216\n",
      "Training loss per 100 training steps: 0.0743781060486052\n",
      "Training loss per 100 training steps: 0.0740994080778805\n",
      "Training loss per 100 training steps: 0.07393939486374576\n",
      "Training loss per 100 training steps: 0.07365732699885895\n",
      "Training loss per 100 training steps: 0.07384338316480184\n",
      "Training loss per 100 training steps: 0.07401844389966084\n",
      "Training loss per 100 training steps: 0.07378118839879928\n",
      "Training loss per 100 training steps: 0.07406063194051672\n",
      "Training loss per 100 training steps: 0.0739087724853248\n",
      "Training loss per 100 training steps: 0.07397386071659372\n",
      "Training loss per 100 training steps: 0.07406003299979308\n",
      "Training loss per 100 training steps: 0.07394650265810464\n",
      "Training loss per 100 training steps: 0.07370032793427703\n",
      "Training loss per 100 training steps: 0.07398737415646044\n",
      "Training loss per 100 training steps: 0.07443658930455961\n",
      "Training loss per 100 training steps: 0.07434086138214403\n",
      "Training loss per 100 training steps: 0.07466222609745693\n",
      "Training loss per 100 training steps: 0.07453334841032724\n",
      "Training loss per 100 training steps: 0.07438961220967577\n",
      "Training loss per 100 training steps: 0.07460027944243981\n",
      "Training loss per 100 training steps: 0.07475911038751043\n",
      "Training loss per 100 training steps: 0.07466912144417985\n",
      "Training loss per 100 training steps: 0.07446470530938128\n",
      "Training loss per 100 training steps: 0.07459094036723933\n",
      "Training loss per 100 training steps: 0.07458569157879191\n",
      "Training loss per 100 training steps: 0.07433764216867544\n",
      "Training loss per 100 training steps: 0.0743247981466934\n",
      "Training loss per 100 training steps: 0.07440520324328241\n",
      "Training loss per 100 training steps: 0.0742146851541936\n",
      "Training loss per 100 training steps: 0.07412936535000249\n",
      "Training loss per 100 training steps: 0.07418699561903302\n",
      "Training loss per 100 training steps: 0.07393062177676794\n",
      "Training loss per 100 training steps: 0.07387153549818035\n",
      "Training loss per 100 training steps: 0.073941943736903\n",
      "Training loss per 100 training steps: 0.07392226956657547\n",
      "Training loss per 100 training steps: 0.07380906218346488\n",
      "Training loss per 100 training steps: 0.07368505039593871\n",
      "Training loss per 100 training steps: 0.07392419805297801\n",
      "Training loss per 100 training steps: 0.07388332029530095\n",
      "Training loss per 100 training steps: 0.07369786230566215\n",
      "Training loss per 100 training steps: 0.07353552560435388\n",
      "Training loss per 100 training steps: 0.07333422967593844\n",
      "Training loss per 100 training steps: 0.07321285894143675\n",
      "Training loss per 100 training steps: 0.07301108766867183\n",
      "Training loss per 100 training steps: 0.07291841801812783\n",
      "Training loss per 100 training steps: 0.07280559161688105\n",
      "Training loss per 100 training steps: 0.07258025355691525\n",
      "Training loss per 100 training steps: 0.07236615641842097\n",
      "Training loss per 100 training steps: 0.07236360644989602\n",
      "Training loss per 100 training steps: 0.07221036812928028\n",
      "Training loss per 100 training steps: 0.07214806892122012\n",
      "Training loss per 100 training steps: 0.07199474419829649\n",
      "Training loss per 100 training steps: 0.07212115720604267\n",
      "Training loss per 100 training steps: 0.07198659026989802\n",
      "Training loss per 100 training steps: 0.07200416472593717\n",
      "Training loss per 100 training steps: 0.07213006165022467\n",
      "Training loss per 100 training steps: 0.07211108774372371\n",
      "Training loss per 100 training steps: 0.07205002482339479\n",
      "Training loss per 100 training steps: 0.07216948021090484\n",
      "Training loss per 100 training steps: 0.07197446092309912\n",
      "Training loss per 100 training steps: 0.07214858324163824\n",
      "Training loss per 100 training steps: 0.07228252895553654\n",
      "Training loss per 100 training steps: 0.0723835851938756\n",
      "Training loss per 100 training steps: 0.0726340680447276\n",
      "Training loss per 100 training steps: 0.07256301036056882\n",
      "Training loss per 100 training steps: 0.0727443620781699\n",
      "Training loss per 100 training steps: 0.07268470990131236\n",
      "Training loss per 100 training steps: 0.07268981997308631\n",
      "Training loss per 100 training steps: 0.07262193726453396\n",
      "Training loss per 100 training steps: 0.0726404518539335\n",
      "Training loss per 100 training steps: 0.07256225466365901\n",
      "Training loss per 100 training steps: 0.07244722928759348\n",
      "Training loss per 100 training steps: 0.07229431369996807\n",
      "Training loss per 100 training steps: 0.07276314058857258\n",
      "Training loss per 100 training steps: 0.07304887402201023\n",
      "Training loss per 100 training steps: 0.07317147810587359\n",
      "Training loss per 100 training steps: 0.07299853385342396\n",
      "Training loss per 100 training steps: 0.07300433333561746\n",
      "Training loss per 100 training steps: 0.0728226190208221\n",
      "Training loss per 100 training steps: 0.07335818449203396\n",
      "Training loss per 100 training steps: 0.07339286565655168\n",
      "Training loss per 100 training steps: 0.07347060500397072\n",
      "Training loss per 100 training steps: 0.07344054109600291\n",
      "Training loss per 100 training steps: 0.07352924106223284\n",
      "Training loss per 100 training steps: 0.0734503931397669\n",
      "Training loss per 100 training steps: 0.07333209514289381\n",
      "Training loss per 100 training steps: 0.07322547439521929\n",
      "Training loss per 100 training steps: 0.07316401235660139\n",
      "Training loss per 100 training steps: 0.07304591602740784\n",
      "Training loss per 100 training steps: 0.07303317920106185\n",
      "Training loss per 100 training steps: 0.07291289366712671\n",
      "Training loss per 100 training steps: 0.07285153001759477\n",
      "Training loss per 100 training steps: 0.07287494244586629\n",
      "Training loss per 100 training steps: 0.07277456870231051\n",
      "Training loss per 100 training steps: 0.07282888449059245\n",
      "Training loss per 100 training steps: 0.07295272074169853\n",
      "Training loss per 100 training steps: 0.07283344739731053\n",
      "Training loss per 100 training steps: 0.07293661158980334\n",
      "Training loss per 100 training steps: 0.07283729350896471\n",
      "Training loss per 100 training steps: 0.07295537248306692\n",
      "Training loss per 100 training steps: 0.07284206973341971\n",
      "Training loss per 100 training steps: 0.07276010182487125\n",
      "Training loss per 100 training steps: 0.07261207599182617\n",
      "Training loss per 100 training steps: 0.07257694946493311\n",
      "Training loss per 100 training steps: 0.07261877192847642\n",
      "Training loss per 100 training steps: 0.07248523216993503\n",
      "Training loss per 100 training steps: 0.07243478639904935\n",
      "Training loss per 100 training steps: 0.07225217036461604\n",
      "Training loss per 100 training steps: 0.07219736470523395\n",
      "Training loss per 100 training steps: 0.07223339634537886\n",
      "Training loss per 100 training steps: 0.07213421634898608\n",
      "Training loss per 100 training steps: 0.07200636974932706\n",
      "Training loss per 100 training steps: 0.07198319944727376\n",
      "Training loss per 100 training steps: 0.07179860075002308\n",
      "Training loss per 100 training steps: 0.07166560125938778\n",
      "Training loss per 100 training steps: 0.07146936698948023\n",
      "Training loss per 100 training steps: 0.0713754161923287\n",
      "Training loss per 100 training steps: 0.07143225381047481\n",
      "Training loss per 100 training steps: 0.071245069657469\n",
      "Training loss per 100 training steps: 0.07109490312905639\n",
      "Training loss per 100 training steps: 0.07136726591442513\n",
      "Training loss per 100 training steps: 0.07143259559884337\n",
      "Training loss per 100 training steps: 0.07137817039236986\n",
      "Training loss per 100 training steps: 0.07137795104410286\n",
      "Training loss per 100 training steps: 0.07132661728149535\n",
      "Training loss per 100 training steps: 0.07139300927044981\n",
      "Training loss per 100 training steps: 0.07126698648138619\n",
      "Training loss per 100 training steps: 0.07140302289062737\n",
      "Training loss per 100 training steps: 0.0714615852490814\n",
      "Training loss per 100 training steps: 0.07147482738687679\n",
      "Training loss per 100 training steps: 0.07130508665957906\n",
      "Training loss per 100 training steps: 0.0712037738020122\n",
      "Training loss per 100 training steps: 0.07120377207675893\n",
      "Training loss per 100 training steps: 0.07104526909080856\n",
      "Training loss per 100 training steps: 0.0711616216966622\n",
      "Training loss per 100 training steps: 0.07132011574410968\n",
      "Training loss per 100 training steps: 0.07138964355115877\n",
      "Training loss per 100 training steps: 0.07128415506656675\n",
      "Training loss per 100 training steps: 0.07125188898198943\n",
      "Training loss per 100 training steps: 0.07110065921597714\n",
      "Training loss per 100 training steps: 0.07104488731371113\n",
      "Training loss per 100 training steps: 0.07092820916597604\n",
      "Training loss per 100 training steps: 0.0712166737160102\n",
      "Training loss per 100 training steps: 0.0713586657947838\n",
      "Training loss per 100 training steps: 0.07141864025364508\n",
      "Training loss per 100 training steps: 0.0713263783230318\n",
      "Training loss per 100 training steps: 0.07121628863180111\n",
      "Training loss per 100 training steps: 0.07113943191434781\n",
      "Training loss per 100 training steps: 0.0710223199410944\n",
      "Training loss epoch: 0.07104861012354469\n",
      "Training accuracy epoch: 0.9881871284030458\n",
      "------------------------------------3-----------------------------------\n",
      "Training loss per 100 training steps: 9.649443381931633e-05\n",
      "Training loss per 100 training steps: 0.0316584033598071\n",
      "Training loss per 100 training steps: 0.01862073783113781\n",
      "Training loss per 100 training steps: 0.034754602438624715\n",
      "Training loss per 100 training steps: 0.050500626424872914\n",
      "Training loss per 100 training steps: 0.04500964096939447\n",
      "Training loss per 100 training steps: 0.041652943741496716\n",
      "Training loss per 100 training steps: 0.04095118195096249\n",
      "Training loss per 100 training steps: 0.0459721461015914\n",
      "Training loss per 100 training steps: 0.047467736576278965\n",
      "Training loss per 100 training steps: 0.04826945923173503\n",
      "Training loss per 100 training steps: 0.051046881649652855\n",
      "Training loss per 100 training steps: 0.057287453811741454\n",
      "Training loss per 100 training steps: 0.05377625333803777\n",
      "Training loss per 100 training steps: 0.050651289554054964\n",
      "Training loss per 100 training steps: 0.052711939132548735\n",
      "Training loss per 100 training steps: 0.061471277305220534\n",
      "Training loss per 100 training steps: 0.0643561377923997\n",
      "Training loss per 100 training steps: 0.061703819950977505\n",
      "Training loss per 100 training steps: 0.0616762082769484\n",
      "Training loss per 100 training steps: 0.06226028193008881\n",
      "Training loss per 100 training steps: 0.06271499583957175\n",
      "Training loss per 100 training steps: 0.06276498492134033\n",
      "Training loss per 100 training steps: 0.06186899940931795\n",
      "Training loss per 100 training steps: 0.060817586476774946\n",
      "Training loss per 100 training steps: 0.06161881508934947\n",
      "Training loss per 100 training steps: 0.061071599232972076\n",
      "Training loss per 100 training steps: 0.0589470473786969\n",
      "Training loss per 100 training steps: 0.05987898028760888\n",
      "Training loss per 100 training steps: 0.06014262841819586\n",
      "Training loss per 100 training steps: 0.060491029337772784\n",
      "Training loss per 100 training steps: 0.06067915679511056\n",
      "Training loss per 100 training steps: 0.06211635536699217\n",
      "Training loss per 100 training steps: 0.06640568521748745\n",
      "Training loss per 100 training steps: 0.06523375568786076\n",
      "Training loss per 100 training steps: 0.06631552169087987\n",
      "Training loss per 100 training steps: 0.06632630522995599\n",
      "Training loss per 100 training steps: 0.06732404336962305\n",
      "Training loss per 100 training steps: 0.06602014272051636\n",
      "Training loss per 100 training steps: 0.06650781819346478\n",
      "Training loss per 100 training steps: 0.06570055240270128\n",
      "Training loss per 100 training steps: 0.06467502653785984\n",
      "Training loss per 100 training steps: 0.06461315489474881\n",
      "Training loss per 100 training steps: 0.06423331940407893\n",
      "Training loss per 100 training steps: 0.06345314516643788\n",
      "Training loss per 100 training steps: 0.06222696605507397\n",
      "Training loss per 100 training steps: 0.06197957313459363\n",
      "Training loss per 100 training steps: 0.06224359629808177\n",
      "Training loss per 100 training steps: 0.06255435476990451\n",
      "Training loss per 100 training steps: 0.06263186881402207\n",
      "Training loss per 100 training steps: 0.06172999952242835\n",
      "Training loss per 100 training steps: 0.06055340329100851\n",
      "Training loss per 100 training steps: 0.06253511704863018\n",
      "Training loss per 100 training steps: 0.06306689651586997\n",
      "Training loss per 100 training steps: 0.062177308439437626\n",
      "Training loss per 100 training steps: 0.06160388335434746\n",
      "Training loss per 100 training steps: 0.061526827470524625\n",
      "Training loss per 100 training steps: 0.06075652601201646\n",
      "Training loss per 100 training steps: 0.06255384358212714\n",
      "Training loss per 100 training steps: 0.06225393051072275\n",
      "Training loss per 100 training steps: 0.06130168558389296\n",
      "Training loss per 100 training steps: 0.061095563969514634\n",
      "Training loss per 100 training steps: 0.06130746653254508\n",
      "Training loss per 100 training steps: 0.061325611512275176\n",
      "Training loss per 100 training steps: 0.06073704522029992\n",
      "Training loss per 100 training steps: 0.05988120841058974\n",
      "Training loss per 100 training steps: 0.059798493486134155\n",
      "Training loss per 100 training steps: 0.059474381293773124\n",
      "Training loss per 100 training steps: 0.058943795981256555\n",
      "Training loss per 100 training steps: 0.058692501701116055\n",
      "Training loss per 100 training steps: 0.05968239878979655\n",
      "Training loss per 100 training steps: 0.0590338942196768\n",
      "Training loss per 100 training steps: 0.059301251301137496\n",
      "Training loss per 100 training steps: 0.060002860994287546\n",
      "Training loss per 100 training steps: 0.05954716606217191\n",
      "Training loss per 100 training steps: 0.0594269502377703\n",
      "Training loss per 100 training steps: 0.05902932515594656\n",
      "Training loss per 100 training steps: 0.059134812370055224\n",
      "Training loss per 100 training steps: 0.058969218074475305\n",
      "Training loss per 100 training steps: 0.05887640339940519\n",
      "Training loss per 100 training steps: 0.05849953744835193\n",
      "Training loss per 100 training steps: 0.05784247308672046\n",
      "Training loss per 100 training steps: 0.05824949114160293\n",
      "Training loss per 100 training steps: 0.05779349157237222\n",
      "Training loss per 100 training steps: 0.058578464896689685\n",
      "Training loss per 100 training steps: 0.059094368134234854\n",
      "Training loss per 100 training steps: 0.05876308495351967\n",
      "Training loss per 100 training steps: 0.05809940477613041\n",
      "Training loss per 100 training steps: 0.058353408740214656\n",
      "Training loss per 100 training steps: 0.058646423170740224\n",
      "Training loss per 100 training steps: 0.05918689778177152\n",
      "Training loss per 100 training steps: 0.059258474915021286\n",
      "Training loss per 100 training steps: 0.058881950553359416\n",
      "Training loss per 100 training steps: 0.058367860090041926\n",
      "Training loss per 100 training steps: 0.058383309866465\n",
      "Training loss per 100 training steps: 0.05846729392183791\n",
      "Training loss per 100 training steps: 0.05843835009712584\n",
      "Training loss per 100 training steps: 0.058161409191519506\n",
      "Training loss per 100 training steps: 0.05839369594515486\n",
      "Training loss per 100 training steps: 0.05823103359677009\n",
      "Training loss per 100 training steps: 0.05824482266396137\n",
      "Training loss per 100 training steps: 0.05774811425997424\n",
      "Training loss per 100 training steps: 0.05778068519272212\n",
      "Training loss per 100 training steps: 0.05787991163816295\n",
      "Training loss per 100 training steps: 0.058157905666417216\n",
      "Training loss per 100 training steps: 0.05797400811071873\n",
      "Training loss per 100 training steps: 0.05751285362403835\n",
      "Training loss per 100 training steps: 0.0570991442851185\n",
      "Training loss per 100 training steps: 0.05685127862814851\n",
      "Training loss per 100 training steps: 0.05751605135443096\n",
      "Training loss per 100 training steps: 0.05717009502923477\n",
      "Training loss per 100 training steps: 0.05758537540761567\n",
      "Training loss per 100 training steps: 0.0576235558235076\n",
      "Training loss per 100 training steps: 0.05793913922775535\n",
      "Training loss per 100 training steps: 0.05754586404870707\n",
      "Training loss per 100 training steps: 0.05751646782064414\n",
      "Training loss per 100 training steps: 0.05736240028519384\n",
      "Training loss per 100 training steps: 0.05723387473928977\n",
      "Training loss per 100 training steps: 0.056836980253367815\n",
      "Training loss per 100 training steps: 0.05638751072277779\n",
      "Training loss per 100 training steps: 0.056068472231782115\n",
      "Training loss per 100 training steps: 0.055750421359790296\n",
      "Training loss per 100 training steps: 0.05596316632380715\n",
      "Training loss per 100 training steps: 0.05618424942075367\n",
      "Training loss per 100 training steps: 0.05603822212320857\n",
      "Training loss per 100 training steps: 0.05597517266677272\n",
      "Training loss per 100 training steps: 0.05603428135771271\n",
      "Training loss per 100 training steps: 0.05560742898818844\n",
      "Training loss per 100 training steps: 0.05546892653882404\n",
      "Training loss per 100 training steps: 0.05598562012376686\n",
      "Training loss per 100 training steps: 0.05605875934334411\n",
      "Training loss per 100 training steps: 0.055774806386174325\n",
      "Training loss per 100 training steps: 0.055496596321580646\n",
      "Training loss per 100 training steps: 0.05512649473307441\n",
      "Training loss per 100 training steps: 0.05491187739086985\n",
      "Training loss per 100 training steps: 0.054668931271445655\n",
      "Training loss per 100 training steps: 0.054329412505604274\n",
      "Training loss per 100 training steps: 0.05432305738249773\n",
      "Training loss per 100 training steps: 0.054206714994729885\n",
      "Training loss per 100 training steps: 0.05435648172807943\n",
      "Training loss per 100 training steps: 0.05407246160820538\n",
      "Training loss per 100 training steps: 0.05443547940829308\n",
      "Training loss per 100 training steps: 0.054880245716210654\n",
      "Training loss per 100 training steps: 0.055062270061692356\n",
      "Training loss per 100 training steps: 0.05480274256716676\n",
      "Training loss per 100 training steps: 0.05529846150020311\n",
      "Training loss per 100 training steps: 0.0549717575709375\n",
      "Training loss per 100 training steps: 0.05497615819898327\n",
      "Training loss per 100 training steps: 0.054669906701177134\n",
      "Training loss per 100 training steps: 0.05435314420294468\n",
      "Training loss per 100 training steps: 0.054615683909927194\n",
      "Training loss per 100 training steps: 0.05471515374505858\n",
      "Training loss per 100 training steps: 0.05528272333854681\n",
      "Training loss per 100 training steps: 0.055049776724601346\n",
      "Training loss per 100 training steps: 0.054716181000012895\n",
      "Training loss per 100 training steps: 0.054490423061612524\n",
      "Training loss per 100 training steps: 0.05469293147511472\n",
      "Training loss per 100 training steps: 0.05461013917966501\n",
      "Training loss per 100 training steps: 0.05444514274705025\n",
      "Training loss per 100 training steps: 0.05440138336270736\n",
      "Training loss per 100 training steps: 0.05414994270763805\n",
      "Training loss per 100 training steps: 0.053883526180211055\n",
      "Training loss per 100 training steps: 0.053707056219605816\n",
      "Training loss per 100 training steps: 0.05390555232405219\n",
      "Training loss per 100 training steps: 0.0539404888921542\n",
      "Training loss per 100 training steps: 0.054054555664165935\n",
      "Training loss per 100 training steps: 0.054152559262475294\n",
      "Training loss per 100 training steps: 0.05395547033864985\n",
      "Training loss per 100 training steps: 0.054722259037906125\n",
      "Training loss per 100 training steps: 0.05471153822862972\n",
      "Training loss per 100 training steps: 0.05442302539928096\n",
      "Training loss per 100 training steps: 0.05421028463124538\n",
      "Training loss per 100 training steps: 0.05391718216855322\n",
      "Training loss per 100 training steps: 0.053738363882796854\n",
      "Training loss per 100 training steps: 0.053689984779049085\n",
      "Training loss per 100 training steps: 0.053912387186959315\n",
      "Training loss per 100 training steps: 0.05393442262993632\n",
      "Training loss per 100 training steps: 0.053735764621922234\n",
      "Training loss per 100 training steps: 0.05388467457393621\n",
      "Training loss per 100 training steps: 0.05366483013763138\n",
      "Training loss per 100 training steps: 0.05358188854199279\n",
      "Training loss per 100 training steps: 0.05331508426948002\n",
      "Training loss per 100 training steps: 0.05307012892296215\n",
      "Training loss per 100 training steps: 0.05311502307662192\n",
      "Training loss per 100 training steps: 0.05320014103829522\n",
      "Training loss per 100 training steps: 0.05315884787510986\n",
      "Training loss per 100 training steps: 0.05308176023279178\n",
      "Training loss per 100 training steps: 0.05313319643036347\n",
      "Training loss per 100 training steps: 0.05287902019080172\n",
      "Training loss per 100 training steps: 0.052706702460885824\n",
      "Training loss per 100 training steps: 0.05256043506455934\n",
      "Training loss per 100 training steps: 0.05258940197600996\n",
      "Training loss per 100 training steps: 0.05281983021396901\n",
      "Training loss per 100 training steps: 0.05280011185937953\n",
      "Training loss per 100 training steps: 0.05280457918654042\n",
      "Training loss per 100 training steps: 0.05268037576549248\n",
      "Training loss per 100 training steps: 0.052621435750511925\n",
      "Training loss per 100 training steps: 0.0528224257037852\n",
      "Training loss per 100 training steps: 0.05265928459275038\n",
      "Training loss per 100 training steps: 0.05267232964747128\n",
      "Training loss per 100 training steps: 0.05253823822151385\n",
      "Training loss per 100 training steps: 0.05241708802839807\n",
      "Training loss per 100 training steps: 0.05244752492490948\n",
      "Training loss per 100 training steps: 0.052429828108831664\n",
      "Training loss per 100 training steps: 0.052359357006384305\n",
      "Training loss per 100 training steps: 0.05213096959638773\n",
      "Training loss per 100 training steps: 0.0519208456746547\n",
      "Training loss per 100 training steps: 0.05192193733761651\n",
      "Training loss per 100 training steps: 0.05178535248530837\n",
      "Training loss per 100 training steps: 0.05182707426723467\n",
      "Training loss per 100 training steps: 0.051772725196782124\n",
      "Training loss per 100 training steps: 0.05158950795728723\n",
      "Training loss per 100 training steps: 0.051696933784282986\n",
      "Training loss per 100 training steps: 0.051516289748561504\n",
      "Training loss per 100 training steps: 0.05142454533075936\n",
      "Training loss per 100 training steps: 0.051439458338540175\n",
      "Training loss per 100 training steps: 0.05150543967148304\n",
      "Training loss per 100 training steps: 0.05196920013190436\n",
      "Training loss per 100 training steps: 0.052048741498534966\n",
      "Training loss per 100 training steps: 0.052165299452472884\n",
      "Training loss per 100 training steps: 0.052182563239682934\n",
      "Training loss per 100 training steps: 0.05226571464726212\n",
      "Training loss per 100 training steps: 0.05269463391394491\n",
      "Training loss per 100 training steps: 0.052534916807630075\n",
      "Training loss per 100 training steps: 0.05249883001813092\n",
      "Training loss per 100 training steps: 0.05232521262329041\n",
      "Training loss per 100 training steps: 0.05233734907901536\n",
      "Training loss per 100 training steps: 0.052359693264637616\n",
      "Training loss per 100 training steps: 0.05246603548305239\n",
      "Training loss per 100 training steps: 0.052534797615790385\n",
      "Training loss per 100 training steps: 0.052761157780930365\n",
      "Training loss per 100 training steps: 0.05270880662829966\n",
      "Training loss per 100 training steps: 0.052641268954213886\n",
      "Training loss per 100 training steps: 0.05278105474731525\n",
      "Training loss per 100 training steps: 0.05271321274532018\n",
      "Training loss per 100 training steps: 0.05304324248635603\n",
      "Training loss per 100 training steps: 0.05303718127428089\n",
      "Training loss per 100 training steps: 0.05296393783989926\n",
      "Training loss per 100 training steps: 0.05279945747325117\n",
      "Training loss per 100 training steps: 0.05298813401045461\n",
      "Training loss per 100 training steps: 0.05279265975221073\n",
      "Training loss per 100 training steps: 0.052626931522467266\n",
      "Training loss per 100 training steps: 0.05266328585524619\n",
      "Training loss per 100 training steps: 0.05265275844712933\n",
      "Training loss per 100 training steps: 0.05246303002355434\n",
      "Training loss per 100 training steps: 0.05244797951726493\n",
      "Training loss per 100 training steps: 0.05241295874313517\n",
      "Training loss per 100 training steps: 0.05233081817081814\n",
      "Training loss per 100 training steps: 0.052340995879067466\n",
      "Training loss per 100 training steps: 0.052299116256807714\n",
      "Training loss per 100 training steps: 0.0524099350324117\n",
      "Training loss per 100 training steps: 0.05247083772398791\n",
      "Training loss per 100 training steps: 0.05268588301574138\n",
      "Training loss per 100 training steps: 0.05255143811941415\n",
      "Training loss per 100 training steps: 0.05249505191349833\n",
      "Training loss per 100 training steps: 0.052473572775458964\n",
      "Training loss per 100 training steps: 0.05243116123450157\n",
      "Training loss per 100 training steps: 0.05246912364011134\n",
      "Training loss per 100 training steps: 0.052370619145016305\n",
      "Training loss per 100 training steps: 0.05226065285527518\n",
      "Training loss per 100 training steps: 0.052321949712153044\n",
      "Training loss per 100 training steps: 0.052234117340949446\n",
      "Training loss per 100 training steps: 0.052223832667345\n",
      "Training loss per 100 training steps: 0.052257541053451796\n",
      "Training loss per 100 training steps: 0.052290745528986916\n",
      "Training loss per 100 training steps: 0.052354584684253254\n",
      "Training loss per 100 training steps: 0.052384525126243864\n",
      "Training loss per 100 training steps: 0.052365714283366574\n",
      "Training loss per 100 training steps: 0.05230868701998636\n",
      "Training loss per 100 training steps: 0.05231526191756815\n",
      "Training loss per 100 training steps: 0.05226330390077992\n",
      "Training loss per 100 training steps: 0.05243759120845437\n",
      "Training loss per 100 training steps: 0.052503487788763126\n",
      "Training loss per 100 training steps: 0.05244877251972259\n",
      "Training loss per 100 training steps: 0.052298286251489724\n",
      "Training loss per 100 training steps: 0.052203641008725966\n",
      "Training loss per 100 training steps: 0.05222881728601356\n",
      "Training loss per 100 training steps: 0.052129144435178854\n",
      "Training loss per 100 training steps: 0.05232022874397721\n",
      "Training loss per 100 training steps: 0.05221984321907357\n",
      "Training loss per 100 training steps: 0.05204827987011341\n",
      "Training loss per 100 training steps: 0.051917684669220324\n",
      "Training loss per 100 training steps: 0.0518645878466409\n",
      "Training loss per 100 training steps: 0.05198280147940309\n",
      "Training loss per 100 training steps: 0.05184769558528061\n",
      "Training loss per 100 training steps: 0.05184364892401135\n",
      "Training loss per 100 training steps: 0.05201420921193674\n",
      "Training loss per 100 training steps: 0.05200423323359772\n",
      "Training loss per 100 training steps: 0.051959985736978666\n",
      "Training loss per 100 training steps: 0.05232194745613428\n",
      "Training loss per 100 training steps: 0.05232109272996571\n",
      "Training loss per 100 training steps: 0.05246241417763213\n",
      "Training loss per 100 training steps: 0.05268044697653041\n",
      "Training loss per 100 training steps: 0.05266385992994277\n",
      "Training loss per 100 training steps: 0.05280967462828037\n",
      "Training loss per 100 training steps: 0.05284951617975452\n",
      "Training loss per 100 training steps: 0.052931515779934574\n",
      "Training loss per 100 training steps: 0.05296384537676187\n",
      "Training loss per 100 training steps: 0.0530051615009606\n",
      "Training loss per 100 training steps: 0.05312938920893096\n",
      "Training loss per 100 training steps: 0.05297618491981353\n",
      "Training loss per 100 training steps: 0.05295569560881075\n",
      "Training loss per 100 training steps: 0.05306727611565222\n",
      "Training loss per 100 training steps: 0.052991687096928815\n",
      "Training loss per 100 training steps: 0.05294731688651656\n",
      "Training loss per 100 training steps: 0.0529836088140822\n",
      "Training loss per 100 training steps: 0.05301825562871108\n",
      "Training loss per 100 training steps: 0.05310383580250304\n",
      "Training loss per 100 training steps: 0.05295977065694302\n",
      "Training loss per 100 training steps: 0.05349128351758611\n",
      "Training loss per 100 training steps: 0.053611512785629256\n",
      "Training loss per 100 training steps: 0.053614801587019534\n",
      "Training loss per 100 training steps: 0.05345117082983872\n",
      "Training loss per 100 training steps: 0.053326610199009354\n",
      "Training loss per 100 training steps: 0.0535275475447294\n",
      "Training loss per 100 training steps: 0.05359534326322022\n",
      "Training loss per 100 training steps: 0.053633462291953406\n",
      "Training loss per 100 training steps: 0.05361879841618315\n",
      "Training loss per 100 training steps: 0.05350737585204853\n",
      "Training loss per 100 training steps: 0.053611963668360685\n",
      "Training loss per 100 training steps: 0.053766086685977356\n",
      "Training loss per 100 training steps: 0.05364072791448431\n",
      "Training loss per 100 training steps: 0.053548741122354436\n",
      "Training loss per 100 training steps: 0.05343570375055756\n",
      "Training loss per 100 training steps: 0.05335438302770093\n",
      "Training loss per 100 training steps: 0.05347003176414648\n",
      "Training loss per 100 training steps: 0.05347515395079102\n",
      "Training loss per 100 training steps: 0.05333175266461965\n",
      "Training loss per 100 training steps: 0.053317392425715385\n",
      "Training loss per 100 training steps: 0.05326526080717985\n",
      "Training loss per 100 training steps: 0.05312240687866702\n",
      "Training loss per 100 training steps: 0.053048064906481264\n",
      "Training loss per 100 training steps: 0.05290140934125769\n",
      "Training loss per 100 training steps: 0.052997316318811584\n",
      "Training loss per 100 training steps: 0.0530199984277831\n",
      "Training loss per 100 training steps: 0.05300329330416265\n",
      "Training loss per 100 training steps: 0.05324225466071509\n",
      "Training loss per 100 training steps: 0.053156421539050404\n",
      "Training loss per 100 training steps: 0.05322592175640487\n",
      "Training loss per 100 training steps: 0.05311512010735626\n",
      "Training loss per 100 training steps: 0.05308806461977787\n",
      "Training loss per 100 training steps: 0.05321150442043251\n",
      "Training loss per 100 training steps: 0.053514488496286455\n",
      "Training loss per 100 training steps: 0.053451826785151424\n",
      "Training loss per 100 training steps: 0.05336801783680484\n",
      "Training loss per 100 training steps: 0.05338198471169144\n",
      "Training loss per 100 training steps: 0.053300825749039785\n",
      "Training loss per 100 training steps: 0.05336265147267165\n",
      "Training loss per 100 training steps: 0.05325044450621961\n",
      "Training loss per 100 training steps: 0.05333150464948927\n",
      "Training loss per 100 training steps: 0.05358719392216848\n",
      "Training loss per 100 training steps: 0.05358528806948629\n",
      "Training loss per 100 training steps: 0.05352839686996664\n",
      "Training loss per 100 training steps: 0.05347889353741446\n",
      "Training loss per 100 training steps: 0.05353546093038055\n",
      "Training loss per 100 training steps: 0.053516483838247\n",
      "Training loss per 100 training steps: 0.05369736642659497\n",
      "Training loss per 100 training steps: 0.05357468758226518\n",
      "Training loss per 100 training steps: 0.05354430194286219\n",
      "Training loss per 100 training steps: 0.053611262674940055\n",
      "Training loss per 100 training steps: 0.05371458193651307\n",
      "Training loss per 100 training steps: 0.05378444675561863\n",
      "Training loss per 100 training steps: 0.05370143354726486\n",
      "Training loss per 100 training steps: 0.053678760378376315\n",
      "Training loss per 100 training steps: 0.05372583819394958\n",
      "Training loss per 100 training steps: 0.053701543392606056\n",
      "Training loss per 100 training steps: 0.05381976606675142\n",
      "Training loss per 100 training steps: 0.053938539103290384\n",
      "Training loss per 100 training steps: 0.054105128295388195\n",
      "Training loss per 100 training steps: 0.054063631834211694\n",
      "Training loss per 100 training steps: 0.054047973966635\n",
      "Training loss per 100 training steps: 0.05432252611680284\n",
      "Training loss per 100 training steps: 0.05447277143112205\n",
      "Training loss per 100 training steps: 0.054355421245280144\n",
      "Training loss per 100 training steps: 0.05436923671406175\n",
      "Training loss per 100 training steps: 0.054253624052309574\n",
      "Training loss per 100 training steps: 0.054148994458719464\n",
      "Training loss per 100 training steps: 0.054069739529216405\n",
      "Training loss per 100 training steps: 0.05409124744597109\n",
      "Training loss per 100 training steps: 0.05427359725068027\n",
      "Training loss per 100 training steps: 0.05431909698343779\n",
      "Training loss per 100 training steps: 0.05433253409330739\n",
      "Training loss per 100 training steps: 0.054590899480888584\n",
      "Training loss per 100 training steps: 0.05447733390394389\n",
      "Training loss epoch: 0.054508878187174516\n",
      "Training accuracy epoch: 0.9905210180452696\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"------------------------------------{epoch}-----------------------------------\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "XLJNYAYFC_H8"
   },
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "          ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "          mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "          labels = batch['labels'].to(device, dtype = torch.long)\n",
    "          \n",
    "          outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "          loss = outputs[\"loss\"]\n",
    "          eval_logits = outputs[\"logits\"]\n",
    "          eval_loss += loss.item()\n",
    "          \n",
    "\n",
    "          nb_eval_steps += 1\n",
    "          nb_eval_examples += labels.size(0)\n",
    "      \n",
    "          if idx % 100==0:\n",
    "              loss_step = eval_loss/nb_eval_steps\n",
    "              print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "            \n",
    "          # compute evaluation accuracy\n",
    "          flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "          active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "          flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "          \n",
    "          # only compute accuracy at active labels\n",
    "          active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "      \n",
    "          labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "          predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "          \n",
    "          eval_labels.extend(labels)\n",
    "          eval_preds.extend(predictions)\n",
    "          \n",
    "          tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "          eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    labels = [[ids_to_labels[id.item()] for id in eval_labels]]\n",
    "    predictions = [[ids_to_labels[id.item()] for id in eval_preds]]\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "-h8fJRABDEJe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 1.168244216387393e-05\n",
      "Validation loss per 100 evaluation steps: 0.13412150904441028\n",
      "Validation loss per 100 evaluation steps: 0.16247626487168856\n",
      "Validation loss per 100 evaluation steps: 0.22640377243597956\n",
      "Validation loss per 100 evaluation steps: 0.2642820271459081\n",
      "Validation loss per 100 evaluation steps: 0.2383593474337086\n",
      "Validation loss per 100 evaluation steps: 0.20557518551231624\n",
      "Validation loss per 100 evaluation steps: 0.17637213623814008\n",
      "Validation loss per 100 evaluation steps: 0.17246732343368337\n",
      "Validation loss per 100 evaluation steps: 0.17125392522954658\n",
      "Validation loss per 100 evaluation steps: 0.1569979724415264\n",
      "Validation loss per 100 evaluation steps: 0.1490759808252324\n",
      "Validation loss per 100 evaluation steps: 0.14292974923054386\n",
      "Validation loss per 100 evaluation steps: 0.146244721324783\n",
      "Validation loss per 100 evaluation steps: 0.13643356720568453\n",
      "Validation loss per 100 evaluation steps: 0.14320098585479243\n",
      "Validation loss per 100 evaluation steps: 0.13627070889934906\n",
      "Validation loss per 100 evaluation steps: 0.1298096913703353\n",
      "Validation loss per 100 evaluation steps: 0.12304285981681794\n",
      "Validation loss per 100 evaluation steps: 0.1199686988999782\n",
      "Validation loss per 100 evaluation steps: 0.11819014200630798\n",
      "Validation loss per 100 evaluation steps: 0.11661407211956981\n",
      "Validation loss per 100 evaluation steps: 0.11602025347753374\n",
      "Validation loss per 100 evaluation steps: 0.1117380709596226\n",
      "Validation loss per 100 evaluation steps: 0.11252104697379149\n",
      "Validation loss per 100 evaluation steps: 0.1080415814938821\n",
      "Validation loss per 100 evaluation steps: 0.10477756151816188\n",
      "Validation loss per 100 evaluation steps: 0.10189845413559481\n",
      "Validation loss per 100 evaluation steps: 0.10202645424671783\n",
      "Validation loss per 100 evaluation steps: 0.09926175691662004\n",
      "Validation loss per 100 evaluation steps: 0.102294704356347\n",
      "Validation loss per 100 evaluation steps: 0.09918316653559985\n",
      "Validation loss per 100 evaluation steps: 0.09963623933418196\n",
      "Validation loss per 100 evaluation steps: 0.09684332411706714\n",
      "Validation loss per 100 evaluation steps: 0.09584842528134971\n",
      "Validation loss per 100 evaluation steps: 0.09487870338311637\n",
      "Validation loss per 100 evaluation steps: 0.0925683039658154\n",
      "Validation loss per 100 evaluation steps: 0.09161582765154037\n",
      "Validation loss per 100 evaluation steps: 0.0895149246078902\n",
      "Validation loss per 100 evaluation steps: 0.08777389205097799\n",
      "Validation loss per 100 evaluation steps: 0.085591016172009\n",
      "Validation loss per 100 evaluation steps: 0.08583339768234237\n",
      "Validation loss per 100 evaluation steps: 0.08449153739430494\n",
      "Validation loss per 100 evaluation steps: 0.08494833408301729\n",
      "Validation loss per 100 evaluation steps: 0.08317815112222252\n",
      "Validation loss per 100 evaluation steps: 0.08674875608172979\n",
      "Validation loss per 100 evaluation steps: 0.08857105154204234\n",
      "Validation loss per 100 evaluation steps: 0.08825238851610064\n",
      "Validation loss per 100 evaluation steps: 0.08757666400240548\n",
      "Validation loss per 100 evaluation steps: 0.08778524614559403\n",
      "Validation loss per 100 evaluation steps: 0.08847380356250023\n",
      "Validation loss per 100 evaluation steps: 0.08809269473235519\n",
      "Validation loss per 100 evaluation steps: 0.0886879055199845\n",
      "Validation loss per 100 evaluation steps: 0.08717415970864427\n",
      "Validation loss per 100 evaluation steps: 0.08731226941356895\n",
      "Validation loss per 100 evaluation steps: 0.08576014135935056\n",
      "Validation loss per 100 evaluation steps: 0.08621669788646644\n",
      "Validation loss per 100 evaluation steps: 0.08643280403016411\n",
      "Validation loss per 100 evaluation steps: 0.08580827951461667\n",
      "Validation loss per 100 evaluation steps: 0.084375554941711\n",
      "Validation loss per 100 evaluation steps: 0.08312635986968622\n",
      "Validation loss per 100 evaluation steps: 0.08192761157618214\n",
      "Validation loss per 100 evaluation steps: 0.08067541037103651\n",
      "Validation loss per 100 evaluation steps: 0.08415318160413016\n",
      "Validation loss per 100 evaluation steps: 0.0831835752727843\n",
      "Validation loss per 100 evaluation steps: 0.08221761862377754\n",
      "Validation loss per 100 evaluation steps: 0.08211739976512242\n",
      "Validation loss per 100 evaluation steps: 0.08271595986460739\n",
      "Validation loss per 100 evaluation steps: 0.08228496497756195\n",
      "Validation loss per 100 evaluation steps: 0.08384932682872931\n",
      "Validation loss per 100 evaluation steps: 0.08268346050390667\n",
      "Validation loss per 100 evaluation steps: 0.08260618012908495\n",
      "Validation loss per 100 evaluation steps: 0.0833320140573062\n",
      "Validation loss per 100 evaluation steps: 0.08223732888569928\n",
      "Validation loss per 100 evaluation steps: 0.08187154262389998\n",
      "Validation loss per 100 evaluation steps: 0.08260394425564188\n",
      "Validation loss per 100 evaluation steps: 0.08207368477478502\n",
      "Validation loss per 100 evaluation steps: 0.08175738793547549\n",
      "Validation loss per 100 evaluation steps: 0.08077719993187332\n",
      "Validation loss per 100 evaluation steps: 0.0798868588763555\n",
      "Validation loss per 100 evaluation steps: 0.07927976937182396\n",
      "Validation loss per 100 evaluation steps: 0.07833308212109862\n",
      "Validation loss per 100 evaluation steps: 0.07781647500692286\n",
      "Validation loss per 100 evaluation steps: 0.0778908372943443\n",
      "Validation loss per 100 evaluation steps: 0.07802690388448237\n",
      "Validation loss per 100 evaluation steps: 0.07880797369008384\n",
      "Validation loss per 100 evaluation steps: 0.08003003930962949\n",
      "Validation loss per 100 evaluation steps: 0.08119127477701418\n",
      "Validation loss per 100 evaluation steps: 0.08038065921601557\n",
      "Validation loss per 100 evaluation steps: 0.07993984626138917\n",
      "Validation loss per 100 evaluation steps: 0.07943083771173864\n",
      "Validation loss per 100 evaluation steps: 0.0795518917793217\n",
      "Validation loss per 100 evaluation steps: 0.079005384201254\n",
      "Validation loss per 100 evaluation steps: 0.07823551634675233\n",
      "Validation loss per 100 evaluation steps: 0.07766339922930493\n",
      "Validation loss per 100 evaluation steps: 0.07686427092875221\n",
      "Validation loss per 100 evaluation steps: 0.07667033750743447\n",
      "Validation loss per 100 evaluation steps: 0.07755011216175532\n",
      "Validation loss per 100 evaluation steps: 0.07693107406394643\n",
      "Validation loss per 100 evaluation steps: 0.07616758045709891\n",
      "Validation loss per 100 evaluation steps: 0.07611049271159402\n",
      "Validation loss per 100 evaluation steps: 0.07577084642915463\n",
      "Validation loss per 100 evaluation steps: 0.07718316766767026\n",
      "Validation loss per 100 evaluation steps: 0.07707033903078266\n",
      "Validation loss per 100 evaluation steps: 0.07637862294383141\n",
      "Validation loss per 100 evaluation steps: 0.07651528810448231\n",
      "Validation loss per 100 evaluation steps: 0.0763687757314315\n",
      "Validation loss per 100 evaluation steps: 0.07592073104514938\n",
      "Validation loss per 100 evaluation steps: 0.07604516105574405\n",
      "Validation loss per 100 evaluation steps: 0.07778854237954294\n",
      "Validation loss per 100 evaluation steps: 0.07831753575109095\n",
      "Validation loss per 100 evaluation steps: 0.07769995049915222\n",
      "Validation loss per 100 evaluation steps: 0.07748832454779382\n",
      "Validation loss per 100 evaluation steps: 0.0779949387734476\n",
      "Validation loss per 100 evaluation steps: 0.07765561357175894\n",
      "Validation loss per 100 evaluation steps: 0.0772055752737973\n",
      "Validation loss per 100 evaluation steps: 0.07767992396184661\n",
      "Validation loss per 100 evaluation steps: 0.077180688270435\n",
      "Validation loss per 100 evaluation steps: 0.07761845223432924\n",
      "Validation loss per 100 evaluation steps: 0.07701556111219869\n",
      "Validation loss per 100 evaluation steps: 0.07817724855420262\n",
      "Validation loss per 100 evaluation steps: 0.0776360329583998\n",
      "Validation loss per 100 evaluation steps: 0.07705848434792599\n",
      "Validation loss per 100 evaluation steps: 0.07689861818694965\n",
      "Validation loss per 100 evaluation steps: 0.07671018211901628\n",
      "Validation loss per 100 evaluation steps: 0.07629546554246033\n",
      "Validation loss per 100 evaluation steps: 0.07634541675584854\n",
      "Validation loss per 100 evaluation steps: 0.07618812320009383\n",
      "Validation loss per 100 evaluation steps: 0.07678054266319591\n",
      "Validation loss per 100 evaluation steps: 0.07695212539349792\n",
      "Validation loss per 100 evaluation steps: 0.07656149588008009\n",
      "Validation loss per 100 evaluation steps: 0.07610500198659344\n",
      "Validation loss per 100 evaluation steps: 0.07686200488877769\n",
      "Validation loss per 100 evaluation steps: 0.07671947303305267\n",
      "Validation loss per 100 evaluation steps: 0.07667047079160146\n",
      "Validation loss per 100 evaluation steps: 0.07699034167769925\n",
      "Validation loss per 100 evaluation steps: 0.07693331485944967\n",
      "Validation loss per 100 evaluation steps: 0.07718050573054676\n",
      "Validation loss per 100 evaluation steps: 0.07679817363952622\n",
      "Validation loss per 100 evaluation steps: 0.07661001096511168\n",
      "Validation loss per 100 evaluation steps: 0.07625217110650032\n",
      "Validation loss per 100 evaluation steps: 0.0762403480322903\n",
      "Validation loss per 100 evaluation steps: 0.07661364633186236\n",
      "Validation loss per 100 evaluation steps: 0.07825590342880277\n",
      "Validation loss per 100 evaluation steps: 0.07772611079936094\n",
      "Validation loss per 100 evaluation steps: 0.07795149066179977\n",
      "Validation loss per 100 evaluation steps: 0.07838910514621769\n",
      "Validation loss per 100 evaluation steps: 0.07794307901679054\n",
      "Validation loss per 100 evaluation steps: 0.07776821475650456\n",
      "Validation loss per 100 evaluation steps: 0.07775227495346561\n",
      "Validation loss per 100 evaluation steps: 0.07725393318444698\n",
      "Validation loss per 100 evaluation steps: 0.07679321468387183\n",
      "Validation loss per 100 evaluation steps: 0.07636778532694734\n",
      "Validation loss per 100 evaluation steps: 0.07666898518528832\n",
      "Validation loss per 100 evaluation steps: 0.07658190769860071\n",
      "Validation loss per 100 evaluation steps: 0.07677314044030123\n",
      "Validation loss per 100 evaluation steps: 0.07722299988575534\n",
      "Validation loss per 100 evaluation steps: 0.07684628639889024\n",
      "Validation loss per 100 evaluation steps: 0.07636189544202099\n",
      "Validation loss per 100 evaluation steps: 0.07593648021100806\n",
      "Validation loss per 100 evaluation steps: 0.0760312421637552\n",
      "Validation loss per 100 evaluation steps: 0.07737400386734931\n",
      "Validation loss per 100 evaluation steps: 0.07721269017988874\n",
      "Validation loss per 100 evaluation steps: 0.0775692446405967\n",
      "Validation loss per 100 evaluation steps: 0.07767844870148316\n",
      "Validation loss per 100 evaluation steps: 0.07734464650599467\n",
      "Validation loss per 100 evaluation steps: 0.07730930037750865\n",
      "Validation loss per 100 evaluation steps: 0.07734884120780763\n",
      "Validation loss per 100 evaluation steps: 0.07703693612576165\n",
      "Validation loss per 100 evaluation steps: 0.07668678204901191\n",
      "Validation loss per 100 evaluation steps: 0.07766378607067376\n",
      "Validation loss per 100 evaluation steps: 0.07831019714399401\n",
      "Validation loss per 100 evaluation steps: 0.07913691430385214\n",
      "Validation loss per 100 evaluation steps: 0.07899124540385072\n",
      "Validation loss per 100 evaluation steps: 0.07916659978079295\n",
      "Validation loss per 100 evaluation steps: 0.07905200769802145\n",
      "Validation loss per 100 evaluation steps: 0.0792058361817353\n",
      "Validation loss per 100 evaluation steps: 0.07932363821101152\n",
      "Validation loss per 100 evaluation steps: 0.0789044587498704\n",
      "Validation loss per 100 evaluation steps: 0.07888240353962421\n",
      "Validation loss per 100 evaluation steps: 0.07965372300204508\n",
      "Validation loss per 100 evaluation steps: 0.07956143632319741\n",
      "Validation loss per 100 evaluation steps: 0.07948446689456788\n",
      "Validation loss per 100 evaluation steps: 0.07968278155543847\n",
      "Validation loss per 100 evaluation steps: 0.08005683488119306\n",
      "Validation loss per 100 evaluation steps: 0.07968439709312243\n",
      "Validation loss per 100 evaluation steps: 0.08042905054812667\n",
      "Validation loss per 100 evaluation steps: 0.08090063667233156\n",
      "Validation loss per 100 evaluation steps: 0.08050739547728841\n",
      "Validation loss per 100 evaluation steps: 0.08071918379835656\n",
      "Validation loss per 100 evaluation steps: 0.08123970148711865\n",
      "Validation loss per 100 evaluation steps: 0.08125309399358686\n",
      "Validation loss per 100 evaluation steps: 0.08110927989818932\n",
      "Validation loss per 100 evaluation steps: 0.08072530198384197\n",
      "Validation loss per 100 evaluation steps: 0.08074803987352125\n",
      "Validation loss per 100 evaluation steps: 0.08050904145674107\n",
      "Validation loss per 100 evaluation steps: 0.08077096106407207\n",
      "Validation loss per 100 evaluation steps: 0.08036225361954868\n",
      "Validation loss per 100 evaluation steps: 0.07998600771469344\n",
      "Validation loss per 100 evaluation steps: 0.07990500222665732\n",
      "Validation loss per 100 evaluation steps: 0.07979454824240319\n",
      "Validation loss per 100 evaluation steps: 0.07942129215227216\n",
      "Validation loss per 100 evaluation steps: 0.07962525749677184\n",
      "Validation loss per 100 evaluation steps: 0.07931364394803148\n",
      "Validation loss per 100 evaluation steps: 0.07942501039843113\n",
      "Validation loss per 100 evaluation steps: 0.07961327502731619\n",
      "Validation loss per 100 evaluation steps: 0.07953459439805509\n",
      "Validation loss per 100 evaluation steps: 0.0799756828917461\n",
      "Validation loss per 100 evaluation steps: 0.08007941259432003\n",
      "Validation loss per 100 evaluation steps: 0.07988740977790759\n",
      "Validation loss per 100 evaluation steps: 0.08071741526190444\n",
      "Validation loss per 100 evaluation steps: 0.08039496264177169\n",
      "Validation loss per 100 evaluation steps: 0.0813936604348199\n",
      "Validation loss per 100 evaluation steps: 0.08110373442402205\n",
      "Validation loss per 100 evaluation steps: 0.0812494068548786\n",
      "Validation loss per 100 evaluation steps: 0.08090986084175898\n",
      "Validation loss per 100 evaluation steps: 0.08055663574025981\n",
      "Validation loss per 100 evaluation steps: 0.08018819147565207\n",
      "Validation loss per 100 evaluation steps: 0.08006796938284731\n",
      "Validation loss per 100 evaluation steps: 0.08025814783005754\n",
      "Validation loss per 100 evaluation steps: 0.08082604569037419\n",
      "Validation loss per 100 evaluation steps: 0.08057402500019051\n",
      "Validation loss per 100 evaluation steps: 0.08034949522712206\n",
      "Validation loss per 100 evaluation steps: 0.08035590417085871\n",
      "Validation loss per 100 evaluation steps: 0.08075481490729572\n",
      "Validation loss per 100 evaluation steps: 0.08046355499699583\n",
      "Validation loss per 100 evaluation steps: 0.080817171508388\n",
      "Validation loss per 100 evaluation steps: 0.08056865954440781\n",
      "Validation loss per 100 evaluation steps: 0.08051742672413731\n",
      "Validation loss per 100 evaluation steps: 0.08199880275508337\n",
      "Validation loss per 100 evaluation steps: 0.08183685602831961\n",
      "Validation loss per 100 evaluation steps: 0.08166613624819248\n",
      "Validation loss per 100 evaluation steps: 0.08206386185883753\n",
      "Validation loss per 100 evaluation steps: 0.08232816099615932\n",
      "Validation loss per 100 evaluation steps: 0.08232130144459256\n",
      "Validation loss per 100 evaluation steps: 0.08198476982134212\n",
      "Validation loss per 100 evaluation steps: 0.08185739449977823\n",
      "Validation loss per 100 evaluation steps: 0.08156069877491942\n",
      "Validation loss per 100 evaluation steps: 0.08125883706973695\n",
      "Validation loss per 100 evaluation steps: 0.08147422011513096\n",
      "Validation loss per 100 evaluation steps: 0.08173257084442256\n",
      "Validation loss per 100 evaluation steps: 0.08154792357696543\n",
      "Validation loss per 100 evaluation steps: 0.08199580791100763\n",
      "Validation loss per 100 evaluation steps: 0.08205114604953632\n",
      "Validation loss per 100 evaluation steps: 0.08188634580374245\n",
      "Validation loss per 100 evaluation steps: 0.08178460164334397\n",
      "Validation loss per 100 evaluation steps: 0.08241755937441028\n",
      "Validation loss per 100 evaluation steps: 0.08282959688020645\n",
      "Validation loss per 100 evaluation steps: 0.08305629927551667\n",
      "Validation loss per 100 evaluation steps: 0.0828954889612733\n",
      "Validation loss per 100 evaluation steps: 0.08306554583101168\n",
      "Validation loss per 100 evaluation steps: 0.0828533061268245\n",
      "Validation loss per 100 evaluation steps: 0.08295460482884678\n",
      "Validation loss per 100 evaluation steps: 0.08280851831649022\n",
      "Validation loss per 100 evaluation steps: 0.08262060627373198\n",
      "Validation loss per 100 evaluation steps: 0.08276113574734527\n",
      "Validation Loss: 0.0828400719638581\n",
      "Validation Accuracy: 0.9861143706485176\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "_fsSt_F_DGPf",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              precision    recall  f1-score   support\n",
      "\n",
      "                        dipeptidyl peptidase       0.75      1.00      0.86         6\n",
      "                   motivational interviewing       1.00      1.00      1.00         4\n",
      "                                hemodialyzed       0.00      0.00      0.00         1\n",
      "                  anaplastic lymphoma kinase       1.00      1.00      1.00         3\n",
      "                          neurocysticercosis       1.00      0.71      0.83         7\n",
      "                             position effect       0.00      0.00      0.00         2\n",
      "                                       lewis       0.00      0.00      0.00         2\n",
      "                  aminoglycoside antibiotics       1.00      1.00      1.00         6\n",
      "                melaninconcentrating hormone       1.00      0.78      0.88         9\n",
      "                             assisted living       0.00      0.00      0.00         1\n",
      "      quantitative polymerase chain reaction       0.00      0.00      0.00         1\n",
      "          laparoscopic radical prostatectomy       1.00      1.00      1.00         3\n",
      "                                    tantalum       1.00      1.00      1.00         2\n",
      "                                tibial nerve       0.00      0.00      0.00         1\n",
      "                             ultrafiltration       0.00      0.00      0.00         2\n",
      "                     wiskottaldrich syndrome       0.91      1.00      0.95        10\n",
      "                            mechanosensitive       1.00      0.33      0.50         3\n",
      "      macrophage migration inhibitory factor       1.00      1.00      1.00        11\n",
      "                           pulmonary embolus       0.14      0.50      0.22         2\n",
      "             immediate breast reconstruction       1.00      1.00      1.00         1\n",
      "                                 hivinfected       0.00      0.00      0.00         2\n",
      "                  microcrystalline cellulose       0.00      0.00      0.00         1\n",
      "               prosthetic valve endocarditis       1.00      0.33      0.50         3\n",
      "                      fructosebisphosphatase       0.50      1.00      0.67         1\n",
      "                        mean platelet volume       1.00      1.00      1.00         4\n",
      "                       primary myelofibrosis       0.55      1.00      0.71         6\n",
      "                      exerciseinduced asthma       1.00      0.50      0.67         4\n",
      "                    streptococcus agalactiae       0.60      0.75      0.67         4\n",
      "                             noonan syndrome       0.67      1.00      0.80         2\n",
      "                            chemiluminescent       0.00      0.00      0.00         1\n",
      "                     methyl methanesulfonate       0.00      0.00      0.00         1\n",
      "                   rat peritoneal mast cells       0.00      0.00      0.00         2\n",
      "                         caloric restriction       0.00      0.00      0.00         1\n",
      "                              posterolateral       0.00      0.00      0.00         1\n",
      "                    eosinophilic esophagitis       1.00      0.83      0.91         6\n",
      "                                    vascular       0.00      0.00      0.00         2\n",
      "                                 gemfibrozil       0.75      1.00      0.86         3\n",
      "                  avian myeloblastosis virus       1.00      1.00      1.00         2\n",
      "                       heterogeneous nuclear       1.00      1.00      1.00         2\n",
      "                       left pulmonary artery       0.00      0.00      0.00         1\n",
      "            recombinant human growth hormone       1.00      1.00      1.00         4\n",
      "                                   bone loss       0.00      0.00      0.00         1\n",
      "                  betahemolytic streptococci       0.00      0.00      0.00         1\n",
      "                     breast cancer survivors       0.00      0.00      0.00         3\n",
      "                  bronchopulmonary dysplasia       1.00      1.00      1.00         6\n",
      "                                  rheumatoid       0.00      0.00      0.00         2\n",
      "                       japanese encephalitis       1.00      0.86      0.92         7\n",
      "                                   mammalian       0.00      0.00      0.00         1\n",
      "                               cerebrospinal       0.00      0.00      0.00         2\n",
      "                      acanthamoeba keratitis       0.75      1.00      0.86         6\n",
      "                        pulmonary metastases       0.00      0.00      0.00         3\n",
      "                                   hepatitis       0.20      0.33      0.25         3\n",
      "                       cochlear implantation       0.67      1.00      0.80         2\n",
      "                            erythema nodosum       0.00      0.00      0.00         4\n",
      "                             marfan syndrome       0.00      0.00      0.00         2\n",
      "                          basic life support       0.00      0.00      0.00         2\n",
      "                     cutaneous leishmaniasis       0.38      1.00      0.55         3\n",
      "                                    oxidized       0.00      0.00      0.00         1\n",
      "                          friedreichs ataxia       0.00      0.00      0.00         7\n",
      "                 herpes simplex encephalitis       1.00      1.00      1.00         7\n",
      "                           iodine deficiency       0.67      0.50      0.57         4\n",
      "                                pseudorabies       0.80      1.00      0.89         4\n",
      "                     drosophila melanogaster       1.00      1.00      1.00         1\n",
      "                      blunt abdominal trauma       1.00      1.00      1.00         1\n",
      "                      conformal radiotherapy       0.00      0.00      0.00         3\n",
      "                           tetratricopeptide       1.00      1.00      1.00         1\n",
      "                             choanal atresia       0.20      0.33      0.25         3\n",
      "                          methanolic extract       0.00      0.00      0.00         1\n",
      "                       methadone maintenance       0.00      0.00      0.00         1\n",
      "                           innominate artery       0.00      0.00      0.00         2\n",
      "                periventricular leukomalacia       1.00      0.80      0.89         5\n",
      "                       spondyloarthropathies       1.00      0.50      0.67         2\n",
      "                            dry eye syndrome       0.88      1.00      0.93         7\n",
      "                          cerebral perfusion       0.00      0.00      0.00         1\n",
      "                          dopa decarboxylase       1.00      1.00      1.00         1\n",
      "                         calorie restriction       0.50      0.40      0.44         5\n",
      "                        acute pyelonephritis       1.00      0.33      0.50         3\n",
      "                     common mental disorders       0.50      1.00      0.67         1\n",
      "                      carpal tunnel syndrome       0.60      1.00      0.75         3\n",
      "             cervical spondylotic myelopathy       1.00      1.00      1.00         4\n",
      "                     bacterial translocation       0.67      1.00      0.80         2\n",
      "                        arachidonoylglycerol       1.00      1.00      1.00         1\n",
      "                           cardiac tamponade       0.38      1.00      0.55         3\n",
      "                     pulmonary sequestration       0.50      1.00      0.67         4\n",
      "                      complementary medicine       1.00      1.00      1.00         2\n",
      "                              intraabdominal       0.17      0.50      0.25         2\n",
      "                            chemical warfare       1.00      1.00      1.00         2\n",
      "                               lichen planus       0.89      0.89      0.89         9\n",
      "                      trabecular bone volume       0.00      0.00      0.00         1\n",
      "                           total gastrectomy       0.00      0.00      0.00         1\n",
      "                             episodic memory       0.00      0.00      0.00         1\n",
      "                 receptorinteracting protein       1.00      1.00      1.00         3\n",
      "                          glatiramer acetate       0.50      1.00      0.67         1\n",
      "              neuroleptic malignant syndrome       0.86      0.86      0.86         7\n",
      "                        short bowel syndrome       1.00      1.00      1.00         3\n",
      "                               hip dysplasia       0.33      1.00      0.50         2\n",
      "              primary pulmonary hypertension       0.80      1.00      0.89         4\n",
      "                         bovine tuberculosis       0.67      1.00      0.80         6\n",
      "                                   uric acid       0.00      0.00      0.00         1\n",
      "                               phenothiazine       0.00      0.00      0.00         2\n",
      "               chronic granulomatous disease       1.00      1.00      1.00         4\n",
      "                         mycobacterium bovis       0.50      1.00      0.67         3\n",
      "                    recurrent abdominal pain       0.75      1.00      0.86         3\n",
      "                     alcoholic liver disease       1.00      1.00      1.00         5\n",
      "                  lung transplant recipients       0.50      0.67      0.57         3\n",
      "                          gonadal dysgenesis       0.00      0.00      0.00         1\n",
      "                         aberrant crypt foci       1.00      1.00      1.00         1\n",
      "                                phytosterols       0.00      0.00      0.00         2\n",
      "                         erythema multiforme       0.57      0.80      0.67         5\n",
      "                         cognitivebehavioral       0.50      1.00      0.67         1\n",
      "                             polyelectrolyte       0.00      0.00      0.00         1\n",
      "                    adrenocortical carcinoma       1.00      1.00      1.00         3\n",
      "                          olfactory receptor       0.00      0.00      0.00         1\n",
      "                                 rubrospinal       0.00      0.00      0.00         1\n",
      "                                insulin gene       0.00      0.00      0.00         1\n",
      "                     transsphenoidal surgery       0.50      1.00      0.67         1\n",
      "               invasive pneumococcal disease       0.67      1.00      0.80         2\n",
      "                           enteral nutrition       0.20      1.00      0.33         1\n",
      "                           rift valley fever       0.89      1.00      0.94         8\n",
      "                              hexosaminidase       1.00      0.50      0.67         4\n",
      "                           glycogen synthase       0.00      0.00      0.00         1\n",
      "                                 cabergoline       1.00      1.00      1.00         2\n",
      "                     bone marrow involvement       1.00      1.00      1.00         1\n",
      "                          total testosterone       0.00      0.00      0.00         1\n",
      "                             neck dissection       0.00      0.00      0.00         2\n",
      "          dobutamine stress echocardiography       0.80      1.00      0.89         4\n",
      "                            opioid receptors       0.33      1.00      0.50         1\n",
      "                      sesquiterpene lactones       0.60      1.00      0.75         3\n",
      "                         supercritical fluid       1.00      0.75      0.86         4\n",
      "                                intragastric       1.00      1.00      1.00         1\n",
      "                        aortic valve disease       0.75      1.00      0.86         3\n",
      "                           western australia       0.00      0.00      0.00         1\n",
      "                             proximal tubule       0.00      0.00      0.00         1\n",
      "                            dynamic exercise       0.00      0.00      0.00         1\n",
      "                                 farinfrared       1.00      1.00      1.00         1\n",
      "          insulindependent diabetes mellitus       0.50      1.00      0.67         2\n",
      "                        vascular endothelial       0.67      0.80      0.73         5\n",
      "                             resiniferatoxin       0.00      0.00      0.00         3\n",
      "                         articular cartilage       0.00      0.00      0.00         1\n",
      "                         neuroblastoma cells       0.00      0.00      0.00         1\n",
      "                     posterior cranial fossa       0.00      0.00      0.00         1\n",
      "                       vaccine effectiveness       0.00      0.00      0.00         1\n",
      "                            pulmonary emboli       0.00      0.00      0.00         2\n",
      "                                 myoelectric       0.00      0.00      0.00         1\n",
      "                          conscious sedation       0.00      0.00      0.00         1\n",
      "                              lyme arthritis       0.50      1.00      0.67         1\n",
      "       granulocyte colony stimulating factor       0.67      1.00      0.80         2\n",
      "                     internal anal sphincter       0.00      0.00      0.00         1\n",
      "                                 megavoltage       0.00      0.00      0.00         1\n",
      "                                  molybdenum       0.67      0.67      0.67         3\n",
      "                            social isolation       0.00      0.00      0.00         2\n",
      "                        tuberculin skin test       0.00      0.00      0.00         1\n",
      "                             cardiac rupture       0.00      0.00      0.00         3\n",
      "                               methylglyoxal       0.50      1.00      0.67         1\n",
      "                          granulation tissue       0.00      0.00      0.00         1\n",
      "                                   pegylated       0.00      0.00      0.00         2\n",
      "                           adductor pollicis       0.00      0.00      0.00         1\n",
      "                                 tropomyosin       0.00      0.00      0.00         1\n",
      "                 reninangiotensinaldosterone       1.00      1.00      1.00         2\n",
      "recombinant human bone morphogenetic protein       1.00      1.00      1.00         1\n",
      "                    microcomputed tomography       0.00      0.00      0.00         2\n",
      "             methadone maintenance treatment       0.56      1.00      0.71         5\n",
      "                          serotonin receptor       0.50      1.00      0.67         1\n",
      "                      low anterior resection       0.00      0.00      0.00         1\n",
      "                             atherosclerotic       0.00      0.00      0.00         1\n",
      "                                    bed rest       1.00      1.00      1.00         1\n",
      "                    major histocompatibility       0.00      0.00      0.00         2\n",
      "                       interstitial cystitis       0.50      1.00      0.67         1\n",
      "                          retrograde amnesia       0.00      0.00      0.00         1\n",
      "                   reciprocal translocations       0.00      0.00      0.00         1\n",
      "                               tuning curves       0.00      0.00      0.00         1\n",
      "                                  picosecond       1.00      1.00      1.00         2\n",
      "                   men who have sex with men       0.67      1.00      0.80         2\n",
      "                     erythrocyte aggregation       0.00      0.00      0.00         1\n",
      "                            transgenic mouse       0.00      0.00      0.00         2\n",
      "                          estrogen receptors       0.00      0.00      0.00         1\n",
      "                           negative symptoms       0.00      0.00      0.00         2\n",
      "                              pulsed doppler       0.00      0.00      0.00         1\n",
      "                          pharyngoesophageal       0.00      0.00      0.00         1\n",
      "                           cognitive therapy       0.00      0.00      0.00         1\n",
      "                                  tributyrin       0.00      0.00      0.00         1\n",
      "                              response times       0.00      0.00      0.00         1\n",
      "          serial analysis of gene expression       1.00      1.00      1.00         2\n",
      "                               abscisic acid       0.00      0.00      0.00         2\n",
      "              videoassisted thoracic surgery       1.00      1.00      1.00         1\n",
      "                           rapid prototyping       0.00      0.00      0.00         1\n",
      "                               physiotherapy       0.00      0.00      0.00         2\n",
      "                               tetracyclines       0.67      1.00      0.80         2\n",
      "                left ventricular dysfunction       0.00      0.00      0.00         1\n",
      "                      stearoylcoa desaturase       0.60      1.00      0.75         3\n",
      "               coronary artery calcification       1.00      0.86      0.92         7\n",
      "                                   stem cell       0.00      0.00      0.00         1\n",
      "                                black carbon       1.00      1.00      1.00         1\n",
      "                    global cerebral ischemia       0.00      0.00      0.00         1\n",
      "                                myosin heavy       0.00      0.00      0.00         2\n",
      "                        patientcentered care       0.50      1.00      0.67         1\n",
      "                              working memory       0.33      1.00      0.50         1\n",
      "                        best supportive care       0.00      0.00      0.00         1\n",
      "                              variant angina       0.00      0.00      0.00         1\n",
      "                          continuity of care       1.00      1.00      1.00         2\n",
      "                         occupational health       1.00      1.00      1.00         1\n",
      "                      intraabdominal abscess       0.00      0.00      0.00         1\n",
      "                              stomach cancer       1.00      0.50      0.67         2\n",
      "                           family physicians       0.67      1.00      0.80         2\n",
      "                            light microscopy       0.00      0.00      0.00         1\n",
      "                   insulindependent diabetes       0.00      0.00      0.00         2\n",
      "                          antireflux surgery       1.00      0.50      0.67         2\n",
      "                         proliferative index       0.00      0.00      0.00         1\n",
      "                            resistant starch       0.50      0.50      0.50         2\n",
      "                         homozygous deletion       0.00      0.00      0.00         1\n",
      "                               multislice ct       1.00      0.50      0.67         2\n",
      "                                  homologous       0.00      0.00      0.00         1\n",
      "                  cardiac magnetic resonance       1.00      1.00      1.00         1\n",
      "                               acute myeloid       1.00      1.00      1.00         3\n",
      "                                  nicorandil       0.00      0.00      0.00         1\n",
      "             resident peritoneal macrophages       1.00      1.00      1.00         1\n",
      "                                  artemether       0.00      0.00      0.00         2\n",
      "                        alternative splicing       0.00      0.00      0.00         2\n",
      "                            food deprivation       0.00      0.00      0.00         2\n",
      "                        electroretinographic       1.00      1.00      1.00         1\n",
      "                          polypropylene mesh       0.00      0.00      0.00         1\n",
      "                 endothelial cell monolayers       0.00      0.00      0.00         1\n",
      "                                   metformin       0.00      0.00      0.00         1\n",
      "                                hexobarbital       0.00      0.00      0.00         2\n",
      "                                peptic ulcer       0.33      1.00      0.50         1\n",
      "                  connective tissue diseases       0.00      0.00      0.00         1\n",
      "                          electrophysiologic       0.00      0.00      0.00         2\n",
      "                           vasovagal syncope       0.14      1.00      0.25         1\n",
      "                    dissolved organic carbon       0.00      0.00      0.00         1\n",
      "             nethylmaleimidesensitive factor       0.00      0.00      0.00         1\n",
      "                  immunocompromised patients       1.00      1.00      1.00         1\n",
      "                           chemiluminescence       0.00      0.00      0.00         1\n",
      "                                   shortaxis       0.00      0.00      0.00         1\n",
      "                               gonadotrophin       0.00      0.00      0.00         1\n",
      "                             hydroxybenzoate       1.00      1.00      1.00         1\n",
      "                   tricyclic antidepressants       1.00      1.00      1.00         2\n",
      "                            tracheobronchial       0.14      1.00      0.25         1\n",
      "                              melting points       0.00      0.00      0.00         1\n",
      "                       discriminant function       0.00      0.00      0.00         1\n",
      "                                antidiuretic       0.00      0.00      0.00         1\n",
      "                             hexagonal phase       0.00      0.00      0.00         1\n",
      "                                  rnaprotein       0.00      0.00      0.00         1\n",
      "    major histocompatibility complex class i       1.00      1.00      1.00         1\n",
      "                  costeffectiveness analysis       1.00      1.00      1.00         1\n",
      "                          isoelectrofocusing       0.00      0.00      0.00         1\n",
      "                  proteinprotein interaction       1.00      1.00      1.00         1\n",
      "                                  retrovirus       0.00      0.00      0.00         2\n",
      "                               pancreastatin       0.14      1.00      0.25         1\n",
      "                       meningococcal disease       1.00      1.00      1.00         1\n",
      "                            inferior oblique       0.00      0.00      0.00         1\n",
      "                     cardiac transplantation       0.00      0.00      0.00         1\n",
      "                            high cholesterol       0.00      0.00      0.00         1\n",
      "                                         cbl       0.00      0.00      0.00         1\n",
      "                               plasmodesmata       0.50      1.00      0.67         1\n",
      "                      prostate brachytherapy       1.00      1.00      1.00         1\n",
      "                              neurosecretory       0.00      0.00      0.00         1\n",
      "                             brassinosteroid       0.00      0.00      0.00         1\n",
      "                                 gibberellin       0.00      0.00      0.00         1\n",
      "                     stress echocardiography       0.00      0.00      0.00         1\n",
      "                              venous outflow       0.00      0.00      0.00         1\n",
      "                   ventromedial hypothalamic       0.00      0.00      0.00         1\n",
      "                  right ventricular pressure       0.00      0.00      0.00         1\n",
      "                                    f hybrid       0.00      0.00      0.00         1\n",
      "                                  sacroiliac       0.00      0.00      0.00         1\n",
      "\n",
      "                                   micro avg       0.65      0.60      0.62       565\n",
      "                                   macro avg       0.55      0.60      0.56       565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report,f1_score\n",
    "\n",
    "print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "H84xJ2uxMLTY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = \"./model_2\"\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# save vocabulary of the tokenizer\n",
    "tokenizer.save_vocabulary(directory)\n",
    "# save the model weights and its configuration file\n",
    "model.save_pretrained(directory)\n",
    "print('All files saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0449ee29b8be40359e5dec1055689664": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "057afc3f1bf0472a93fb85c04e983f86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0beb39391dad46a58061b5005bfe05a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1ed178a8643407f9c041b0cb4d31485",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e471753f4232433e97df92fbe99b3c25",
      "value": 570
     }
    },
    "0ccab1927a624d6194a3bdb2f6fdbe46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "162cc643970248e1a90f95b32051e09e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17e55f8b4a4b4515b8df0154a1caf1ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2abdc206698b4c6eae3e9aadb82891e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9eec38e5e7cf4c1bb94ffc2c813ed4ae",
      "placeholder": "",
      "style": "IPY_MODEL_97566bd57258417490704690e66db5ce",
      "value": "Downloading ()okenizer_config.json: 100%"
     }
    },
    "2b91c34758c241ac8f649d34c7cc1c7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2de4114a6daf430e81f40e11b0b8d7fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37ce0e7f681540f0b94db0b75b6fd65b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc754a57abc9410b8da5061c342a9cec",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d5097890e83844a6a30e5700fc61d40c",
      "value": 440473133
     }
    },
    "3de0161dfd3a4356be21de12a3dd8761": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4556de712c6b43bb99b0611bfb053d21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6e9752a11a14bb4bd01de903ac0178d",
      "placeholder": "",
      "style": "IPY_MODEL_544f8855a35a4fc8a524f9c9c08cabbb",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "494159e2c4c44a5fb9bb9b3cb458683b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2de4114a6daf430e81f40e11b0b8d7fd",
      "placeholder": "",
      "style": "IPY_MODEL_ed75b579b0254b4f866ac91c3af65e5f",
      "value": "Downloading ()lve/main/config.json: 100%"
     }
    },
    "516c5340a9e94b8aaa22fbe44f80c9e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "524e576b7c934eb4ba1c8e8c12cfe75f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "544f8855a35a4fc8a524f9c9c08cabbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "580b262793ee4c59b142bf471d5b6416": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58c7ff4f1b64478f80e3a3e7e7f025d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c5a1716f3bb41c987b3f68714a5f862": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_162cc643970248e1a90f95b32051e09e",
      "placeholder": "",
      "style": "IPY_MODEL_580b262793ee4c59b142bf471d5b6416",
      "value": "Downloading ()/main/tokenizer.json: 100%"
     }
    },
    "65435ff608704501a710839c7cca7e17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65c848f9d382415885bc02b86d9eb805": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a44c7ad03e442b68284a30da2d3b310": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c19b280e0f24471a25e21e40520471c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "75949b69e7a447b4bd37de56b54b5225": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "771bda931edf422aa5a2ac077f961266": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f54a3d1429145c18eb30fb422b8da1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83f9b1c8b58d4b6bbc94983c8d78a3fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3de0161dfd3a4356be21de12a3dd8761",
      "placeholder": "",
      "style": "IPY_MODEL_65c848f9d382415885bc02b86d9eb805",
      "value": " 232k/232k [00:00&lt;00:00, 2.12MB/s]"
     }
    },
    "846d46fdd2864b2ba151997f3b5234a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_494159e2c4c44a5fb9bb9b3cb458683b",
       "IPY_MODEL_0beb39391dad46a58061b5005bfe05a3",
       "IPY_MODEL_97b6c10a1e084cfc8930cdf9392659fa"
      ],
      "layout": "IPY_MODEL_057afc3f1bf0472a93fb85c04e983f86"
     }
    },
    "8ea6cdfda386407ebcb48692261b9c8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58c7ff4f1b64478f80e3a3e7e7f025d1",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c19b280e0f24471a25e21e40520471c",
      "value": 466062
     }
    },
    "91095500ddd247ad8fcc95038e5e2f75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_771bda931edf422aa5a2ac077f961266",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0449ee29b8be40359e5dec1055689664",
      "value": 231508
     }
    },
    "9677a938913941198cebb0bf76b7a57b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a44c7ad03e442b68284a30da2d3b310",
      "placeholder": "",
      "style": "IPY_MODEL_c8cd176682b74bffbfb964d8681752fc",
      "value": " 28.0/28.0 [00:00&lt;00:00, 836B/s]"
     }
    },
    "97566bd57258417490704690e66db5ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "97b6c10a1e084cfc8930cdf9392659fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f54a3d1429145c18eb30fb422b8da1d",
      "placeholder": "",
      "style": "IPY_MODEL_65435ff608704501a710839c7cca7e17",
      "value": " 570/570 [00:00&lt;00:00, 17.2kB/s]"
     }
    },
    "9eec38e5e7cf4c1bb94ffc2c813ed4ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a66b80c0d2474bd88fa3f853d658c4b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aeb2589b18b2404cbd1ba5d6fd40575c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b365473f00954e5db97592f213c32aae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c08f9b2730274e8abfc6e942208964bb",
       "IPY_MODEL_91095500ddd247ad8fcc95038e5e2f75",
       "IPY_MODEL_83f9b1c8b58d4b6bbc94983c8d78a3fd"
      ],
      "layout": "IPY_MODEL_df05cbdbb56c4ae590f9489f01c4cb29"
     }
    },
    "b51fbdaa86f9462bac966aa8167d7bf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2abdc206698b4c6eae3e9aadb82891e8",
       "IPY_MODEL_d6f543a965c6445cacb6c3b71293301b",
       "IPY_MODEL_9677a938913941198cebb0bf76b7a57b"
      ],
      "layout": "IPY_MODEL_f502b4e1d5b04f498781c17593925c5a"
     }
    },
    "b6e9752a11a14bb4bd01de903ac0178d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c08f9b2730274e8abfc6e942208964bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_524e576b7c934eb4ba1c8e8c12cfe75f",
      "placeholder": "",
      "style": "IPY_MODEL_c53cb709e9a54595b5a8fc51ea3924b5",
      "value": "Downloading ()solve/main/vocab.txt: 100%"
     }
    },
    "c53cb709e9a54595b5a8fc51ea3924b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8cd176682b74bffbfb964d8681752fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cb6cc1e0796a4a578117fa91c7c1180f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fde608d7b6774909bc7df1895aabaaf9",
      "placeholder": "",
      "style": "IPY_MODEL_aeb2589b18b2404cbd1ba5d6fd40575c",
      "value": " 440M/440M [00:02&lt;00:00, 143MB/s]"
     }
    },
    "cfd1c557cd7c423bbb61e1bc011a3d22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5c5a1716f3bb41c987b3f68714a5f862",
       "IPY_MODEL_8ea6cdfda386407ebcb48692261b9c8c",
       "IPY_MODEL_db13f9dab0564e99810569af3c8b5492"
      ],
      "layout": "IPY_MODEL_17e55f8b4a4b4515b8df0154a1caf1ed"
     }
    },
    "d5097890e83844a6a30e5700fc61d40c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d6f543a965c6445cacb6c3b71293301b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75949b69e7a447b4bd37de56b54b5225",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ccab1927a624d6194a3bdb2f6fdbe46",
      "value": 28
     }
    },
    "d7f9a1f407cf46af914bb869105e6f9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4556de712c6b43bb99b0611bfb053d21",
       "IPY_MODEL_37ce0e7f681540f0b94db0b75b6fd65b",
       "IPY_MODEL_cb6cc1e0796a4a578117fa91c7c1180f"
      ],
      "layout": "IPY_MODEL_516c5340a9e94b8aaa22fbe44f80c9e3"
     }
    },
    "db13f9dab0564e99810569af3c8b5492": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a66b80c0d2474bd88fa3f853d658c4b0",
      "placeholder": "",
      "style": "IPY_MODEL_2b91c34758c241ac8f649d34c7cc1c7c",
      "value": " 466k/466k [00:00&lt;00:00, 3.37MB/s]"
     }
    },
    "dc754a57abc9410b8da5061c342a9cec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df05cbdbb56c4ae590f9489f01c4cb29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e471753f4232433e97df92fbe99b3c25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ed75b579b0254b4f866ac91c3af65e5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f1ed178a8643407f9c041b0cb4d31485": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f502b4e1d5b04f498781c17593925c5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fde608d7b6774909bc7df1895aabaaf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
